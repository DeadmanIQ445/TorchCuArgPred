{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "general-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from torch import nn\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "third-governor",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "TRAIN_TEST_SPLIT = 0.9\n",
    "DS_PATH = \"/home/deadman445/PycharmProjects/CuArgPred/data/_all_data2.csv\"\n",
    "EPOCHS = 3\n",
    "FREQ_LIMIT = 300\n",
    "\n",
    "# FREQ_LIMIT = 200\n",
    "FREQ_CUT_SYMBOL = \"<UNK>\"\n",
    "NaN_symbol = ''\n",
    "MAX_CUT = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "guided-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "bert = AutoModel.from_pretrained(\"microsoft/codebert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "minute-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DS_PATH)\n",
    "data['arg_types'] = data['arg_types'].apply(eval)\n",
    "data = data[data.arg_types.astype(bool)]\n",
    "df_labels = pd.DataFrame(data['arg_types'].values.tolist())\n",
    "df_labels[pd.isnull(df_labels)]  = NaN_symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "unlimited-scope",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226711.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.apply(pd.Series.value_counts).sum(axis=1).sort_values(ascending=False).iloc[1:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "south-rocket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161953.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.apply(pd.Series.value_counts).sum(axis=1).sort_values(ascending=False).iloc[2:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "distant-burns",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            5515939.0\n",
       "<UNK>         64758.0\n",
       "str            8038.0\n",
       "int            8023.0\n",
       "dict           7990.0\n",
       "bool           7984.0\n",
       "list           7966.0\n",
       "Any            5653.0\n",
       "float          5232.0\n",
       "callable       3335.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_composite(p):\n",
    "    a = []\n",
    "    for i in p:\n",
    "        if 'tuple' in i.lower():\n",
    "            a.append(i)\n",
    "            continue\n",
    "        if '[' in i and not 'Union' in i:\n",
    "            b = i.split('[')                \n",
    "            if 'Optional' == b[0]:\n",
    "                if len(b)>1:\n",
    "                    a.append(b[1].split(']')[0].lower())\n",
    "                else:\n",
    "                    a.append(b[0].lower())\n",
    "            else:\n",
    "                a.append(b[0].lower())\n",
    "        else:\n",
    "            if i=='List' or i=='Dict' or i=='Callable':\n",
    "                a.append(i.lower())                \n",
    "            else:\n",
    "                a.append(i.split('.')[-1])\n",
    "    return a\n",
    "\n",
    "def replace_type(df, typ='str', frac=0.9):\n",
    "    df2= df.copy()\n",
    "    str_cvrt = func(typ)\n",
    "    df2.update(df[df.eq(typ).any(axis=1)].sample(frac=frac).apply(str_cvrt))\n",
    "    return df2\n",
    "\n",
    "\n",
    "def func(typ):\n",
    "    def cvrt(p):\n",
    "        a = []\n",
    "        for i in p:\n",
    "            if i == typ:\n",
    "                a.append(FREQ_CUT_SYMBOL)\n",
    "            else:\n",
    "                a.append(i)\n",
    "        return a\n",
    "    return cvrt\n",
    "\n",
    "dd = df_labels.apply(remove_composite)\n",
    "for (k,v) in dict(dd.apply(pd.Series.value_counts).sum(axis=1).sort_values(ascending=False)).items():\n",
    "    if k!=FREQ_CUT_SYMBOL and k!=NaN_symbol and v>MAX_CUT:\n",
    "        dd = replace_type(dd, k, (v-MAX_CUT)/v) \n",
    "df_labels = dd\n",
    "df_labels = dd\n",
    "dd.apply(pd.Series.value_counts).sum(axis=1).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "consecutive-revision",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[''] ['<UNK>']\n",
      "Enc for \"NaN\" [0], Enc for FREQ_CUT_SYMBOL [1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def la(data_batch_i):\n",
    "    r = []\n",
    "    \n",
    "    for i in data_batch_i:\n",
    "        if not (i == NaN_enc[0] or i==FREQ_CUT_ENC[0] or i==Any_enc[0]):\n",
    "            r.append(i)\n",
    "        if i==FREQ_CUT_ENC[0] or i==Any_enc[0]:\n",
    "            r.append(NaN_enc[0])\n",
    "    if len(r) == 0 or sum(r)==0:\n",
    "        return pd.NA\n",
    "    return r\n",
    "\n",
    "df_labels = df_labels.apply(lambda x: x.mask(x.map(x.value_counts())<FREQ_LIMIT, FREQ_CUT_SYMBOL))\n",
    "enc = preprocessing.LabelEncoder()\n",
    "all_types = df_labels.apply(pd.Series).stack().values\n",
    "enc.fit(all_types)\n",
    "FREQ_CUT_ENC = enc.transform([FREQ_CUT_SYMBOL])\n",
    "NaN_enc = enc.transform([NaN_symbol])\n",
    "Any_enc = enc.transform(['Any'])\n",
    "print(enc.inverse_transform(NaN_enc), enc.inverse_transform(FREQ_CUT_ENC))\n",
    "print(f'Enc for \"NaN\" {NaN_enc}, Enc for FREQ_CUT_SYMBOL {FREQ_CUT_ENC}')\n",
    "df3 = df_labels.apply(enc.transform)\n",
    "data['labels'] = df3.values.tolist()\n",
    "\n",
    "data['labels'] = data['labels'].apply(la)\n",
    "data = data.dropna(subset=['labels'], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "def train_test_by_repo(data, split=0.75):\n",
    "    train_l = []\n",
    "    test_l = []\n",
    "    c = 0\n",
    "    train_len = split * len(data)\n",
    "    for name, i in data.groupby(['repo']).count().sample(frac=1).iterrows():\n",
    "        if train_len > c:\n",
    "            train_l.append(name)\n",
    "            c += i['author']\n",
    "        else:\n",
    "            test_l.append(name)\n",
    "    return data.loc[data['repo'].isin(train_l)], data.loc[data['repo'].isin(test_l)]\n",
    "\n",
    "\n",
    "\n",
    "train_ds, test_ds = train_test_by_repo(data, TRAIN_TEST_SPLIT)\n",
    "\n",
    "\n",
    "len(enc.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "decent-monroe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"types.txt\", 'w') as f:\n",
    "    for i in enc.classes_:\n",
    "        f.write(i)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "meaning-density",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: GeForce RTX 2060 SUPER\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sustainable-globe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "backed-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_elem(data_batch_i):\n",
    "    sentence_line =  tokenizer(data_batch_i['body'], return_tensors='pt', padding='max_length', truncation=True)\n",
    "    sentence_line1 = tokenizer(data_batch_i['body'], padding='max_length', truncation=True,  return_offsets_mapping=True, return_length=True)\n",
    "    args = get_names(data_batch_i['body'])\n",
    "    labels = dict(zip([i[0] for i in args], data_batch_i['labels']))\n",
    "    args = offset2ind(args, sentence_line1)\n",
    "    ids = torch.zeros_like(sentence_line['input_ids'])\n",
    "    for i in args:\n",
    "        ids[0][i[1]]=labels.get(i[0], NaN_enc[0])\n",
    "    return sentence_line, ids\n",
    "\n",
    "def offset2ind(args, tokens):\n",
    "    def find(tok, lis):\n",
    "        r = []\n",
    "        for i in lis:\n",
    "            if i[0]>=tok[1][0] and i[1]<=tok[1][1]:\n",
    "                r.append(i)\n",
    "                break\n",
    "        b = [lis.index(i) for i in r]\n",
    "        return b\n",
    "    return [(i[0], find(i,tokens['offset_mapping'])) for i in args]\n",
    "\n",
    "\n",
    "def get_names(src):\n",
    "    ret = []\n",
    "    line_lengths = [len(i) for i in src.split('\\n')]\n",
    "    line_lengths = [0] + line_lengths\n",
    "    for i in range(1,len(line_lengths)):\n",
    "        line_lengths[i] += line_lengths[i-1]+1\n",
    "    \n",
    "    try:\n",
    "        for node in ast.walk(ast.parse(src)):\n",
    "            if isinstance(node, ast.arg):\n",
    "                ret.append((node.arg,(line_lengths[node.lineno-1]+node.col_offset, line_lengths[node.lineno-1]+node.end_col_offset)))\n",
    "        return ret\n",
    "    except:\n",
    "        print(\"Could Not process the code\")\n",
    "        return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "outside-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.data = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        data_batch = self.data.iloc[idx, :]\n",
    "        full_sentence, ids = process_elem(data_batch)\n",
    "        return {'input_ids': full_sentence['input_ids'].squeeze().to(device),\n",
    "                    'attention_mask':full_sentence['attention_mask'].squeeze().to(device),\n",
    "                    'input_mask': (ids > 0).squeeze().to(device),\n",
    "                    'ids': ids.squeeze().to(device),\n",
    "                       'idx': idx}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "drawn-posting",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DataLoader(DataDataset(train_ds), batch_size=4,\n",
    "                        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "reverse-chase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, bert, out_dim):\n",
    "        super().__init__()\n",
    "        self.out_dim = out_dim\n",
    "        self.bert = bert\n",
    "        self.dense = nn.Linear(768, out_dim)\n",
    "        nn.init.normal_(self.dense.weight,0,0.02)\n",
    "\n",
    "    def forward(self, a):\n",
    "        \n",
    "        emb = self.bert(a['input_ids'], attention_mask=a['attention_mask'])['last_hidden_state']\n",
    "        out = self.dense(emb)\n",
    "        mask = a['input_mask'].unsqueeze(-1).expand(out.size())\n",
    "        masked = torch.masked_select(out, mask).reshape(len(torch.masked_select(a['ids'], a['input_mask'])),self.out_dim)\n",
    "        return F.softmax(masked)\n",
    "\n",
    "\n",
    "model = Model(bert, len(enc.classes_))\n",
    "model.to(device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "faced-plane",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JITDataDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.data = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        data_batch = self.data.iloc[idx, :]\n",
    "        full_sentence, ids = process_elem(data_batch)\n",
    "        return (full_sentence['input_ids'].squeeze().to(device),\n",
    "                full_sentence['attention_mask'].squeeze().to(device),\n",
    "                (ids > 0).squeeze().to(device),\n",
    "                ids.squeeze().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "subtle-lunch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class JITModel(torch.nn.Module):\n",
    "    def __init__(self, bert, out_dim,dense):\n",
    "        super().__init__()\n",
    "        self.out_dim = out_dim\n",
    "        self.bert = bert\n",
    "#         \n",
    "        self.dense = dense\n",
    "\n",
    "    def forward(self, a,b,c,d):\n",
    "        \n",
    "        emb = self.bert(a, attention_mask=b)[0]\n",
    "        out = self.dense(emb)\n",
    "        mask = c.unsqueeze(-1).expand(out.size())\n",
    "        masked = torch.masked_select(out, mask).reshape(len(torch.masked_select(d, c)),self.out_dim)\n",
    "        return F.softmax(masked)\n",
    "#          masked\n",
    "\n",
    "\n",
    "jitmodel = JITModel(model.bert, len(enc.classes_), model.dense)\n",
    "jitmodel.to(device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "humanitarian-mother",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "compressed-psychiatry",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deadman445/anaconda3/envs/torchdimplom/lib/python3.8/site-packages/transformers/modeling_utils.py:1759: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert all(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Encountering a dict at the output of the tracer might cause the trace to be incorrect, this is only valid if the container structure does not change based on the module's inputs. Consider using a constant container instead (e.g. for `list`, use a `tuple` instead. for `dict`, use a `NamedTuple` instead). If you absolutely need this and know the side effects, pass strict=False to trace() to allow this behavior.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-e06bfc3b6462>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mjitmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mjitmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mjitmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjitmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtraced_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjitmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torchdimplom/lib/python3.8/site-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m         return trace_module(\n\u001b[0m\u001b[1;32m    734\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0;34m\"forward\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torchdimplom/lib/python3.8/site-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"forward\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0mexample_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m             module._c._create_method_from_trace(\n\u001b[0m\u001b[1;32m    935\u001b[0m                 \u001b[0mmethod_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Encountering a dict at the output of the tracer might cause the trace to be incorrect, this is only valid if the container structure does not change based on the module's inputs. Consider using a constant container instead (e.g. for `list`, use a `tuple` instead. for `dict`, use a `NamedTuple` instead). If you absolutely need this and know the side effects, pass strict=False to trace() to allow this behavior."
     ]
    }
   ],
   "source": [
    "cpu = torch.device(\"cpu\")\n",
    "a = next(iter(DataLoader(JITDataDataset(test_ds), batch_size=1, num_workers=0)))\n",
    "jitmodel.to(cpu)\n",
    "jitmodel.bert.to(cpu)\n",
    "jitmodel.bert = torch.jit.trace(jitmodel.bert, (a[0].to(cpu), a[1].to(cpu)))\n",
    "\n",
    "traced_model = torch.jit.script(jitmodel)\n",
    "torch.jit.save(traced_model, \"zvuchit_norm.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bottom-magnet",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "intermediate-editing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b8345df376e484790063d16ca160ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11492 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-acb4d2329173>:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(masked)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bool' 'bool' 'bool' 'Text'] ['UserProfile' 'str' 'callable' 'list']\n",
      "['bool' 'float' 'int' 'bool' 'Text' 'Session' 'bool' 'bool' 'Text'] ['int' 'int' 'int' 'Tensor' 'Tensor' 'list' 'UserProfile' 'iterable'\n",
      " 'sequence']\n",
      "['bool' 'bool' 'bool' 'bool'] ['HomeAssistant' 'str' 'list' 'list']\n",
      "['bool' 'bool' 'bool' 'bool' 'bool'] ['list' 'dict' 'Tensor' 'Tensor' 'float']\n",
      "['bool' 'bool' 'bool' 'bool' 'bool' 'bool'] ['list' 'int' 'str' 'str' 'bool' 'list']\n",
      "['str' 'dict' 'list' 'str'] ['float' 'DataFrame' 'DataFrame' 'Path']\n",
      "['dict' 'dict' 'str' 'int' 'str' 'int'] ['list' 'type' 'str' 'float' 'int' 'int']\n",
      "['dict' 'list' 'str' 'bool' 'dict'] ['dict' 'dict' 'list' 'bool' 'callable']\n",
      "['list' 'bool' 'dict' 'str'] ['iterable' 'bool' 'dict' 'UserProfile']\n",
      "['dict' 'dict' 'dict' 'str' 'str' 'str'] ['UserProfile' 'dict' 'bytes' 'bytes' 'UserProfile' 'UserProfile']\n",
      "['int' 'int' 'int' 'dict' 'str' 'bool' 'int' 'int' 'int'] ['Tensor' 'Tensor' 'int' 'dict' 'Path' 'bool' 'float' 'float' 'int']\n",
      "['str' 'int' 'dict' 'list' 'int'] ['int' 'int' 'dict' 'list' 'float']\n",
      "['str' 'callable' 'dict' 'list' 'bool'] ['Element' 'callable' 'dict' 'Namespace' 'bool']\n",
      "['str' 'bool' 'int' 'int' 'int'] ['Element' 'bool' 'float' 'int' 'int']\n",
      "['dict' 'bool' 'list' 'int' 'list' 'list' 'HttpRequest'] ['User' 'bool' 'ndarray' 'int' 'ndarray' 'ndarray' 'HttpRequest']\n",
      "['HomeAssistant' 'dict' 'dict' 'bool' 'bool' 'bool' 'str'] ['HomeAssistantType' 'ConfigEntry' 'ndarray' 'bool' 'bool' 'bool' 'str']\n",
      "['HomeAssistant' 'dict' 'HttpRequest' 'float' 'int' 'float' 'float'] ['HomeAssistant' 'dict' 'HttpRequest' 'datetime' 'float' 'float' 'float']\n",
      "['dict' 'HomeAssistantType' 'HomeAssistantType' 'dict' 'str'] ['dict' 'HomeAssistant' 'HomeAssistantType' 'ConfigType' 'list']\n",
      "['dict' 'HomeAssistantType' 'bool' 'int'] ['dict' 'HomeAssistantType' 'bool' 'float']\n",
      "['list' 'str' 'str' 'str' 'HomeAssistantType'] ['list' 'str' 'Path' 'Path' 'HomeAssistant']\n",
      "['str' 'bool' 'list' 'callable'] ['str' 'bool' 'list' 'callable']\n",
      "['str' 'list' 'callable' 'bool'] ['str' 'sequence' 'type' 'bool']\n",
      "['callable' 'float' 'int' 'int' 'str'] ['str' 'datetime' 'float' 'float' 'bytes']\n",
      "['list' 'str' 'bool' 'callable' 'bool'] ['list' 'Path' 'bool' 'callable' 'bool']\n",
      "['HomeAssistant' 'bool' 'dict' 'HomeAssistantType' 'str'] ['HomeAssistant' 'list' 'dict' 'HomeAssistantType' 'str']\n",
      "['dict' 'dict' 'HomeAssistantType' 'dict' 'Path'] ['dict' 'dict' 'HomeAssistantType' 'ConfigEntry' 'Path']\n",
      "['UserProfile' 'bool' 'UserProfile' 'str' 'dict'] ['UserProfile' 'bool' 'UserProfile' 'bytes' 'dict']\n",
      "['Message' 'dict' 'dict' 'dict'] ['Message' 'dict' 'dict' 'dict']\n",
      "['Path' 'dict' 'list' 'list' 'Namespace'] ['Path' 'dict' 'list' 'list' 'Namespace']\n",
      "['ndarray' 'int' 'float' 'int' 'int' 'Tensor' 'Realm'] ['Tensor' 'int' 'int' 'int' 'int' 'datetime' 'Realm']\n",
      "['str' 'dict' 'dict' 'str' 'bool' 'dict'] ['str' 'dict' 'dict' 'str' 'bool' 'DataFrame']\n",
      "['str' 'Namespace' 'Context' 'dict'] ['list' 'Namespace' 'Context' 'dict']\n",
      "['str' 'bool' 'list' 'Path' 'Session' 'Path'] ['str' 'bool' 'list' 'str' 'Session' 'Path']\n",
      "['float' 'HomeAssistant' 'str' 'str' 'bool'] ['float' 'HomeAssistant' 'str' 'Path' 'bool']\n",
      "['int' 'int' 'bool' 'HttpRequest' 'Message' 'dict'] ['int' 'int' 'bool' 'Request' 'Message' 'dict']\n",
      "['str' 'Client' 'bool' 'list' 'list'] ['str' 'Client' 'bool' 'sequence' 'dict']\n",
      "['dict' 'HomeAssistant' 'ConfigEntry' 'HttpRequest' 'UserProfile' 'str'] ['bool' 'HomeAssistant' 'ConfigEntry' 'HttpRequest' 'UserProfile' 'dict']\n",
      "['str' 'str' 'int' 'str'] ['str' 'Text' 'float' 'str']\n",
      "['HomeAssistant' 'int' 'str' 'HomeAssistantType'] ['HomeAssistant' 'int' 'str' 'HomeAssistantType']\n",
      "['UserProfile' 'list' 'Session' 'callable' 'type' 'HomeAssistantType'] ['UserProfile' 'list' 'Session' 'callable' 'type' 'HomeAssistantType']\n",
      "['list' 'HttpRequest' 'float' 'float' 'float' 'float' 'UserProfile'] ['list' 'HttpRequest' 'float' 'float' 'float' 'float' 'UserProfile']\n",
      "['int' 'HttpRequest' 'UserProfile' 'list' 'Path' 'dict' 'HttpRequest'] ['int' 'HttpRequest' 'UserProfile' 'list' 'str' 'str' 'HttpRequest']\n",
      "['HttpRequest' 'UserProfile' 'float' 'float' 'float' 'str' 'float' 'bool'] ['HttpRequest' 'UserProfile' 'float' 'str' 'str' 'str' 'float' 'bool']\n",
      "['UserProfile' 'bool' 'UserProfile' 'bool' 'bool' 'Tensor'] ['User' 'bool' 'UserProfile' 'bool' 'bool' 'Tensor']\n",
      "['list' 'list' 'HomeAssistantType' 'dict' 'HomeAssistantType'\n",
      " 'ConfigEntry'] ['list' 'list' 'HomeAssistant' 'ConfigType' 'HomeAssistant' 'ConfigEntry']\n",
      "['HomeAssistantType' 'Client' 'HomeAssistantType' 'ConfigEntry' 'float'] ['HomeAssistant' 'Client' 'HomeAssistantType' 'ConfigEntry' 'float']\n",
      "['float' 'str' 'UserProfile' 'list' 'list'] ['list' 'str' 'UserProfile' 'list' 'iterable']\n",
      "['HomeAssistant' 'ConfigEntry' 'Tensor' 'dict' 'dict'] ['HomeAssistant' 'ConfigEntry' 'Tensor' 'bool' 'dict']\n",
      "['Tensor' 'list' 'callable' 'UserProfile'] ['ndarray' 'list' 'bool' 'UserProfile']\n",
      "['callable' 'float' 'float' 'HomeAssistant' 'ConfigType' 'Tensor' 'bool'\n",
      " 'str'] ['callable' 'float' 'float' 'HomeAssistantType' 'ConfigType' 'Tensor'\n",
      " 'bytes' 'str']\n",
      "['str' 'dict' 'dict' 'Path' 'Realm'] ['str' 'Message' 'Message' 'Path' 'Realm']\n",
      "['dict' 'str' 'HomeAssistant' 'ConfigEntry' 'callable' 'HomeAssistant'\n",
      " 'list'] ['str' 'str' 'HomeAssistant' 'ConfigEntry' 'callable' 'HomeAssistantType'\n",
      " 'iterable']\n",
      "['int' 'HttpRequest' 'str' 'float' 'bool' 'bool'] ['int' 'HttpRequest' 'Text' 'float' 'str' 'bool']\n",
      "['bool' 'float' 'UserProfile' 'int'] ['bool' 'float' 'UserProfile' 'int']\n",
      "['str' 'dict' 'callable' 'int'] ['str' 'dict' 'callable' 'int']\n",
      "['callable' 'float' 'HomeAssistantType' 'dict' 'str'] ['callable' 'float' 'HomeAssistantType' 'dict' 'str']\n",
      "['dict' 'str' 'float' 'str' 'str' 'bool'] ['dict' 'Path' 'float' 'str' 'str' 'bool']\n",
      "['int' 'int' 'list' 'type' 'Request'] ['int' 'int' 'list' 'type' 'Request']\n",
      "['list' 'Client' 'bool' 'Context'] ['sequence' 'Client' 'bool' 'Context']\n",
      "['float' 'Realm' 'callable' 'list' 'float'] ['ndarray' 'Realm' 'callable' 'sequence' 'int']\n",
      "['HomeAssistantType' 'float' 'bool' 'dict' 'str'] ['HomeAssistantType' 'float' 'bool' 'dict' 'str']\n",
      "['HttpRequest' 'UserProfile' 'iterable' 'float' 'ndarray'] ['HttpRequest' 'UserProfile' 'iterable' 'int' 'ndarray']\n",
      "['float' 'Path' 'dict' 'HttpRequest' 'UserProfile' 'bool'] ['int' 'Path' 'dict' 'HttpRequest' 'UserProfile' 'bool']\n",
      "['HomeAssistantType' 'dict' 'HomeAssistantType' 'Context'] ['HomeAssistantType' 'list' 'HomeAssistant' 'list']\n",
      "['bool' 'HomeAssistant' 'dict' 'int' 'list' 'bool'] ['bool' 'HomeAssistant' 'dict' 'int' 'list' 'bool']\n",
      "['Message' 'list' 'list' 'bool' 'HomeAssistant' 'float' 'float'] ['Message' 'list' 'ndarray' 'bool' 'HomeAssistant' 'float' 'float']\n",
      "['float' 'bytes' 'int' 'dict'] ['float' 'bytes' 'int' 'dict']\n",
      "['int' 'list' 'dict' 'dict' 'dict'] ['float' 'list' 'list' 'dict' 'dict']\n",
      "['bytes' 'bytes' 'Client' 'bool' 'list'] ['bytes' 'bytes' 'Client' 'bool' 'ndarray']\n",
      "['str' 'int' 'callable' 'callable' 'Element' 'dict'] ['list' 'int' 'callable' 'callable' 'Element' 'dict']\n",
      "['str' 'str' 'bool' 'dict' 'dict'] ['int' 'int' 'bool' 'dict' 'dict']\n",
      "['dict' 'dict' 'HomeAssistant' 'Path' 'bool'] ['dict' 'dict' 'HomeAssistant' 'Path' 'bool']\n",
      "['int' 'dict' 'list' 'int' 'HomeAssistantType' 'dict'] ['int' 'dict' 'list' 'int' 'HomeAssistantType' 'ConfigType']\n",
      "['Path' 'Path' 'bool' 'float' 'bool' 'int' 'Message'] ['Path' 'Path' 'bool' 'float' 'bool' 'int' 'callable']\n",
      "['list' 'str' 'str' 'str' 'callable' 'HttpRequest' 'UserProfile'] ['list' 'str' 'str' 'str' 'callable' 'HttpRequest' 'UserProfile']\n",
      "['dict' 'dict' 'iterable' 'iterable' 'callable' 'int'] ['dict' 'list' 'iterable' 'iterable' 'callable' 'int']\n",
      "['dict' 'Tensor' 'Tensor' 'HttpRequest' 'UserProfile' 'bool' 'UserProfile'] ['dict' 'Tensor' 'Tensor' 'HttpRequest' 'UserProfile' 'bool' 'UserProfile']\n",
      "['ndarray' 'Tensor' 'ndarray' 'Session'] ['float' 'Tensor' 'Tensor' 'Session']\n",
      "['int' 'float' 'float' 'Namespace' 'iterable'] ['int' 'float' 'float' 'Namespace' 'iterable']\n",
      "['dict' 'list' 'int' 'ndarray' 'callable'] ['dict' 'iterable' 'int' 'ndarray' 'callable']\n",
      "['str' 'int' 'str' 'str' 'UserProfile' 'list' 'dict' 'dict'] ['str' 'str' 'str' 'str' 'UserProfile' 'dict' 'dict' 'dict']\n",
      "['list' 'User' 'int' 'UserProfile'] ['list' 'User' 'int' 'UserProfile']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['float' 'float' 'float' 'float' 'float' 'float' 'Path' 'str'] ['float' 'float' 'float' 'float' 'float' 'float' 'Path' 'Text']\n",
      "['ndarray' 'HttpRequest' 'HomeAssistant' 'float' 'float'] ['ndarray' 'HttpRequest' 'HomeAssistantType' 'float' 'float']\n",
      "['str' 'Path' 'str' 'Tensor' 'Tensor' 'bool'] ['str' 'Path' 'str' 'Tensor' 'Tensor' 'bool']\n",
      "['dict' 'dict' 'Namespace' 'list' 'float' 'int' 'int'] ['sequence' 'dict' 'Namespace' 'list' 'int' 'int' 'int']\n",
      "['dict' 'int' 'callable' 'iterable' 'iterable' 'bool' 'bool' 'bool'] ['dict' 'int' 'callable' 'iterable' 'iterable' 'bool' 'bool' 'bool']\n",
      "['str' 'HomeAssistantType' 'list' 'dict'] ['str' 'HomeAssistant' 'sequence' 'dict']\n",
      "['bool' 'bool' 'list' 'ndarray' 'ndarray'] ['bool' 'bool' 'iterable' 'ndarray' 'ndarray']\n",
      "['int' 'int' 'HttpRequest' 'dict' 'callable' 'Tensor' 'Tensor'] ['int' 'int' 'HttpRequest' 'dict' 'callable' 'Tensor' 'Tensor']\n",
      "['float' 'float' 'float' 'bytes' 'Path' 'type'] ['int' 'int' 'int' 'bytes' 'Path' 'type']\n",
      "['HttpRequest' 'UserProfile' 'HomeAssistantType' 'Tensor' 'Tensor' 'bool'\n",
      " 'list'] ['HttpRequest' 'UserProfile' 'HomeAssistantType' 'Tensor' 'Tensor' 'float'\n",
      " 'list']\n",
      "['Realm' 'HomeAssistantType' 'ConfigType' 'int' 'dict'] ['Realm' 'HomeAssistantType' 'ConfigType' 'int' 'dict']\n",
      "['Namespace' 'dict' 'dict' 'ndarray' 'bool'] ['Namespace' 'dict' 'dict' 'ndarray' 'bool']\n",
      "['str' 'HomeAssistant' 'ConfigEntry' 'bool' 'bool' 'UserProfile'] ['int' 'HomeAssistant' 'ConfigEntry' 'bool' 'bool' 'UserProfile']\n",
      "['callable' 'HomeAssistant' 'ConfigEntry' 'int' 'Element'] ['callable' 'HomeAssistantType' 'ConfigEntry' 'int' 'Node']\n",
      "['list' 'list' 'HomeAssistant' 'int' 'DataFrame'] ['iterable' 'dict' 'HomeAssistant' 'int' 'DataFrame']\n",
      "['Namespace' 'int' 'UserProfile' 'dict' 'datetime'] ['Namespace' 'int' 'UserProfile' 'dict' 'datetime']\n",
      "['callable' 'dict' 'HomeAssistant' 'dict' 'dict'] ['callable' 'dict' 'HomeAssistant' 'dict' 'dict']\n",
      "['Path' 'Path' 'Path' 'Request' 'bool'] ['Path' 'Path' 'Path' 'Request' 'bool']\n",
      "['str' 'str' 'int' 'HomeAssistantType' 'str'] ['Path' 'Text' 'int' 'HomeAssistant' 'str']\n",
      "['list' 'int' 'Client' 'HomeAssistantType' 'bool' 'str'] ['list' 'list' 'Client' 'HomeAssistantType' 'bool' 'bool']\n",
      "['datetime' 'type' 'HttpRequest' 'UserProfile' 'dict' 'HomeAssistant'] ['datetime' 'type' 'HttpRequest' 'UserProfile' 'dict' 'HomeAssistant']\n",
      "['str' 'bytes' 'ndarray' 'HttpRequest'] ['str' 'bytes' 'ndarray' 'HttpRequest']\n",
      "['bool' 'str' 'dict' 'list' 'str' 'str'] ['bool' 'str' 'mapping' 'str' 'str' 'str']\n",
      "['datetime' 'Node' 'Namespace' 'list'] ['datetime' 'type' 'Namespace' 'list']\n",
      "['dict' 'Session' 'HttpRequest' 'UserProfile' 'dict' 'dict'] ['dict' 'Session' 'HttpRequest' 'UserProfile' 'dict' 'iterable']\n",
      "['str' 'dict' 'Context' 'Path'] ['str' 'dict' 'Context' 'Path']\n",
      "['str' 'list' 'list' 'ndarray' 'float' 'str'] ['str' 'list' 'list' 'ndarray' 'float' 'dict']\n",
      "['float' 'list' 'int' 'bool'] ['float' 'list' 'dict' 'bool']\n",
      "['str' 'dict' 'callable' 'list' 'dict' 'list' 'list'] ['str' 'dict' 'callable' 'list' 'dict' 'iterable' 'list']\n",
      "['Context' 'float' 'float' 'float' 'float' 'type'] ['Context' 'ndarray' 'ndarray' 'float' 'float' 'type']\n",
      "['str' 'str' 'Client' 'list' 'dict' 'int'] ['str' 'str' 'Client' 'list' 'dict' 'int']\n",
      "['dict' 'bool' 'Path' 'Path' 'Request'] ['dict' 'bool' 'Path' 'Path' 'Request']\n",
      "['HomeAssistantType' 'ConfigType' 'callable' 'list' 'float' 'float' 'bool'\n",
      " 'UserProfile'] ['HomeAssistantType' 'ConfigType' 'callable' 'sequence' 'float' 'float'\n",
      " 'bool' 'UserProfile']\n",
      "['Tensor' 'Tensor' 'float' 'float' 'list' 'Tensor'] ['Tensor' 'Tensor' 'float' 'float' 'list' 'Tensor']\n",
      "['iterable' 'iterable' 'int' 'ndarray' 'str'] ['iterable' 'iterable' 'int' 'ndarray' 'int']\n",
      "['dict' 'list' 'dict' 'int' 'int' 'int' 'float'] ['dict' 'dict' 'dict' 'int' 'int' 'int' 'int']\n",
      "['list' 'HomeAssistant' 'HomeAssistant' 'callable' 'str'] ['list' 'HomeAssistant' 'HomeAssistant' 'callable' 'str']\n",
      "['bool' 'ndarray' 'ndarray' 'bool' 'list'] ['bool' 'ndarray' 'ndarray' 'bool' 'list']\n",
      "['int' 'int' 'int' 'bool' 'str' 'bool' 'bool' 'float' 'str'] ['int' 'int' 'int' 'bool' 'Path' 'bool' 'bool' 'float' 'str']\n",
      "['int' 'int' 'list' 'bool' 'HttpRequest' 'str' 'str'] ['int' 'int' 'set' 'bool' 'HttpRequest' 'str' 'str']\n",
      "['int' 'Path' 'list' 'float' 'int' 'mapping'] ['float' 'Path' 'list' 'float' 'int' 'mapping']\n",
      "['Request' 'list' 'dict' 'ndarray' 'float' 'float' 'float' 'float'] ['Request' 'list' 'dict' 'ndarray' 'float' 'float' 'float' 'float']\n",
      "['HomeAssistant' 'ConfigType' 'bool' 'mapping' 'bool'] ['HomeAssistant' 'dict' 'bool' 'mapping' 'bool']\n",
      "['callable' 'callable' 'list' 'list' 'str' 'Path'] ['callable' 'callable' 'list' 'list' 'Path' 'Path']\n",
      "['Namespace' 'list' 'list' 'bool' 'HomeAssistant'] ['Namespace' 'list' 'list' 'bool' 'HomeAssistant']\n",
      "['HomeAssistantType' 'str' 'str' 'str' 'list'] ['HomeAssistant' 'Text' 'str' 'str' 'list']\n",
      "['dict' 'list' 'list' 'str'] ['mapping' 'list' 'list' 'Text']\n",
      "['bool' 'bool' 'str' 'list' 'list' 'bool'] ['bool' 'bool' 'str' 'list' 'iterable' 'bool']\n",
      "['str' 'str' 'str' 'str' 'HomeAssistantType' 'dict' 'bool' 'list'] ['str' 'str' 'str' 'str' 'HomeAssistantType' 'dict' 'bool' 'sequence']\n",
      "['str' 'bool' 'HomeAssistantType' 'int' 'list'] ['int' 'bool' 'HomeAssistant' 'int' 'list']\n",
      "['Path' 'dict' 'Tensor' 'int' 'HttpRequest' 'UserProfile'] ['Path' 'dict' 'Tensor' 'int' 'HttpRequest' 'UserProfile']\n",
      "['list' 'bool' 'bool' 'bool' 'dict' 'list' 'Path'] ['list' 'bool' 'bool' 'bool' 'dict' 'list' 'Path']\n",
      "['HttpRequest' 'UserProfile' 'str' 'bytes' 'dict' 'Tensor'] ['HttpRequest' 'UserProfile' 'str' 'bytes' 'mapping' 'ndarray']\n",
      "['ndarray' 'bool' 'Path' 'float' 'HomeAssistant' 'ConfigEntry'] ['ndarray' 'bool' 'Path' 'float' 'HomeAssistant' 'ConfigEntry']\n",
      "['list' 'list' 'list' 'bytes' 'bool' 'bool' 'float'] ['list' 'list' 'list' 'bytes' 'bool' 'bool' 'float']\n",
      "['float' 'HomeAssistantType' 'str' 'bool' 'list'] ['float' 'HomeAssistantType' 'str' 'bool' 'list']\n",
      "['Realm' 'HttpRequest' 'DataFrame' 'float' 'float'] ['Realm' 'HttpRequest' 'DataFrame' 'float' 'float']\n",
      "['Request' 'float' 'float' 'int' 'str' 'list'] ['Request' 'float' 'float' 'float' 'str' 'list']\n",
      "['callable' 'dict' 'list' 'list' 'dict' 'dict' 'dict'] ['callable' 'dict' 'list' 'list' 'dict' 'dict' 'dict']\n",
      "['dict' 'iterable' 'callable' 'mapping' 'HomeAssistant'] ['dict' 'iterable' 'callable' 'mapping' 'HomeAssistantType']\n",
      "['str' 'bool' 'bool' 'bool' 'str' 'dict' 'bool' 'Tensor' 'float' 'float'\n",
      " 'HomeAssistantType' 'ConfigEntry' 'callable'] ['int' 'bool' 'bool' 'bool' 'str' 'str' 'str' 'Tensor' 'float' 'float'\n",
      " 'HomeAssistant' 'ConfigEntry' 'callable']\n",
      "['Namespace' 'int' 'float' 'int' 'str' 'str' 'int'] ['Namespace' 'int' 'int' 'int' 'str' 'str' 'int']\n",
      "['callable' 'HomeAssistantType' 'DataFrame' 'float' 'float' 'float'] ['callable' 'HomeAssistant' 'DataFrame' 'float' 'float' 'float']\n",
      "['callable' 'bytes' 'ndarray' 'datetime'] ['callable' 'bytes' 'ndarray' 'datetime']\n",
      "['Session' 'HomeAssistantType' 'int' 'int' 'str'] ['Session' 'HomeAssistant' 'int' 'int' 'str']\n",
      "['User' 'callable' 'int' 'Message'] ['User' 'list' 'int' 'mapping']\n",
      "['float' 'dict' 'HttpRequest' 'HttpRequest' 'UserProfile'] ['float' 'dict' 'HttpRequest' 'HttpRequest' 'UserProfile']\n",
      "['Tensor' 'UserProfile' 'list' 'dict' 'Realm'] ['Tensor' 'UserProfile' 'list' 'dict' 'Realm']\n",
      "['Namespace' 'int' 'int' 'int' 'list' 'float' 'list' 'bool'] ['Namespace' 'int' 'int' 'int' 'iterable' 'float' 'list' 'bool']\n",
      "['int' 'UserProfile' 'float' 'float' 'int' 'callable'] ['int' 'UserProfile' 'float' 'float' 'float' 'callable']\n",
      "['bytes' 'ndarray' 'HomeAssistant' 'list'] ['bytes' 'ndarray' 'HomeAssistant' 'list']\n",
      "['Message' 'iterable' 'DataFrame' 'Path' 'bool'] ['Message' 'iterable' 'DataFrame' 'Path' 'bool']\n",
      "['Client' 'HttpRequest' 'dict' 'dict' 'dict' 'HttpRequest' 'UserProfile'\n",
      " 'dict'] ['Client' 'HttpRequest' 'dict' 'dict' 'dict' 'HttpRequest' 'UserProfile'\n",
      " 'dict']\n",
      "['str' 'Client' 'str' 'str' 'int' 'int' 'list'] ['Text' 'Client' 'str' 'str' 'int' 'float' 'list']\n",
      "['ndarray' 'bool' 'HomeAssistant' 'dict' 'HttpRequest' 'UserProfile'\n",
      " 'dict' 'HomeAssistantType'] ['ndarray' 'bool' 'HomeAssistant' 'dict' 'HttpRequest' 'UserProfile'\n",
      " 'dict' 'HomeAssistantType']\n",
      "['Path' 'ndarray' 'ndarray' 'Realm' 'Element'] ['str' 'ndarray' 'ndarray' 'Realm' 'str']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['str' 'bool' 'ndarray' 'int' 'int' 'int' 'int' 'str'] ['int' 'bool' 'ndarray' 'int' 'int' 'int' 'int' 'Path']\n",
      "['list' 'list' 'list' 'bool' 'Path' 'dict' 'int'] ['list' 'list' 'list' 'bool' 'Path' 'dict' 'int']\n",
      "['str' 'list' 'str' 'str'] ['str' 'list' 'list' 'str']\n",
      "['User' 'bool' 'bool' 'str' 'str' 'str' 'int' 'int'] ['User' 'bool' 'bool' 'str' 'str' 'str' 'int' 'str']\n",
      "['iterable' 'list' 'str' 'str' 'Namespace'] ['iterable' 'list' 'list' 'list' 'Namespace']\n",
      "['Tensor' 'dict' 'str' 'str' 'list' 'bool'] ['ndarray' 'dict' 'str' 'list' 'list' 'bool']\n",
      "['dict' 'list' 'HomeAssistant' 'dict'] ['dict' 'list' 'HomeAssistant' 'dict']\n",
      "['float' 'str' 'str' 'HomeAssistant' 'Tensor'] ['float' 'dict' 'str' 'HomeAssistant' 'Tensor']\n",
      "['str' 'int' 'list' 'bytes' 'int'] ['str' 'int' 'sequence' 'bytes' 'bytes']\n",
      "['HomeAssistant' 'dict' 'bool' 'iterable'] ['HomeAssistantType' 'dict' 'bool' 'iterable']\n",
      "['list' 'Context' 'bool' 'UserProfile' 'iterable' 'list'] ['list' 'Context' 'bool' 'UserProfile' 'iterable' 'iterable']\n",
      "['User' 'list' 'list' 'float'] ['User' 'sequence' 'list' 'float']\n",
      "['Path' 'int' 'int' 'ndarray' 'Context'] ['Path' 'int' 'int' 'ndarray' 'Context']\n",
      "['HomeAssistantType' 'dict' 'dict' 'list'] ['HomeAssistantType' 'dict' 'dict' 'list']\n",
      "['list' 'Path' 'dict' 'list' 'list'] ['list' 'Path' 'dict' 'list' 'list']\n",
      "['float' 'bool' 'int' 'int' 'int' 'Path'] ['float' 'bool' 'int' 'int' 'int' 'Path']\n",
      "['str' 'list' 'str' 'str' 'UserProfile' 'HomeAssistant' 'dict'] ['str' 'list' 'str' 'str' 'UserProfile' 'HomeAssistant' 'dict']\n",
      "['HomeAssistantType' 'int' 'HomeAssistantType' 'ConfigEntry' 'dict'] ['HomeAssistantType' 'float' 'HomeAssistant' 'ConfigEntry' 'dict']\n",
      "['str' 'dict' 'int' 'int' 'dict'] ['str' 'dict' 'int' 'int' 'dict']\n",
      "['type' 'int' 'Node' 'HttpRequest' 'dict'] ['type' 'int' 'Node' 'HttpRequest' 'dict']\n",
      "['list' 'callable' 'callable' 'callable' 'HttpRequest' 'callable'] ['list' 'callable' 'callable' 'callable' 'Request' 'callable']\n",
      "['DataFrame' 'int' 'int' 'list' 'float' 'float' 'float' 'int'] ['DataFrame' 'int' 'int' 'list' 'int' 'int' 'int' 'int']\n",
      "['HomeAssistantType' 'HomeAssistant' 'HttpRequest' 'dict'] ['HomeAssistant' 'HomeAssistant' 'HttpRequest' 'dict']\n",
      "['list' 'str' 'Tensor' 'list' 'float' 'Namespace'] ['list' 'str' 'Tensor' 'list' 'float' 'Namespace']\n",
      "['list' 'DataFrame' 'int' 'str' 'Path' 'dict'] ['sequence' 'DataFrame' 'str' 'str' 'Path' 'dict']\n",
      "['HttpRequest' 'UserProfile' 'Path' 'callable' 'int'] ['HttpRequest' 'UserProfile' 'Path' 'callable' 'int']\n",
      "['dict' 'bool' 'dict' 'dict'] ['dict' 'bool' 'dict' 'dict']\n",
      "['int' 'bytes' 'list' 'list' 'list'] ['int' 'bytes' 'list' 'list' 'list']\n",
      "['HttpRequest' 'Request' 'str' 'str' 'dict'] ['HttpRequest' 'Request' 'str' 'str' 'dict']\n",
      "['str' 'str' 'str' 'str' 'bool' 'bool' 'ndarray' 'HomeAssistant' 'dict'] ['str' 'str' 'str' 'str' 'bool' 'bool' 'ndarray' 'HomeAssistantType'\n",
      " 'dict']\n",
      "['str' 'str' 'Realm' 'Realm' 'callable' 'HomeAssistant' 'dict'] ['str' 'str' 'Realm' 'Realm' 'callable' 'HomeAssistantType' 'dict']\n",
      "['Tensor' 'ndarray' 'type' 'HomeAssistantType'] ['Tensor' 'ndarray' 'type' 'HomeAssistantType']\n",
      "['HomeAssistant' 'dict' 'HttpRequest' 'UserProfile' 'list' 'dict'] ['HomeAssistant' 'dict' 'HttpRequest' 'UserProfile' 'sequence' 'dict']\n",
      "['Tensor' 'HttpRequest' 'UserProfile' 'dict' 'float' 'str'] ['Tensor' 'HttpRequest' 'UserProfile' 'dict' 'int' 'str']\n",
      "['dict' 'UserProfile' 'dict' 'list' 'bool' 'Namespace'] ['dict' 'UserProfile' 'str' 'str' 'bool' 'Namespace']\n",
      "['bool' 'dict' 'HomeAssistant' 'list' 'list' 'list'] ['bool' 'dict' 'HomeAssistant' 'list' 'list' 'sequence']\n",
      "['Path' 'dict' 'list' 'DataFrame' 'bool'] ['Path' 'dict' 'iterable' 'ndarray' 'bool']\n",
      "['Session' 'list' 'list' 'HttpRequest' 'UserProfile' 'bool'] ['Session' 'list' 'list' 'HttpRequest' 'UserProfile' 'bool']\n",
      "['dict' 'int' 'ndarray' 'int' 'int' 'dict' 'bool' 'bool'] ['dict' 'int' 'ndarray' 'int' 'int' 'dict' 'bool' 'bool']\n",
      "['str' 'HttpRequest' 'UserProfile' 'dict' 'list' 'list' 'str' 'str'\n",
      " 'Namespace'] ['str' 'HttpRequest' 'UserProfile' 'dict' 'list' 'list' 'str' 'str'\n",
      " 'Namespace']\n",
      "['int' 'int' 'bool' 'bool' 'list' 'DataFrame' 'dict' 'bool' 'Path'] ['int' 'int' 'bool' 'bool' 'iterable' 'Path' 'dict' 'bool' 'Path']\n",
      "['callable' 'dict' 'float' 'str'] ['callable' 'dict' 'float' 'str']\n",
      "['mapping' 'Namespace' 'DataFrame' 'dict'] ['mapping' 'Namespace' 'DataFrame' 'dict']\n",
      "['float' 'float' 'bool' 'UserProfile' 'list' 'ndarray' 'float' 'int'] ['float' 'float' 'bool' 'UserProfile' 'list' 'ndarray' 'float' 'int']\n",
      "['UserProfile' 'float' 'float' 'bool' 'list' 'str'] ['UserProfile' 'float' 'float' 'bool' 'list' 'str']\n",
      "['Tensor' 'dict' 'bool' 'int' 'ndarray' 'int'] ['Tensor' 'str' 'str' 'int' 'ndarray' 'int']\n",
      "['str' 'dict' 'list' 'HomeAssistant' 'str' 'list' 'int'] ['callable' 'ndarray' 'ndarray' 'HomeAssistant' 'str' 'list' 'int']\n",
      "['DataFrame' 'callable' 'callable' 'callable' 'Realm'] ['DataFrame' 'callable' 'callable' 'type' 'Realm']\n",
      "['dict' 'list' 'Path' 'list'] ['dict' 'iterable' 'Path' 'dict']\n",
      "['callable' 'list' 'Client' 'dict'] ['callable' 'list' 'Client' 'dict']\n",
      "['list' 'dict' 'bool' 'bool' 'bool' 'str'] ['list' 'dict' 'bool' 'bool' 'bool' 'Text']\n",
      "['str' 'str' 'int' 'float' 'int' 'list'] ['str' 'str' 'float' 'float' 'int' 'ndarray']\n",
      "['iterable' 'UserProfile' 'list' 'Tensor' 'callable' 'callable' 'callable'] ['iterable' 'UserProfile' 'list' 'Tensor' 'callable' 'callable' 'callable']\n",
      "['ndarray' 'ndarray' 'int' 'str' 'list' 'str'] ['ndarray' 'ndarray' 'int' 'str' 'list' 'bytes']\n",
      "['Path' 'Path' 'bool' 'iterable' 'callable' 'Node'] ['Path' 'Path' 'bool' 'iterable' 'callable' 'Node']\n",
      "['bytes' 'callable' 'float' 'dict'] ['str' 'callable' 'float' 'str']\n",
      "['int' 'str' 'dict' 'dict' 'HomeAssistant' 'float'] ['str' 'str' 'dict' 'dict' 'HomeAssistant' 'float']\n",
      "['bool' 'HomeAssistantType' 'list' 'bytes' 'str' 'str'] ['bool' 'HomeAssistantType' 'list' 'bytes' 'str' 'str']\n",
      "['int' 'type' 'str' 'list' 'list'] ['int' 'type' 'str' 'Tensor' 'Tensor']\n",
      "['list' 'list' 'list' 'list' 'list'] ['list' 'list' 'iterable' 'sequence' 'dict']\n",
      "['dict' 'Namespace' 'HomeAssistantType' 'HttpRequest'] ['dict' 'Namespace' 'HomeAssistantType' 'HttpRequest']\n",
      "['list' 'dict' 'list' 'list' 'Path'] ['list' 'dict' 'list' 'sequence' 'Path']\n",
      "['list' 'str' 'HttpRequest' 'UserProfile'] ['list' 'str' 'HttpRequest' 'UserProfile']\n",
      "['ndarray' 'list' 'dict' 'dict'] ['list' 'list' 'dict' 'dict']\n",
      "['HttpRequest' 'str' 'str' 'list' 'list' 'UserProfile' 'str'] ['HttpRequest' 'str' 'str' 'sequence' 'list' 'UserProfile' 'str']\n",
      "['str' 'list' 'HttpRequest' 'UserProfile' 'dict' 'Tensor'] ['str' 'list' 'HttpRequest' 'UserProfile' 'dict' 'Tensor']\n",
      "['str' 'HttpRequest' 'list' 'bool' 'bool' 'bool'] ['str' 'HttpRequest' 'set' 'bool' 'bool' 'bool']\n",
      "['Node' 'bytes' 'int' 'UserProfile'] ['Node' 'bytes' 'int' 'UserProfile']\n",
      "['dict' 'HttpRequest' 'UserProfile' 'dict' 'list' 'list' 'int'] ['dict' 'HttpRequest' 'UserProfile' 'dict' 'list' 'iterable' 'int']\n",
      "['HttpRequest' 'str' 'Node' 'callable'] ['HttpRequest' 'str' 'Node' 'dict']\n",
      "['int' 'str' 'HomeAssistant' 'HomeAssistant' 'ConfigEntry' 'int'] ['str' 'str' 'HomeAssistant' 'HomeAssistantType' 'ConfigEntry' 'dict']\n",
      "['Tensor' 'int' 'int' 'UserProfile' 'iterable' 'int' 'dict'] ['Tensor' 'int' 'int' 'UserProfile' 'iterable' 'int' 'dict']\n"
     ]
    }
   ],
   "source": [
    "opti = torch.optim.Adam(model.parameters(), lr = 5e-7)\n",
    "pbar = tqdm(total=len(train))\n",
    "losses = []\n",
    "accuracy = []\n",
    "for i,a in enumerate(train):\n",
    "    out = model.forward(a)\n",
    "    labels = torch.masked_select(a['ids'], a['input_mask'])\n",
    "\n",
    "    loss = F.nll_loss(torch.log(out), labels)\n",
    "    if i % 50==0:\n",
    "        print(enc.inverse_transform(torch.argmax(out.cpu(), dim=1)), enc.inverse_transform(labels.cpu()))\n",
    "\n",
    "    if torch.isnan(loss):\n",
    "#         print(a)\n",
    "        pass\n",
    "    else:\n",
    "        loss.backward()\n",
    "        accuracy.append(sum(torch.argmax(out.detach(), dim=1) == labels)/len(labels))\n",
    "        losses.append(loss.detach())\n",
    "        opti.step()\n",
    "    if i % 1 ==0:\n",
    "        pbar.set_description(f\"Loss : { sum(losses)/len(losses)}, acc: {sum(accuracy)/len(accuracy)}\")\n",
    "    pbar.update(1)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "double-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_av = lambda x : sum(x)/len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "russian-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = DataLoader(DataDataset(test_ds), batch_size=1, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "olive-migration",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5cad6b453404eedb90ea1b5e3bc9e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-acb4d2329173>:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(masked)\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(total=len(test))\n",
    "test_top_5s = []\n",
    "test_accuracy = []\n",
    "test_losses = []\n",
    "test_true = []\n",
    "test_pred = []\n",
    "for i,a in enumerate(test):\n",
    "    out = model.forward(a)\n",
    "    labels = torch.masked_select(a['ids'], a['input_mask'])\n",
    "    loss = F.nll_loss(torch.log(out), labels)\n",
    "\n",
    "    if torch.isnan(loss):\n",
    "#         print(a)\n",
    "        pass\n",
    "    else:\n",
    "        test_pred = test_pred + list(enc.inverse_transform(torch.argmax(out.cpu(), dim=1)))\n",
    "        test_true = test_true + list(enc.inverse_transform(labels.cpu()))\n",
    "        test_accuracy.append(sum(torch.argmax(out, dim=1) == labels).detach()/len(labels))\n",
    "        test_losses.append(loss.detach())\n",
    "        top5s = torch.topk(out, 5).indices\n",
    "        correct_top5 = 0\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] in top5s[i]:\n",
    "                correct_top5 += 1\n",
    "        test_top_5s.append(correct_top5/len(labels))\n",
    "    \n",
    "        if i % 20 ==0:\n",
    "            pbar.set_description(f\"Loss : { pr_av(test_losses)}, acc: {pr_av(test_accuracy)}, top5s: {pr_av(test_top_5s)}\")\n",
    "    pbar.update(1)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fewer-seventh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "           Client       1.00      1.00      1.00         2\n",
      "      ConfigEntry       0.97      1.00      0.99        39\n",
      "       ConfigType       0.96      0.98      0.97        54\n",
      "          Context       0.98      1.00      0.99        85\n",
      "        DataFrame       0.92      0.89      0.90       105\n",
      "          Element       0.33      1.00      0.50         1\n",
      "    HomeAssistant       0.72      0.88      0.80       130\n",
      "HomeAssistantType       0.91      0.78      0.84       198\n",
      "      HttpRequest       0.97      0.88      0.92       286\n",
      "          Message       0.97      0.97      0.97        75\n",
      "        Namespace       1.00      0.91      0.95        78\n",
      "             Node       0.91      0.97      0.94        31\n",
      "             Path       0.73      0.92      0.81       178\n",
      "          Request       0.57      0.85      0.68        60\n",
      "          Session       0.80      0.89      0.84         9\n",
      "           Tensor       0.70      0.91      0.79       124\n",
      "             Text       0.00      0.00      0.00         2\n",
      "             User       0.95      0.75      0.84        53\n",
      "      UserProfile       0.00      0.00      0.00         0\n",
      "             bool       0.97      0.94      0.96       648\n",
      "            bytes       0.80      0.80      0.80       161\n",
      "         callable       0.85      0.89      0.87       313\n",
      "         datetime       0.98      0.94      0.96        69\n",
      "             dict       0.87      0.81      0.84       691\n",
      "            float       0.85      0.90      0.87       481\n",
      "              int       0.84      0.85      0.84       773\n",
      "         iterable       0.66      0.48      0.56       212\n",
      "             list       0.65      0.86      0.74       836\n",
      "          mapping       0.33      0.09      0.14        11\n",
      "          ndarray       0.49      0.78      0.60        58\n",
      "         sequence       0.29      0.01      0.03       139\n",
      "              set       0.86      0.11      0.19       110\n",
      "              str       0.85      0.75      0.79       812\n",
      "             type       0.66      0.86      0.75        98\n",
      "\n",
      "         accuracy                           0.82      6922\n",
      "        macro avg       0.75      0.75      0.73      6922\n",
      "     weighted avg       0.82      0.82      0.81      6922\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deadman445/anaconda3/envs/torchdimplom/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/deadman445/anaconda3/envs/torchdimplom/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/deadman445/anaconda3/envs/torchdimplom/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/deadman445/anaconda3/envs/torchdimplom/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/deadman445/anaconda3/envs/torchdimplom/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/deadman445/anaconda3/envs/torchdimplom/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "\n",
    "print(classification_report(test_true, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-oxygen",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "delayed-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def transform_to_model(method, dev):\n",
    "    data_batch={'body':method, 'labels':[1]*len(get_names(method))}\n",
    "    full_sentence, ids = process_elem(data_batch)\n",
    "    return (full_sentence['input_ids'].to(dev),\n",
    "            full_sentence['attention_mask'].to(dev),\n",
    "            (ids > 0).to(dev),\n",
    "            ids.to(dev))\n",
    "\n",
    "def infer(model, method):\n",
    "    a = transform_to_model(method, device)\n",
    "    out = model.forward(a)\n",
    "    ret = enc.inverse_transform(torch.argmax(out.cpu(), dim=1))\n",
    "    top5s = torch.topk(out, 5).indices.cpu()\n",
    "#     for i in top5s:\n",
    "#         print(\"Top5: \",enc.inverse_transform(i))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "occupied-camel",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-1c45dc996275>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0mn\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0mn\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-63bbcba0490d>\u001b[0m in \u001b[0;36minfer\u001b[0;34m(model, method)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_to_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtop5s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-acb4d2329173>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_hidden_state'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "method='def func(age, street, name = (fun, 1, (2,3))):\\n\\\n",
    "    if (name == \"Vadim\"):\\n\\\n",
    "        print(\"smth is wrong\")\\n\\\n",
    "    else:\\n\\\n",
    "        print(\"Navanyi\")\\n\\\n",
    "    print(age, street)\\n\\\n",
    "    print(name, age, street)\\n'\n",
    "infer(model, method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-ambassador",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('file','r') as f:\n",
    "    method = \"\\n\".join(f.readlines())\n",
    "infer(model, method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-polyester",
   "metadata": {},
   "source": [
    "'CC' вместо нее G\n",
    "\n",
    "Gdef\n",
    "\n",
    "):\n",
    "\n",
    "G(\n",
    "\n",
    "G==\n",
    "\n",
    "pri vet    priv et\n",
    "\n",
    "\\\\\n",
    "\n",
    "\"\" а уменя нет\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-assembly",
   "metadata": {},
   "source": [
    "# Romanov dataset test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "green-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "romanov = pd.read_json('./annotated_functios/functions_with_annotations.jsonl', lines=True)\n",
    "\n",
    "rm_extra_ents = lambda i:[x[2] for x in i]\n",
    "romanov['arg_types']=romanov['ents'].apply(rm_extra_ents)\n",
    "\n",
    "romanov['body']=romanov['text']\n",
    "del romanov['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "recorded-kansas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ents</th>\n",
       "      <th>cats</th>\n",
       "      <th>replacements</th>\n",
       "      <th>docstrings</th>\n",
       "      <th>arg_types</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[36, 45, Union[int, float]], [25, 34, int]]</td>\n",
       "      <td>[str]</td>\n",
       "      <td>[[4, 24, 1429694], [54, 61, 642357], [84, 93, ...</td>\n",
       "      <td>[    \"\"\"Generate an error message when the the...</td>\n",
       "      <td>[Union[int, float], int]</td>\n",
       "      <td>def generate_range_error(range_min, range_max)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           ents   cats  \\\n",
       "0  [[36, 45, Union[int, float]], [25, 34, int]]  [str]   \n",
       "\n",
       "                                        replacements  \\\n",
       "0  [[4, 24, 1429694], [54, 61, 642357], [84, 93, ...   \n",
       "\n",
       "                                          docstrings  \\\n",
       "0  [    \"\"\"Generate an error message when the the...   \n",
       "\n",
       "                  arg_types                                               body  \n",
       "0  [Union[int, float], int]  def generate_range_error(range_min, range_max)...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "romanov.iloc[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "funded-assumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_arg_types(line):\n",
    "    args = get_names(line['body'])\n",
    "    types = line['arg_types']\n",
    "    args = [arg for arg in args if arg[0] not in ['self', 'args', 'kwargs']]\n",
    "    if len(args)!=len(types):\n",
    "        return pd.NA\n",
    "    return line\n",
    "\n",
    "romanov_consistent = romanov.apply(change_arg_types, axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "hispanic-medicare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     73916.0\n",
       "str                    677.0\n",
       "int                    366.0\n",
       "bool                   263.0\n",
       "Any                    125.0\n",
       "callable                93.0\n",
       "dict                    76.0\n",
       "bytes                   65.0\n",
       "Description             51.0\n",
       "float                   48.0\n",
       "list                    48.0\n",
       "sequence                45.0\n",
       "Union[str, bytes]       31.0\n",
       "T                       29.0\n",
       "ndarray                 29.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = pd.DataFrame(romanov_consistent['arg_types'].values.tolist())\n",
    "df_labels[pd.isnull(df_labels)]  = NaN_symbol\n",
    "\n",
    "dd = df_labels.apply(remove_composite)\n",
    "for (k,v) in dict(dd.apply(pd.Series.value_counts).sum(axis=1).sort_values(ascending=False)).items():\n",
    "    if k!=FREQ_CUT_SYMBOL and k!=NaN_symbol and v>MAX_CUT:\n",
    "        dd = replace_type(dd, k, (v-MAX_CUT)/v) \n",
    "df_labels = dd\n",
    "df_labels = dd\n",
    "dd.apply(pd.Series.value_counts).sum(axis=1).sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "intermediate-hawaiian",
   "metadata": {},
   "outputs": [],
   "source": [
    "le_dict = dict(zip(enc.classes_, enc.transform(enc.classes_)))\n",
    "label_encode = lambda i:[le_dict.get(x, NaN_enc[0]) for x in i]\n",
    "\n",
    "\n",
    "\n",
    "romanov_consistent['labels']=dd.apply(label_encode).values.tolist()\n",
    "\n",
    "romanov_consistent['labels'] = romanov_consistent['labels'].apply(la)\n",
    "romanov_consistent = romanov_consistent.dropna(subset=['labels'], axis=0)\n",
    "\n",
    "romanov_loader = DataLoader(DataDataset(romanov_consistent), batch_size=1, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "romance-construction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3340, 6)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "romanov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "sunrise-watts",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2330, 7)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "romanov_consistent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "suspected-feeding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21ad5d9b45ba46568d4bb007d846c2b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/949 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-acb4d2329173>:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(masked)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['int'] ['int']\n",
      "['bytes'] ['str']\n",
      "['type' 'str' 'bool' 'bool'] ['bool' 'str' 'bool' 'bool']\n",
      "['type' 'str'] ['str' 'str']\n",
      "['dict'] ['str']\n",
      "['str' 'list'] ['iterable' 'str']\n",
      "['Tensor' 'int'] ['int' 'int']\n",
      "['ndarray' 'int' 'int' 'ndarray'] ['int' 'int' 'bool' 'str']\n",
      "['DataFrame'] ['int']\n",
      "['Path' 'str' 'str'] ['str' 'str' 'str']\n",
      "['type'] ['sequence']\n",
      "['str' 'dict' 'int' 'int'] ['int' 'int' 'int' 'bool']\n",
      "['type'] ['callable']\n",
      "['type' 'callable'] ['str' 'bool']\n",
      "['str' 'callable' 'float' 'callable' 'dict' 'float' 'float'] ['callable' 'float' 'dict' 'float' 'float' 'int' 'list']\n",
      "['str' 'int' 'int'] ['int' 'int' 'str']\n",
      "['Request' 'str'] ['str' 'str']\n",
      "['type' 'int'] ['str' 'int']\n",
      "['str'] ['str']\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(total=len(romanov_loader))\n",
    "r_top_5s = []\n",
    "r_accuracy = []\n",
    "r_losses = []\n",
    "\n",
    "r_true = []\n",
    "r_pred = []\n",
    "\n",
    "\n",
    "\n",
    "for i,a in enumerate(romanov_loader):\n",
    "    out = model.forward(a)\n",
    "    labels = torch.masked_select(a['ids'], a['input_mask'])\n",
    "    loss = F.nll_loss(torch.log(out), labels)\n",
    "\n",
    "    if torch.isnan(loss):\n",
    "        # print(a)\\n\",\n",
    "        pass\n",
    "    else:\n",
    "        r_pred = r_pred + list(enc.inverse_transform(torch.argmax(out.cpu(), dim=1)))\n",
    "        r_true = r_true + list(enc.inverse_transform(labels.cpu()))\n",
    "        if i%50==0:\n",
    "            print(enc.inverse_transform(torch.argmax(out.cpu(), dim=1)), enc.inverse_transform(labels.cpu()))\n",
    "        r_accuracy.append(sum(torch.argmax(out, dim=1) == labels).detach()/len(labels))\n",
    "        r_losses.append(loss.detach())\n",
    "        top5s = torch.topk(out, 5).indices\n",
    "        correct_top5 = 0\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] in top5s[i]:\n",
    "                correct_top5 += 1\n",
    "        r_top_5s.append(correct_top5/len(labels))\n",
    "    \n",
    "    if i % 20 ==0:\n",
    "        pbar.set_description(f\"Loss : { pr_av(r_losses)}, acc: {pr_av(r_accuracy)}, top5s: {pr_av(r_top_5s)}\")\n",
    "    pbar.update(1)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "compatible-karen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Client       0.00      0.00      0.00         0\n",
      "    DataFrame       0.08      0.62      0.14         8\n",
      "      Element       0.00      0.00      0.00         0\n",
      "HomeAssistant       0.00      0.00      0.00         0\n",
      "      Message       0.00      0.00      0.00         0\n",
      "    Namespace       0.00      0.00      0.00         3\n",
      "         Node       0.00      0.00      0.00         0\n",
      "         Path       0.00      0.00      0.00         0\n",
      "      Request       0.00      0.00      0.00         0\n",
      "       Tensor       0.00      0.00      0.00         0\n",
      "         User       0.00      0.00      0.00         0\n",
      "  UserProfile       0.00      0.00      0.00         0\n",
      "         bool       0.36      0.19      0.25       264\n",
      "        bytes       0.50      0.42      0.45        65\n",
      "     callable       0.27      0.34      0.30        93\n",
      "     datetime       0.00      0.00      0.00         1\n",
      "         dict       0.25      0.25      0.25        76\n",
      "        float       0.24      0.21      0.22        48\n",
      "          int       0.42      0.24      0.30       366\n",
      "     iterable       0.00      0.00      0.00        13\n",
      "         list       0.12      0.27      0.16        48\n",
      "      mapping       0.00      0.00      0.00        14\n",
      "      ndarray       0.12      0.41      0.18        29\n",
      "     sequence       0.67      0.04      0.08        45\n",
      "          set       0.00      0.00      0.00         0\n",
      "          str       0.66      0.35      0.46       679\n",
      "         type       0.04      0.40      0.08        20\n",
      "\n",
      "     accuracy                           0.28      1772\n",
      "    macro avg       0.14      0.14      0.11      1772\n",
      " weighted avg       0.47      0.28      0.34      1772\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deadman445/anaconda3/envs/torchdimplom/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/deadman445/anaconda3/envs/torchdimplom/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/deadman445/anaconda3/envs/torchdimplom/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(r_true, r_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "liked-mustang",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def generate_range_error(range_min, range_max) :\n",
      "\n",
      "    err_str = \"expected \"\n",
      "\n",
      "    if range_max == constants.INFINITY:\n",
      "        err_str += \"at least {} argument\".format(range_min)\n",
      "\n",
      "        if range_min != 1:\n",
      "            err_str += \"s\"\n",
      "    else:\n",
      "        if range_min == range_max:\n",
      "            err_str += \"{} argument\".format(range_min)\n",
      "        else:\n",
      "            err_str += \"{} to {} argument\".format(range_min, range_max)\n",
      "\n",
      "        if range_max != 1:\n",
      "            err_str += \"s\"\n",
      "\n",
      "    return err_str\n",
      "\n",
      "__________________________________________________-\n",
      "def __new__(cls, value, *args, **kwargs) :\n",
      "        return super().__new__(cls, value)\n",
      "\n",
      "__________________________________________________-\n",
      "def __init__(self, value, desc = '', *args, **kwargs) :\n",
      "\n",
      "        super().__init__(*args, **kwargs)\n",
      "        self.description = desc\n",
      "\n",
      "__________________________________________________-\n",
      "def __init__(self, is_method, is_completer, to_call):\n",
      "\n",
      "        self.is_method = is_method\n",
      "        self.is_completer = is_completer\n",
      "        self.to_call = to_call\n",
      "\n",
      "__________________________________________________-\n",
      "def _set_choices_callable(action, choices_callable) :\n",
      "\n",
      "    # Verify consistent use of parameters\n",
      "    if action.choices is not None:\n",
      "        err_msg = (\"None of the following parameters can be used alongside a choices parameter:\\n\"\n",
      "                   \"choices_function, choices_method, completer_function, completer_method\")\n",
      "        raise (TypeError(err_msg))\n",
      "    elif action.nargs == 0:\n",
      "        err_msg = (\"None of the following parameters can be used on an action that takes no arguments:\\n\"\n",
      "                   \"choices_function, choices_method, completer_function, completer_method\")\n",
      "        raise (TypeError(err_msg))\n",
      "\n",
      "    setattr(action, ATTR_CHOICES_CALLABLE, choices_callable)\n",
      "\n",
      "__________________________________________________-\n",
      "def set_choices_function(action, choices_function) :\n",
      "\n",
      "    _set_choices_callable(action, ChoicesCallable(is_method=False, is_completer=False, to_call=choices_function))\n",
      "\n",
      "__________________________________________________-\n",
      "def set_choices_method(action, choices_method) :\n",
      "\n",
      "    _set_choices_callable(action, ChoicesCallable(is_method=True, is_completer=False, to_call=choices_method))\n",
      "\n",
      "__________________________________________________-\n",
      "def set_completer_function(action, completer_function) :\n",
      "\n",
      "    _set_choices_callable(action, ChoicesCallable(is_method=False, is_completer=True, to_call=completer_function))\n",
      "\n",
      "__________________________________________________-\n",
      "def set_completer_method(action, completer_method) :\n",
      "\n",
      "    _set_choices_callable(action, ChoicesCallable(is_method=True, is_completer=True, to_call=completer_method))\n",
      "\n",
      "__________________________________________________-\n",
      "def _add_argument_wrapper(self, *args,\n",
      "                          nargs = None,\n",
      "                          choices_function = None,\n",
      "                          choices_method = None,\n",
      "                          completer_function = None,\n",
      "                          completer_method = None,\n",
      "                          suppress_tab_hint = False,\n",
      "                          descriptive_header = None,\n",
      "                          **kwargs) :\n",
      "\n",
      "    # Verify consistent use of arguments\n",
      "    choices_callables = [choices_function, choices_method, completer_function, completer_method]\n",
      "    num_params_set = len(choices_callables) - choices_callables.count(None)\n",
      "\n",
      "    if num_params_set > 1:\n",
      "        err_msg = (\"Only one of the following parameters may be used at a time:\\n\"\n",
      "                   \"choices_function, choices_method, completer_function, completer_method\")\n",
      "        raise (ValueError(err_msg))\n",
      "\n",
      "    # Pre-process special ranged nargs\n",
      "    nargs_range = None\n",
      "\n",
      "    if nargs is not None:\n",
      "        # Check if nargs was given as a range\n",
      "        if isinstance(nargs, tuple):\n",
      "\n",
      "            # Handle 1-item tuple by setting max to INFINITY\n",
      "            if len(nargs) == 1:\n",
      "                nargs = (nargs[0], constants.INFINITY)\n",
      "\n",
      "            # Validate nargs tuple\n",
      "            if len(nargs) != 2 or not isinstance(nargs[0], int) or \\\n",
      "                    not (isinstance(nargs[1], int) or nargs[1] == constants.INFINITY):\n",
      "                raise ValueError('Ranged values for nargs must be a tuple of 1 or 2 integers')\n",
      "            if nargs[0] >= nargs[1]:\n",
      "                raise ValueError('Invalid nargs range. The first value must be less than the second')\n",
      "            if nargs[0] < 0:\n",
      "                raise ValueError('Negative numbers are invalid for nargs range')\n",
      "\n",
      "            # Save the nargs tuple as our range setting\n",
      "            nargs_range = nargs\n",
      "            range_min = nargs_range[0]\n",
      "            range_max = nargs_range[1]\n",
      "\n",
      "            # Convert nargs into a format argparse recognizes\n",
      "            if range_min == 0:\n",
      "                if range_max == 1:\n",
      "                    nargs_adjusted = argparse.OPTIONAL\n",
      "\n",
      "                    # No range needed since (0, 1) is just argparse.OPTIONAL\n",
      "                    nargs_range = None\n",
      "                else:\n",
      "                    nargs_adjusted = argparse.ZERO_OR_MORE\n",
      "                    if range_max == constants.INFINITY:\n",
      "                        # No range needed since (0, INFINITY) is just argparse.ZERO_OR_MORE\n",
      "                        nargs_range = None\n",
      "            elif range_min == 1 and range_max == constants.INFINITY:\n",
      "                nargs_adjusted = argparse.ONE_OR_MORE\n",
      "\n",
      "                # No range needed since (1, INFINITY) is just argparse.ONE_OR_MORE\n",
      "                nargs_range = None\n",
      "            else:\n",
      "                nargs_adjusted = argparse.ONE_OR_MORE\n",
      "        else:\n",
      "            nargs_adjusted = nargs\n",
      "\n",
      "        # Add the argparse-recognized version of nargs to kwargs\n",
      "        kwargs['nargs'] = nargs_adjusted\n",
      "\n",
      "    # Create the argument using the original add_argument function\n",
      "    new_arg = orig_actions_container_add_argument(self, *args, **kwargs)\n",
      "\n",
      "    # Set the custom attributes\n",
      "    setattr(new_arg, ATTR_NARGS_RANGE, nargs_range)\n",
      "\n",
      "    if choices_function:\n",
      "        set_choices_function(new_arg, choices_function)\n",
      "    elif choices_method:\n",
      "        set_choices_method(new_arg, choices_method)\n",
      "    elif completer_function:\n",
      "        set_completer_function(new_arg, completer_function)\n",
      "    elif completer_method:\n",
      "        set_completer_method(new_arg, completer_method)\n",
      "\n",
      "    setattr(new_arg, ATTR_SUPPRESS_TAB_HINT, suppress_tab_hint)\n",
      "    setattr(new_arg, ATTR_DESCRIPTIVE_COMPLETION_HEADER, descriptive_header)\n",
      "\n",
      "    return new_arg\n",
      "\n",
      "__________________________________________________-\n",
      "def _get_nargs_pattern_wrapper(self, action) :\n",
      "    # Wrapper around ArgumentParser._get_nargs_pattern behavior to support nargs ranges\n",
      "    nargs_range = getattr(action, ATTR_NARGS_RANGE, None)\n",
      "    if nargs_range is not None:\n",
      "        if nargs_range[1] == constants.INFINITY:\n",
      "            range_max = ''\n",
      "        else:\n",
      "            range_max = nargs_range[1]\n",
      "\n",
      "        nargs_pattern = '(-*A{{{},{}}}-*)'.format(nargs_range[0], range_max)\n",
      "\n",
      "        # if this is an optional action, -- is not allowed\n",
      "        if action.option_strings:\n",
      "            nargs_pattern = nargs_pattern.replace('-*', '')\n",
      "            nargs_pattern = nargs_pattern.replace('-', '')\n",
      "        return nargs_pattern\n",
      "\n",
      "    return orig_argument_parser_get_nargs_pattern(self, action)\n",
      "\n",
      "__________________________________________________-\n",
      "def _match_argument_wrapper(self, action, arg_strings_pattern) :\n",
      "    # Wrapper around ArgumentParser._match_argument behavior to support nargs ranges\n",
      "    nargs_pattern = self._get_nargs_pattern(action)\n",
      "    match = re.match(nargs_pattern, arg_strings_pattern)\n",
      "\n",
      "    # raise an exception if we weren't able to find a match\n",
      "    if match is None:\n",
      "        nargs_range = getattr(action, ATTR_NARGS_RANGE, None)\n",
      "        if nargs_range is not None:\n",
      "            raise ArgumentError(action, generate_range_error(nargs_range[0], nargs_range[1]))\n",
      "\n",
      "    return orig_argument_parser_match_argument(self, action, arg_strings_pattern)\n",
      "\n",
      "__________________________________________________-\n",
      "def _format_usage(self, usage, actions, groups, prefix) :\n",
      "        if prefix is None:\n",
      "            prefix = _('Usage: ')\n",
      "\n",
      "        # if usage is specified, use that\n",
      "        if usage is not None:\n",
      "            usage %= dict(prog=self._prog)\n",
      "\n",
      "        # if no optionals or positionals are available, usage is just prog\n",
      "        elif usage is None and not actions:\n",
      "            usage = '%(prog)s' % dict(prog=self._prog)\n",
      "\n",
      "        # if optionals and positionals are available, calculate usage\n",
      "        elif usage is None:\n",
      "            prog = '%(prog)s' % dict(prog=self._prog)\n",
      "\n",
      "            # split optionals from positionals\n",
      "            optionals = []\n",
      "            positionals = []\n",
      "            # Begin cmd2 customization (separates required and optional, applies to all changes in this function)\n",
      "            required_options = []\n",
      "            for action in actions:\n",
      "                if action.option_strings:\n",
      "                    if action.required:\n",
      "                        required_options.append(action)\n",
      "                    else:\n",
      "                        optionals.append(action)\n",
      "                else:\n",
      "                    positionals.append(action)\n",
      "            # End cmd2 customization\n",
      "\n",
      "            # build full usage string\n",
      "            format = self._format_actions_usage\n",
      "            action_usage = format(required_options + optionals + positionals, groups)\n",
      "            usage = ' '.join([s for s in [prog, action_usage] if s])\n",
      "\n",
      "            # wrap the usage parts if it's too long\n",
      "            text_width = self._width - self._current_indent\n",
      "            if len(prefix) + len(usage) > text_width:\n",
      "\n",
      "                # Begin cmd2 customization\n",
      "\n",
      "                # break usage into wrappable parts\n",
      "                part_regexp = r'\\(.*?\\)+|\\[.*?\\]+|\\S+'\n",
      "                req_usage = format(required_options, groups)\n",
      "                opt_usage = format(optionals, groups)\n",
      "                pos_usage = format(positionals, groups)\n",
      "                req_parts = re.findall(part_regexp, req_usage)\n",
      "                opt_parts = re.findall(part_regexp, opt_usage)\n",
      "                pos_parts = re.findall(part_regexp, pos_usage)\n",
      "                assert ' '.join(req_parts) == req_usage\n",
      "                assert ' '.join(opt_parts) == opt_usage\n",
      "                assert ' '.join(pos_parts) == pos_usage\n",
      "\n",
      "                # End cmd2 customization\n",
      "\n",
      "                # helper for wrapping lines\n",
      "                # noinspection PyMissingOrEmptyDocstring,PyShadowingNames\n",
      "                def get_lines(parts, indent, prefix=None):\n",
      "                    lines = []\n",
      "                    line = []\n",
      "                    if prefix is not None:\n",
      "                        line_len = len(prefix) - 1\n",
      "                    else:\n",
      "                        line_len = len(indent) - 1\n",
      "                    for part in parts:\n",
      "                        if line_len + 1 + len(part) > text_width and line:\n",
      "                            lines.append(indent + ' '.join(line))\n",
      "                            line = []\n",
      "                            line_len = len(indent) - 1\n",
      "                        line.append(part)\n",
      "                        line_len += len(part) + 1\n",
      "                    if line:\n",
      "                        lines.append(indent + ' '.join(line))\n",
      "                    if prefix is not None:\n",
      "                        lines[0] = lines[0][len(indent):]\n",
      "                    return lines\n",
      "\n",
      "                # if prog is short, follow it with optionals or positionals\n",
      "                if len(prefix) + len(prog) <= 0.75 * text_width:\n",
      "                    indent = ' ' * (len(prefix) + len(prog) + 1)\n",
      "                    # Begin cmd2 customization\n",
      "                    if req_parts:\n",
      "                        lines = get_lines([prog] + req_parts, indent, prefix)\n",
      "                        lines.extend(get_lines(opt_parts, indent))\n",
      "                        lines.extend(get_lines(pos_parts, indent))\n",
      "                    elif opt_parts:\n",
      "                        lines = get_lines([prog] + opt_parts, indent, prefix)\n",
      "                        lines.extend(get_lines(pos_parts, indent))\n",
      "                    elif pos_parts:\n",
      "                        lines = get_lines([prog] + pos_parts, indent, prefix)\n",
      "                    else:\n",
      "                        lines = [prog]\n",
      "                    # End cmd2 customization\n",
      "\n",
      "                # if prog is long, put it on its own line\n",
      "                else:\n",
      "                    indent = ' ' * len(prefix)\n",
      "                    # Begin cmd2 customization\n",
      "                    parts = req_parts + opt_parts + pos_parts\n",
      "                    lines = get_lines(parts, indent)\n",
      "                    if len(lines) > 1:\n",
      "                        lines = []\n",
      "                        lines.extend(get_lines(req_parts, indent))\n",
      "                        lines.extend(get_lines(opt_parts, indent))\n",
      "                        lines.extend(get_lines(pos_parts, indent))\n",
      "                    # End cmd2 customization\n",
      "                    lines = [prog] + lines\n",
      "\n",
      "                # join lines into usage\n",
      "                usage = '\\n'.join(lines)\n",
      "\n",
      "        # prefix with 'Usage:'\n",
      "        return '%s%s\\n\\n' % (prefix, usage)\n",
      "\n",
      "__________________________________________________-\n",
      "def _format_action_invocation(self, action) :\n",
      "        if not action.option_strings:\n",
      "            default = self._get_default_metavar_for_positional(action)\n",
      "            metavar, = self._metavar_formatter(action, default)(1)\n",
      "            return metavar\n",
      "\n",
      "        else:\n",
      "            parts = []\n",
      "\n",
      "            # if the Optional doesn't take a value, format is:\n",
      "            #    -s, --long\n",
      "            if action.nargs == 0:\n",
      "                parts.extend(action.option_strings)\n",
      "                return ', '.join(parts)\n",
      "\n",
      "            # Begin cmd2 customization (less verbose)\n",
      "            # if the Optional takes a value, format is:\n",
      "            #    -s, --long ARGS\n",
      "            else:\n",
      "                default = self._get_default_metavar_for_optional(action)\n",
      "                args_string = self._format_args(action, default)\n",
      "\n",
      "                return ', '.join(action.option_strings) + ' ' + args_string\n",
      "            # End cmd2 customization\n",
      "__________________________________________________-\n",
      "def _metavar_formatter(self, action, default_metavar) :\n",
      "        if action.metavar is not None:\n",
      "            result = action.metavar\n",
      "        elif action.choices is not None:\n",
      "            choice_strs = [str(choice) for choice in action.choices]\n",
      "            # Begin cmd2 customization (added space after comma)\n",
      "            result = '{%s}' % ', '.join(choice_strs)\n",
      "            # End cmd2 customization\n",
      "        else:\n",
      "            result = default_metavar\n",
      "\n",
      "        # noinspection PyMissingOrEmptyDocstring\n",
      "        def format(tuple_size):\n",
      "            if isinstance(result, tuple):\n",
      "                return result\n",
      "            else:\n",
      "                return (result, ) * tuple_size\n",
      "        return format\n",
      "\n",
      "__________________________________________________-\n",
      "def _format_args(self, action, default_metavar) :\n",
      "        get_metavar = self._metavar_formatter(action, default_metavar)\n",
      "        # Begin cmd2 customization (less verbose)\n",
      "        nargs_range = getattr(action, ATTR_NARGS_RANGE, None)\n",
      "\n",
      "        if nargs_range is not None:\n",
      "            if nargs_range[1] == constants.INFINITY:\n",
      "                range_str = '{}+'.format(nargs_range[0])\n",
      "            else:\n",
      "                range_str = '{}..{}'.format(nargs_range[0], nargs_range[1])\n",
      "\n",
      "            result = '{}{{{}}}'.format('%s' % get_metavar(1), range_str)\n",
      "        elif action.nargs == ZERO_OR_MORE:\n",
      "            result = '[%s [...]]' % get_metavar(1)\n",
      "        elif action.nargs == ONE_OR_MORE:\n",
      "            result = '%s [...]' % get_metavar(1)\n",
      "        elif isinstance(action.nargs, int) and action.nargs > 1:\n",
      "            result = '{}{{{}}}'.format('%s' % get_metavar(1), action.nargs)\n",
      "        # End cmd2 customization\n",
      "        else:\n",
      "            result = super()._format_args(action, default_metavar)\n",
      "        return result\n",
      "\n",
      "__________________________________________________-\n",
      "def __init__(self, *args, **kwargs) :\n",
      "        if 'formatter_class' not in kwargs:\n",
      "            kwargs['formatter_class'] = Cmd2HelpFormatter\n",
      "\n",
      "        super().__init__(*args, **kwargs)\n",
      "\n",
      "__________________________________________________-\n",
      "def error(self, message) :\n",
      "\n",
      "        lines = message.split('\\n')\n",
      "        linum = 0\n",
      "        formatted_message = ''\n",
      "        for line in lines:\n",
      "            if linum == 0:\n",
      "                formatted_message = 'Error: ' + line\n",
      "            else:\n",
      "                formatted_message += '\\n       ' + line\n",
      "            linum += 1\n",
      "\n",
      "        self.print_usage(sys.stderr)\n",
      "        formatted_message = ansi.style_error(formatted_message)\n",
      "        self.exit(2, '{}\\n\\n'.format(formatted_message))\n",
      "\n",
      "__________________________________________________-\n",
      "def format_help(self) :\n",
      "\n",
      "        formatter = self._get_formatter()\n",
      "\n",
      "        # usage\n",
      "        formatter.add_usage(self.usage, self._actions,\n",
      "                            self._mutually_exclusive_groups)\n",
      "\n",
      "        # description\n",
      "        formatter.add_text(self.description)\n",
      "\n",
      "        # Begin cmd2 customization (separate required and optional arguments)\n",
      "\n",
      "        # positionals, optionals and user-defined groups\n",
      "        for action_group in self._action_groups:\n",
      "            if action_group.title == 'optional arguments':\n",
      "                # check if the arguments are required, group accordingly\n",
      "                req_args = []\n",
      "                opt_args = []\n",
      "                for action in action_group._group_actions:\n",
      "                    if action.required:\n",
      "                        req_args.append(action)\n",
      "                    else:\n",
      "                        opt_args.append(action)\n",
      "\n",
      "                # separately display required arguments\n",
      "                formatter.start_section('required arguments')\n",
      "                formatter.add_text(action_group.description)\n",
      "                formatter.add_arguments(req_args)\n",
      "                formatter.end_section()\n",
      "\n",
      "                # now display truly optional arguments\n",
      "                formatter.start_section(action_group.title)\n",
      "                formatter.add_text(action_group.description)\n",
      "                formatter.add_arguments(opt_args)\n",
      "                formatter.end_section()\n",
      "            else:\n",
      "                formatter.start_section(action_group.title)\n",
      "                formatter.add_text(action_group.description)\n",
      "                formatter.add_arguments(action_group._group_actions)\n",
      "                formatter.end_section()\n",
      "\n",
      "        # End cmd2 customization\n",
      "\n",
      "        # epilog\n",
      "        formatter.add_text(self.epilog)\n",
      "\n",
      "        # determine help from format above\n",
      "        return formatter.format_help() + '\\n'\n",
      "\n",
      "__________________________________________________-\n",
      "def set_default_argument_parser(parser) :\n",
      "\n",
      "    global DEFAULT_ARGUMENT_PARSER\n",
      "    DEFAULT_ARGUMENT_PARSER = parser\n",
      "\n",
      "__________________________________________________-\n",
      "def __init__(self, header, *, width = None,\n",
      "                 header_horiz_align = HorizontalAlignment.LEFT,\n",
      "                 header_vert_align = VerticalAlignment.BOTTOM,\n",
      "                 data_horiz_align = HorizontalAlignment.LEFT,\n",
      "                 data_vert_align = VerticalAlignment.TOP,\n",
      "                 max_data_lines = constants.INFINITY) :\n",
      "\n",
      "        self.header = header\n",
      "\n",
      "        if width is None:\n",
      "            # Use the width of the widest line in the header or 1 if the header has no width\n",
      "            line_widths = [ansi.style_aware_wcswidth(line) for line in self.header.splitlines()]\n",
      "            line_widths.append(1)\n",
      "            self.width = max(line_widths)\n",
      "        elif width < 1:\n",
      "            raise ValueError(\"Column width cannot be less than 1\")\n",
      "        else:\n",
      "            self.width = width\n",
      "\n",
      "        self.header_horiz_align = header_horiz_align\n",
      "        self.header_vert_align = header_vert_align\n",
      "        self.data_horiz_align = data_horiz_align\n",
      "        self.data_vert_align = data_vert_align\n",
      "\n",
      "        if max_data_lines < 1:\n",
      "            raise ValueError(\"Max data lines cannot be less than 1\")\n",
      "\n",
      "        self.max_data_lines = max_data_lines\n",
      "\n",
      "__________________________________________________-\n",
      "def __init__(self, cols, *, tab_width = 4) :\n",
      "\n",
      "        self.cols = copy.copy(cols)\n",
      "        self.tab_width = tab_width\n",
      "\n",
      "__________________________________________________-\n",
      "def _wrap_long_word(word, max_width, max_lines, is_last_word) :\n",
      "\n",
      "        styles = utils.get_styles_in_text(word)\n",
      "        wrapped_buf = io.StringIO()\n",
      "\n",
      "        # How many lines we've used\n",
      "        total_lines = 1\n",
      "\n",
      "        # Display width of the current line we are building\n",
      "        cur_line_width = 0\n",
      "\n",
      "        char_index = 0\n",
      "        while char_index < len(word):\n",
      "            # We've reached the last line. Let truncate_line do the rest.\n",
      "            if total_lines == max_lines:\n",
      "                # If this isn't the last word, but it's gonna fill the final line, then force truncate_line\n",
      "                # to place an ellipsis at the end of it by making the word too wide.\n",
      "                remaining_word = word[char_index:]\n",
      "                if not is_last_word and ansi.style_aware_wcswidth(remaining_word) == max_width:\n",
      "                    remaining_word += \"EXTRA\"\n",
      "\n",
      "                truncated_line = utils.truncate_line(remaining_word, max_width)\n",
      "                cur_line_width = ansi.style_aware_wcswidth(truncated_line)\n",
      "                wrapped_buf.write(truncated_line)\n",
      "                break\n",
      "\n",
      "            # Check if we're at a style sequence. These don't count toward display width.\n",
      "            if char_index in styles:\n",
      "                wrapped_buf.write(styles[char_index])\n",
      "                char_index += len(styles[char_index])\n",
      "                continue\n",
      "\n",
      "            cur_char = word[char_index]\n",
      "            cur_char_width = wcwidth(cur_char)\n",
      "\n",
      "            if cur_char_width > max_width:\n",
      "                # We have a case where the character is wider than max_width. This can happen if max_width\n",
      "                # is 1 and the text contains wide characters (e.g. East Asian). Replace it with an ellipsis.\n",
      "                cur_char = constants.HORIZONTAL_ELLIPSIS\n",
      "                cur_char_width = wcwidth(cur_char)\n",
      "\n",
      "            if cur_line_width + cur_char_width > max_width:\n",
      "                # Adding this char will exceed the max_width. Start a new line.\n",
      "                wrapped_buf.write('\\n')\n",
      "                total_lines += 1\n",
      "                cur_line_width = 0\n",
      "                continue\n",
      "\n",
      "            # Add this character and move to the next one\n",
      "            cur_line_width += cur_char_width\n",
      "            wrapped_buf.write(cur_char)\n",
      "            char_index += 1\n",
      "\n",
      "        return wrapped_buf.getvalue(), total_lines, cur_line_width\n",
      "\n",
      "__________________________________________________-\n",
      "def _wrap_text(text, max_width, max_lines) :\n",
      "\n",
      "        def add_word(word_to_add, is_last_word):\n",
      "\n",
      "            nonlocal cur_line_width\n",
      "            nonlocal total_lines\n",
      "\n",
      "            # No more space to add word\n",
      "            if total_lines == max_lines and cur_line_width == max_width:\n",
      "                return\n",
      "\n",
      "            word_width = ansi.style_aware_wcswidth(word_to_add)\n",
      "\n",
      "            # If the word is wider than max width of a line, attempt to start it on its own line and wrap it\n",
      "            if word_width > max_width:\n",
      "                room_to_add = True\n",
      "\n",
      "                if cur_line_width > 0:\n",
      "                    # The current line already has text, check if there is room to create a new line\n",
      "                    if total_lines < max_lines:\n",
      "                        wrapped_buf.write('\\n')\n",
      "                        total_lines += 1\n",
      "                    else:\n",
      "                        # We will truncate this word on the remaining line\n",
      "                        room_to_add = False\n",
      "\n",
      "                if room_to_add:\n",
      "                    wrapped_word, lines_used, cur_line_width = TableCreator._wrap_long_word(word_to_add,\n",
      "                                                                                            max_width,\n",
      "                                                                                            max_lines - total_lines + 1,\n",
      "                                                                                            is_last_word)\n",
      "                    # Write the word to the buffer\n",
      "                    wrapped_buf.write(wrapped_word)\n",
      "                    total_lines += lines_used - 1\n",
      "                    return\n",
      "\n",
      "            # We aren't going to wrap the word across multiple lines\n",
      "            remaining_width = max_width - cur_line_width\n",
      "\n",
      "            # Check if we need to start a new line\n",
      "            if word_width > remaining_width and total_lines < max_lines:\n",
      "                # Save the last character in wrapped_buf, which can't be empty at this point.\n",
      "                seek_pos = wrapped_buf.tell() - 1\n",
      "                wrapped_buf.seek(seek_pos)\n",
      "                last_char = wrapped_buf.read()\n",
      "\n",
      "                wrapped_buf.write('\\n')\n",
      "                total_lines += 1\n",
      "                cur_line_width = 0\n",
      "                remaining_width = max_width\n",
      "\n",
      "                # Only when a space is following a space do we want to start the next line with it.\n",
      "                if word_to_add == SPACE and last_char != SPACE:\n",
      "                    return\n",
      "\n",
      "            # Check if we've hit the last line we're allowed to create\n",
      "            if total_lines == max_lines:\n",
      "                # If this word won't fit, truncate it\n",
      "                if word_width > remaining_width:\n",
      "                    word_to_add = utils.truncate_line(word_to_add, remaining_width)\n",
      "                    word_width = remaining_width\n",
      "\n",
      "                # If this isn't the last word, but it's gonna fill the final line, then force truncate_line\n",
      "                # to place an ellipsis at the end of it by making the word too wide.\n",
      "                elif not is_last_word and word_width == remaining_width:\n",
      "                    word_to_add = utils.truncate_line(word_to_add + \"EXTRA\", remaining_width)\n",
      "\n",
      "            cur_line_width += word_width\n",
      "            wrapped_buf.write(word_to_add)\n",
      "\n",
      "        ############################################################################################################\n",
      "        # _wrap_text() main code\n",
      "        ############################################################################################################\n",
      "        # Buffer of the wrapped text\n",
      "        wrapped_buf = io.StringIO()\n",
      "\n",
      "        # How many lines we've used\n",
      "        total_lines = 0\n",
      "\n",
      "        # Respect the existing line breaks\n",
      "        data_str_lines = text.splitlines()\n",
      "        for data_line_index, data_line in enumerate(data_str_lines):\n",
      "            total_lines += 1\n",
      "\n",
      "            if data_line_index > 0:\n",
      "                wrapped_buf.write('\\n')\n",
      "\n",
      "            # Locate the styles in this line\n",
      "            styles = utils.get_styles_in_text(data_line)\n",
      "\n",
      "            # Display width of the current line we are building\n",
      "            cur_line_width = 0\n",
      "\n",
      "            # Current word being built\n",
      "            cur_word_buf = io.StringIO()\n",
      "\n",
      "            char_index = 0\n",
      "            while char_index < len(data_line):\n",
      "                if total_lines == max_lines and cur_line_width == max_width:\n",
      "                    break\n",
      "\n",
      "                # Check if we're at a style sequence. These don't count toward display width.\n",
      "                if char_index in styles:\n",
      "                    cur_word_buf.write(styles[char_index])\n",
      "                    char_index += len(styles[char_index])\n",
      "                    continue\n",
      "\n",
      "                cur_char = data_line[char_index]\n",
      "                if cur_char == SPACE:\n",
      "                    # If we've reached the end of a word, then add the word to the wrapped text\n",
      "                    if cur_word_buf.tell() > 0:\n",
      "                        # is_last_word is False since there is a space after the word\n",
      "                        add_word(cur_word_buf.getvalue(), is_last_word=False)\n",
      "                        cur_word_buf = io.StringIO()\n",
      "\n",
      "                    # Add the space to the wrapped text\n",
      "                    last_word = data_line_index == len(data_str_lines) - 1 and char_index == len(data_line) - 1\n",
      "                    add_word(cur_char, last_word)\n",
      "                else:\n",
      "                    # Add this character to the word buffer\n",
      "                    cur_word_buf.write(cur_char)\n",
      "\n",
      "                char_index += 1\n",
      "\n",
      "            # Add the final word of this line if it's been started\n",
      "            if cur_word_buf.tell() > 0:\n",
      "                last_word = data_line_index == len(data_str_lines) - 1 and char_index == len(data_line)\n",
      "                add_word(cur_word_buf.getvalue(), last_word)\n",
      "\n",
      "            # Stop line loop if we've written to max_lines\n",
      "            if total_lines == max_lines:\n",
      "                # If this isn't the last data line and there is space left on the final wrapped line, then add an ellipsis\n",
      "                if data_line_index < len(data_str_lines) - 1 and cur_line_width < max_width:\n",
      "                    wrapped_buf.write(constants.HORIZONTAL_ELLIPSIS)\n",
      "                break\n",
      "\n",
      "        return wrapped_buf.getvalue()\n",
      "\n",
      "__________________________________________________-\n",
      "def add_word(word_to_add, is_last_word):\n",
      "\n",
      "            nonlocal cur_line_width\n",
      "            nonlocal total_lines\n",
      "\n",
      "            # No more space to add word\n",
      "            if total_lines == max_lines and cur_line_width == max_width:\n",
      "                return\n",
      "\n",
      "            word_width = ansi.style_aware_wcswidth(word_to_add)\n",
      "\n",
      "            # If the word is wider than max width of a line, attempt to start it on its own line and wrap it\n",
      "            if word_width > max_width:\n",
      "                room_to_add = True\n",
      "\n",
      "                if cur_line_width > 0:\n",
      "                    # The current line already has text, check if there is room to create a new line\n",
      "                    if total_lines < max_lines:\n",
      "                        wrapped_buf.write('\\n')\n",
      "                        total_lines += 1\n",
      "                    else:\n",
      "                        # We will truncate this word on the remaining line\n",
      "                        room_to_add = False\n",
      "\n",
      "                if room_to_add:\n",
      "                    wrapped_word, lines_used, cur_line_width = TableCreator._wrap_long_word(word_to_add,\n",
      "                                                                                            max_width,\n",
      "                                                                                            max_lines - total_lines + 1,\n",
      "                                                                                            is_last_word)\n",
      "                    # Write the word to the buffer\n",
      "                    wrapped_buf.write(wrapped_word)\n",
      "                    total_lines += lines_used - 1\n",
      "                    return\n",
      "\n",
      "            # We aren't going to wrap the word across multiple lines\n",
      "            remaining_width = max_width - cur_line_width\n",
      "\n",
      "            # Check if we need to start a new line\n",
      "            if word_width > remaining_width and total_lines < max_lines:\n",
      "                # Save the last character in wrapped_buf, which can't be empty at this point.\n",
      "                seek_pos = wrapped_buf.tell() - 1\n",
      "                wrapped_buf.seek(seek_pos)\n",
      "                last_char = wrapped_buf.read()\n",
      "\n",
      "                wrapped_buf.write('\\n')\n",
      "                total_lines += 1\n",
      "                cur_line_width = 0\n",
      "                remaining_width = max_width\n",
      "\n",
      "                # Only when a space is following a space do we want to start the next line with it.\n",
      "                if word_to_add == SPACE and last_char != SPACE:\n",
      "                    return\n",
      "\n",
      "            # Check if we've hit the last line we're allowed to create\n",
      "            if total_lines == max_lines:\n",
      "                # If this word won't fit, truncate it\n",
      "                if word_width > remaining_width:\n",
      "                    word_to_add = utils.truncate_line(word_to_add, remaining_width)\n",
      "                    word_width = remaining_width\n",
      "\n",
      "                # If this isn't the last word, but it's gonna fill the final line, then force truncate_line\n",
      "                # to place an ellipsis at the end of it by making the word too wide.\n",
      "                elif not is_last_word and word_width == remaining_width:\n",
      "                    word_to_add = utils.truncate_line(word_to_add + \"EXTRA\", remaining_width)\n",
      "\n",
      "            cur_line_width += word_width\n",
      "            wrapped_buf.write(word_to_add)\n",
      "\n",
      "__________________________________________________-\n",
      "def _generate_cell_lines(self, cell_data, is_header, col, fill_char) :\n",
      "\n",
      "        # Convert data to string and replace tabs with spaces\n",
      "        data_str = str(cell_data).replace('\\t', SPACE * self.tab_width)\n",
      "\n",
      "        # Wrap text in this cell\n",
      "        max_lines = constants.INFINITY if is_header else col.max_data_lines\n",
      "        wrapped_text = self._wrap_text(data_str, col.width, max_lines)\n",
      "\n",
      "        # Align the text horizontally\n",
      "        horiz_alignment = col.header_horiz_align if is_header else col.data_horiz_align\n",
      "        if horiz_alignment == HorizontalAlignment.LEFT:\n",
      "            text_alignment = utils.TextAlignment.LEFT\n",
      "        elif horiz_alignment == HorizontalAlignment.CENTER:\n",
      "            text_alignment = utils.TextAlignment.CENTER\n",
      "        else:\n",
      "            text_alignment = utils.TextAlignment.RIGHT\n",
      "\n",
      "        aligned_text = utils.align_text(wrapped_text, fill_char=fill_char, width=col.width, alignment=text_alignment)\n",
      "\n",
      "        lines = deque(aligned_text.splitlines())\n",
      "        cell_width = max([ansi.style_aware_wcswidth(line) for line in lines])\n",
      "        return lines, cell_width\n",
      "\n",
      "__________________________________________________-\n",
      "def generate_row(self, *, row_data = None, fill_char = SPACE,\n",
      "                     pre_line = EMPTY, inter_cell = (2 * SPACE), post_line = EMPTY) :\n",
      "\n",
      "        class Cell:\n",
      "\n",
      "            def __init__(self) :\n",
      "                # Data in this cell split into individual lines\n",
      "                self.lines = []\n",
      "\n",
      "                # Display width of this cell\n",
      "                self.width = 0\n",
      "\n",
      "        if row_data is None:\n",
      "            row_data = [col.header for col in self.cols]\n",
      "            is_header = True\n",
      "        else:\n",
      "            if len(row_data) != len(self.cols):\n",
      "                raise ValueError(\"Length of row_data must match length of cols\")\n",
      "            is_header = False\n",
      "\n",
      "        # Replace tabs (tabs in data strings will be handled in _generate_cell_lines())\n",
      "        fill_char = fill_char.replace('\\t', SPACE)\n",
      "        pre_line = pre_line.replace('\\t', SPACE * self.tab_width)\n",
      "        inter_cell = inter_cell.replace('\\t', SPACE * self.tab_width)\n",
      "        post_line = post_line.replace('\\t', SPACE * self.tab_width)\n",
      "\n",
      "        # Validate fill_char character count\n",
      "        if len(ansi.strip_style(fill_char)) != 1:\n",
      "            raise TypeError(\"Fill character must be exactly one character long\")\n",
      "\n",
      "        # Look for unprintable characters\n",
      "        validation_dict = {'fill_char': fill_char, 'pre_line': pre_line,\n",
      "                           'inter_cell': inter_cell, 'post_line': post_line}\n",
      "        for key, val in validation_dict.items():\n",
      "            if ansi.style_aware_wcswidth(val) == -1:\n",
      "                raise (ValueError(\"{} contains an unprintable character\".format(key)))\n",
      "\n",
      "        # Number of lines this row uses\n",
      "        total_lines = 0\n",
      "\n",
      "        # Generate the cells for this row\n",
      "        cells = list()\n",
      "\n",
      "        for col_index, col in enumerate(self.cols):\n",
      "            cell = Cell()\n",
      "            cell.lines, cell.width = self._generate_cell_lines(row_data[col_index], is_header, col, fill_char)\n",
      "            cells.append(cell)\n",
      "            total_lines = max(len(cell.lines), total_lines)\n",
      "\n",
      "        row_buf = io.StringIO()\n",
      "\n",
      "        # Vertically align each cell\n",
      "        for cell_index, cell in enumerate(cells):\n",
      "            col = self.cols[cell_index]\n",
      "            vert_align = col.header_vert_align if is_header else col.data_vert_align\n",
      "\n",
      "            # Check if this cell need vertical filler\n",
      "            line_diff = total_lines - len(cell.lines)\n",
      "            if line_diff == 0:\n",
      "                continue\n",
      "\n",
      "            # Add vertical filler lines\n",
      "            padding_line = utils.align_left(EMPTY, fill_char=fill_char, width=cell.width)\n",
      "            if vert_align == VerticalAlignment.TOP:\n",
      "                to_top = 0\n",
      "                to_bottom = line_diff\n",
      "            elif vert_align == VerticalAlignment.MIDDLE:\n",
      "                to_top = line_diff // 2\n",
      "                to_bottom = line_diff - to_top\n",
      "            else:\n",
      "                to_top = line_diff\n",
      "                to_bottom = 0\n",
      "\n",
      "            for i in range(to_top):\n",
      "                cell.lines.appendleft(padding_line)\n",
      "            for i in range(to_bottom):\n",
      "                cell.lines.append(padding_line)\n",
      "\n",
      "        # Build this row one line at a time\n",
      "        for line_index in range(total_lines):\n",
      "            for cell_index, cell in enumerate(cells):\n",
      "                if cell_index == 0:\n",
      "                    row_buf.write(pre_line)\n",
      "\n",
      "                row_buf.write(cell.lines[line_index])\n",
      "\n",
      "                if cell_index < len(self.cols) - 1:\n",
      "                    row_buf.write(inter_cell)\n",
      "                if cell_index == len(self.cols) - 1:\n",
      "                    row_buf.write(post_line)\n",
      "\n",
      "            # Add a newline if this is not the last line\n",
      "            if line_index < total_lines - 1:\n",
      "                row_buf.write('\\n')\n",
      "\n",
      "        return row_buf.getvalue()\n",
      "\n",
      "__________________________________________________-\n",
      "def __init__(self) :\n",
      "                # Data in this cell split into individual lines\n",
      "                self.lines = []\n",
      "\n",
      "                # Display width of this cell\n",
      "                self.width = 0\n",
      "\n",
      "__________________________________________________-\n",
      "def __init__(self, cols, *, tab_width = 4, divider_char = '-') :\n",
      "\n",
      "        if divider_char is not None:\n",
      "            if len(ansi.strip_style(divider_char)) != 1:\n",
      "                raise TypeError(\"Divider character must be exactly one character long\")\n",
      "\n",
      "            divider_char_width = ansi.style_aware_wcswidth(divider_char)\n",
      "            if divider_char_width == -1:\n",
      "                raise (ValueError(\"Divider character is an unprintable character\"))\n",
      "\n",
      "        super().__init__(cols, tab_width=tab_width)\n",
      "        self.divider_char = divider_char\n",
      "\n",
      "__________________________________________________-\n",
      "def base_width(cls, num_cols) :\n",
      "\n",
      "        if num_cols < 1:\n",
      "            raise ValueError(\"Column count cannot be less than 1\")\n",
      "\n",
      "        data_str = SPACE\n",
      "        data_width = ansi.style_aware_wcswidth(data_str) * num_cols\n",
      "\n",
      "        tbl = cls([Column(data_str)] * num_cols)\n",
      "        data_row = tbl.generate_data_row([data_str] * num_cols)\n",
      "\n",
      "        return ansi.style_aware_wcswidth(data_row) - data_width\n",
      "\n",
      "__________________________________________________-\n",
      "def generate_data_row(self, row_data) :\n",
      "\n",
      "        return self.generate_row(row_data=row_data, inter_cell=self.INTER_CELL)\n",
      "\n",
      "__________________________________________________-\n",
      "def total_width(self) :\n",
      "\n",
      "        base_width = self.base_width(len(self.cols))\n",
      "        data_width = sum(col.width for col in self.cols)\n",
      "        return base_width + data_width\n",
      "\n",
      "__________________________________________________-\n",
      "def generate_header(self) :\n",
      "\n",
      "        header_buf = io.StringIO()\n",
      "\n",
      "        # Create the header labels\n",
      "        header = self.generate_row(inter_cell=self.INTER_CELL)\n",
      "        header_buf.write(header)\n",
      "\n",
      "        # Create the divider if necessary\n",
      "        if self.divider_char is not None:\n",
      "            total_width = self.total_width()\n",
      "            divider_char_width = ansi.style_aware_wcswidth(self.divider_char)\n",
      "\n",
      "            # Make divider as wide as table and use padding if width of\n",
      "            # divider_char does not divide evenly into table width.\n",
      "            divider = self.divider_char * (total_width // divider_char_width)\n",
      "            divider += SPACE * (total_width % divider_char_width)\n",
      "\n",
      "            header_buf.write('\\n')\n",
      "            header_buf.write(divider)\n",
      "        return header_buf.getvalue()\n",
      "\n",
      "__________________________________________________-\n",
      "def generate_table(self, table_data, *,\n",
      "                       include_header = True, row_spacing = 1) :\n",
      "\n",
      "        if row_spacing < 0:\n",
      "            raise ValueError(\"Row spacing cannot be less than 0\")\n",
      "\n",
      "        table_buf = io.StringIO()\n",
      "\n",
      "        if include_header:\n",
      "            header = self.generate_header()\n",
      "            table_buf.write(header)\n",
      "            if len(table_data) > 0:\n",
      "                table_buf.write('\\n')\n",
      "\n",
      "        for index, row_data in enumerate(table_data):\n",
      "            if index > 0 and row_spacing > 0:\n",
      "                table_buf.write(row_spacing * '\\n')\n",
      "\n",
      "            row = self.generate_data_row(row_data)\n",
      "            table_buf.write(row)\n",
      "            if index < len(table_data) - 1:\n",
      "                table_buf.write('\\n')\n",
      "\n",
      "        return table_buf.getvalue()\n",
      "\n",
      "__________________________________________________-\n",
      "def __init__(self, cols, *, tab_width = 4,\n",
      "                 column_borders = True, padding = 1) :\n",
      "\n",
      "        super().__init__(cols, tab_width=tab_width)\n",
      "        self.empty_data = [EMPTY for _ in self.cols]\n",
      "        self.column_borders = column_borders\n",
      "\n",
      "        if padding < 0:\n",
      "            raise ValueError(\"Padding cannot be less than 0\")\n",
      "        self.padding = padding\n",
      "\n",
      "__________________________________________________-\n",
      "def base_width(cls, num_cols, *, column_borders = True, padding = 1) :\n",
      "\n",
      "        if num_cols < 1:\n",
      "            raise ValueError(\"Column count cannot be less than 1\")\n",
      "\n",
      "        data_str = SPACE\n",
      "        data_width = ansi.style_aware_wcswidth(data_str) * num_cols\n",
      "\n",
      "        tbl = cls([Column(data_str)] * num_cols, column_borders=column_borders, padding=padding)\n",
      "        data_row = tbl.generate_data_row([data_str] * num_cols)\n",
      "\n",
      "        return ansi.style_aware_wcswidth(data_row) - data_width\n",
      "\n",
      "__________________________________________________-\n",
      "def generate_data_row(self, row_data) :\n",
      "\n",
      "        pre_line = '║' + self.padding * SPACE\n",
      "\n",
      "        inter_cell = self.padding * SPACE\n",
      "        if self.column_borders:\n",
      "            inter_cell += '│'\n",
      "        inter_cell += self.padding * SPACE\n",
      "\n",
      "        post_line = self.padding * SPACE + '║'\n",
      "\n",
      "        return self.generate_row(row_data=row_data, pre_line=pre_line, inter_cell=inter_cell, post_line=post_line)\n",
      "\n",
      "__________________________________________________-\n",
      "def total_width(self) :\n",
      "\n",
      "        base_width = self.base_width(len(self.cols), column_borders=self.column_borders, padding=self.padding)\n",
      "        data_width = sum(col.width for col in self.cols)\n",
      "        return base_width + data_width\n",
      "\n",
      "__________________________________________________-\n",
      "def generate_header(self) :\n",
      "\n",
      "        pre_line = '║' + self.padding * SPACE\n",
      "\n",
      "        inter_cell = self.padding * SPACE\n",
      "        if self.column_borders:\n",
      "            inter_cell += '│'\n",
      "        inter_cell += self.padding * SPACE\n",
      "\n",
      "        post_line = self.padding * SPACE + '║'\n",
      "\n",
      "        # Create the bordered header\n",
      "        header_buf = io.StringIO()\n",
      "        header_buf.write(self.generate_table_top_border())\n",
      "        header_buf.write('\\n')\n",
      "        header_buf.write(self.generate_row(pre_line=pre_line, inter_cell=inter_cell, post_line=post_line))\n",
      "        header_buf.write('\\n')\n",
      "        header_buf.write(self.generate_header_bottom_border())\n",
      "\n",
      "        return header_buf.getvalue()\n",
      "\n",
      "__________________________________________________-\n",
      "def generate_table(self, table_data, *, include_header = True) :\n",
      "\n",
      "        table_buf = io.StringIO()\n",
      "\n",
      "        if include_header:\n",
      "            header = self.generate_header()\n",
      "            table_buf.write(header)\n",
      "        else:\n",
      "            top_border = self.generate_table_top_border()\n",
      "            table_buf.write(top_border)\n",
      "\n",
      "        table_buf.write('\\n')\n",
      "\n",
      "        for index, row_data in enumerate(table_data):\n",
      "            if index > 0:\n",
      "                row_bottom_border = self.generate_row_bottom_border()\n",
      "                table_buf.write(row_bottom_border)\n",
      "                table_buf.write('\\n')\n",
      "\n",
      "            row = self.generate_data_row(row_data)\n",
      "            table_buf.write(row)\n",
      "            table_buf.write('\\n')\n",
      "\n",
      "        table_buf.write(self.generate_table_bottom_border())\n",
      "        return table_buf.getvalue()\n",
      "\n",
      "__________________________________________________-\n",
      "def __init__(self, cols, *, tab_width = 4, column_borders = True, padding = 1,\n",
      "                 bg_odd = None, bg_even = ansi.bg.bright_black) :\n",
      "\n",
      "        super().__init__(cols, tab_width=tab_width, column_borders=column_borders, padding=padding)\n",
      "        self.row_num = 1\n",
      "        self.bg_odd = None if bg_odd is None else functools.partial(ansi.style, bg=bg_odd)\n",
      "        self.bg_even = None if bg_even is None else functools.partial(ansi.style, bg=bg_even)\n",
      "\n",
      "__________________________________________________-\n",
      "def _apply_bg_color(self, data) :\n",
      "\n",
      "        if self.row_num % 2 == 0 and self.bg_even is not None:\n",
      "            return self.bg_even(data)\n",
      "        elif self.row_num % 2 != 0 and self.bg_odd is not None:\n",
      "            return self.bg_odd(data)\n",
      "        else:\n",
      "            return str(data)\n",
      "\n",
      "__________________________________________________-\n",
      "def generate_data_row(self, row_data) :\n",
      "\n",
      "        pre_line = '║' + self.padding * SPACE\n",
      "\n",
      "        inter_cell = self.padding * SPACE\n",
      "        if self.column_borders:\n",
      "            inter_cell += '│'\n",
      "        inter_cell += self.padding * SPACE\n",
      "\n",
      "        post_line = self.padding * SPACE + '║'\n",
      "\n",
      "        fill_char = self._apply_bg_color(SPACE)\n",
      "        pre_line = self._apply_bg_color(pre_line)\n",
      "        inter_cell = self._apply_bg_color(inter_cell)\n",
      "        post_line = self._apply_bg_color(post_line)\n",
      "\n",
      "        # Apply appropriate background color to data, but don't change the original\n",
      "        to_display = [self._apply_bg_color(col) for col in row_data]\n",
      "\n",
      "        row = self.generate_row(row_data=to_display, fill_char=fill_char, pre_line=pre_line,\n",
      "                                inter_cell=inter_cell, post_line=post_line)\n",
      "        self.row_num += 1\n",
      "        return row\n",
      "\n",
      "__________________________________________________-\n",
      "def generate_table(self, table_data, *, include_header = True) :\n",
      "\n",
      "        table_buf = io.StringIO()\n",
      "\n",
      "        if include_header:\n",
      "            header = self.generate_header()\n",
      "            table_buf.write(header)\n",
      "        else:\n",
      "            top_border = self.generate_table_top_border()\n",
      "            table_buf.write(top_border)\n",
      "\n",
      "        table_buf.write('\\n')\n",
      "\n",
      "        for row_data in table_data:\n",
      "            row = self.generate_data_row(row_data)\n",
      "            table_buf.write(row)\n",
      "            table_buf.write('\\n')\n",
      "\n",
      "        table_buf.write(self.generate_table_bottom_border())\n",
      "        return table_buf.getvalue()\n",
      "\n",
      "__________________________________________________-\n",
      "def style_aware_write(fileobj, msg) :\n",
      "\n",
      "    if allow_style.lower() == STYLE_NEVER.lower() or \\\n",
      "            (allow_style.lower() == STYLE_TERMINAL.lower() and not fileobj.isatty()):\n",
      "        msg = strip_style(msg)\n",
      "    fileobj.write(msg)\n",
      "\n",
      "__________________________________________________-\n",
      "def style_aware_wcswidth(text) :\n",
      "\n",
      "    # Strip ANSI style sequences since they cause wcswidth to return -1\n",
      "    return wcswidth(strip_style(text))\n",
      "\n",
      "__________________________________________________-\n",
      "def strip_style(text) :\n",
      "\n",
      "    return ANSI_STYLE_RE.sub('', text)\n",
      "\n",
      "__________________________________________________-\n",
      "def style(text, *, fg = '', bg = '', bold = False,\n",
      "          dim = False, underline = False) :\n",
      "\n",
      "    # List of strings that add style\n",
      "    additions = []\n",
      "\n",
      "    # List of strings that remove style\n",
      "    removals = []\n",
      "\n",
      "    # Convert the text object into a string if it isn't already one\n",
      "    text = \"{}\".format(text)\n",
      "\n",
      "    # Process the style settings\n",
      "    if fg:\n",
      "        additions.append(fg_lookup(fg))\n",
      "        removals.append(FG_RESET)\n",
      "\n",
      "    if bg:\n",
      "        additions.append(bg_lookup(bg))\n",
      "        removals.append(BG_RESET)\n",
      "\n",
      "    if bold:\n",
      "        additions.append(INTENSITY_BRIGHT)\n",
      "        removals.append(INTENSITY_NORMAL)\n",
      "\n",
      "    if dim:\n",
      "        additions.append(INTENSITY_DIM)\n",
      "        removals.append(INTENSITY_NORMAL)\n",
      "\n",
      "    if underline:\n",
      "        additions.append(UNDERLINE_ENABLE)\n",
      "        removals.append(UNDERLINE_DISABLE)\n",
      "\n",
      "    # Combine the ANSI style sequences with the text\n",
      "    return \"\".join(additions) + text + \"\".join(removals)\n",
      "\n",
      "__________________________________________________-\n",
      "def __str__(self) :\n",
      "\n",
      "        return str(self.value)\n",
      "\n",
      "__________________________________________________-\n",
      "def __add__(self, other) :\n",
      "\n",
      "        return str(self) + other\n",
      "\n",
      "__________________________________________________-\n"
     ]
    }
   ],
   "source": [
    "for v,i in romanov.iloc[:50].iterrows():\n",
    "    print(i['body'])\n",
    "    print(infer(model, i['body']), i['arg_types'])\n",
    "    print('__________________________________________________-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "selected-indiana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_enc = preprocessing.LabelEncoder()\n",
    "\n",
    "df_labels = pd.DataFrame(romanov_consistent['arg_types'].values.tolist())\n",
    "df_labels[pd.isnull(df_labels)]  = NaN_symbol\n",
    "all_types = df_labels.apply(pd.Series).stack().values\n",
    "r_enc.fit(all_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "blank-costs",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " 'Any',\n",
       " 'DataFrame',\n",
       " 'Type',\n",
       " 'bool',\n",
       " 'bytes',\n",
       " 'dict',\n",
       " 'float',\n",
       " 'int',\n",
       " 'list',\n",
       " 'object',\n",
       " 'str',\n",
       " 'type'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(r_enc.classes_).intersection(set(enc.classes_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
