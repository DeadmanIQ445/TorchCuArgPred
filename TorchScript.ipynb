{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "general-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from torch import nn\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "third-governor",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "TRAIN_TEST_SPLIT = 0.9\n",
    "DS_PATH = \"/home/deadman445/PycharmProjects/CuArgPred/data/_all_data2.csv\"\n",
    "EPOCHS = 3\n",
    "FREQ_LIMIT = 100\n",
    "\n",
    "# FREQ_LIMIT = 200\n",
    "FREQ_CUT_SYMBOL = \"<UNK>\"\n",
    "NaN_symbol = ''\n",
    "MAX_CUT = 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "guided-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "bert = AutoModel.from_pretrained(\"microsoft/codebert-base\", torchscript=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "minute-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DS_PATH)\n",
    "data['arg_types'] = data['arg_types'].apply(eval)\n",
    "data = data[data.arg_types.astype(bool)]\n",
    "df_labels = pd.DataFrame(data['arg_types'].values.tolist())\n",
    "df_labels[pd.isnull(df_labels)]  = NaN_symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hindu-january",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas\n"
     ]
    }
   ],
   "source": [
    "print(data.iloc[74997]['repo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mechanical-christianity",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'Arguments'), Text(0.5, 1.0, 'Number of arguments per method')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 595.44x595.44 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set(rc={'figure.figsize':(8.27,8.27)})\n",
    "sns.set_style(\"darkgrid\")\n",
    "ax = sns.boxplot(y=data['arg_types'].apply(len).sort_values(ascending=False).iloc[1:], )\n",
    "ax.set(ylabel='Arguments', title='Number of arguments per method')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "persistent-graham",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deadman445/anaconda3/envs/torchdimplom/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='repo'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 595.44x595.44 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data.repo.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "destroyed-jaguar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 100.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x595.44 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(4,8.27)})\n",
    "\n",
    "ax = sns.barplot(x=[20,50,100,200],y=[84.3, 82.5, 79, 73], palette='cubehelix')\n",
    "ax.set(ylabel='Accuracy', title='Model Performance', xlabel='Number of Types')\n",
    "ax.set_ylim(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-import",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels.apply(pd.Series.value_counts).sum(axis=1).sort_values(ascending=False).iloc[1:].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "passive-honor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'Number of arguments with type'),\n",
       " Text(0.5, 0, 'Type'),\n",
       " Text(0.5, 1.0, 'Number of arguments with type')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x595.44 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(12.5,8.27)})\n",
    "\n",
    "ax = sns.barplot(x= df_labels.apply(pd.Series.value_counts).sum(axis=1).sort_values(ascending=False).iloc[1:], y=df_labels.apply(pd.Series.value_counts).sum(axis=1).sort_values(ascending=False).iloc[1:])\n",
    "\n",
    "\n",
    "ax.set_xticklabels('')\n",
    "ax.set(ylabel='Number of arguments with type', xlabel='Type', title='Number of arguments with type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "distant-burns",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                 5515939\n",
       "<UNK>              74765\n",
       "list                6051\n",
       "dict                6020\n",
       "bool                6005\n",
       "str                 5977\n",
       "int                 5941\n",
       "Any                 5653\n",
       "float               5232\n",
       "callable            3335\n",
       "Path                2759\n",
       "HttpRequest         2234\n",
       "HomeAssistant       2223\n",
       "UserProfile         2148\n",
       "iterable            2072\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_composite(p):\n",
    "    a = []\n",
    "    for i in p:\n",
    "        if 'tuple' in i.lower():\n",
    "            a.append(i)\n",
    "            continue\n",
    "        if '[' in i and not 'Union' in i:\n",
    "            b = i.split('[')                \n",
    "            if 'Optional' == b[0]:\n",
    "                if len(b)>1:\n",
    "                    a.append(b[1].split(']')[0].lower())\n",
    "                else:\n",
    "                    a.append(b[0].lower())\n",
    "            else:\n",
    "                a.append(b[0].lower())\n",
    "        else:\n",
    "            if i=='List' or i=='Dict' or i=='Callable':\n",
    "                a.append(i.lower())                \n",
    "            else:\n",
    "                a.append(i.split('.')[-1])\n",
    "    return a\n",
    "\n",
    "def replace_type(df, typ='str', frac=0.9):\n",
    "    df2= df.copy()\n",
    "    str_cvrt = func(typ)\n",
    "    df2.update(df[df.eq(typ).any(axis=1)].sample(frac=frac).apply(str_cvrt))\n",
    "    return df2\n",
    "\n",
    "\n",
    "def func(typ):\n",
    "    def cvrt(p):\n",
    "        a = []\n",
    "        for i in p:\n",
    "            if i == typ:\n",
    "                a.append(FREQ_CUT_SYMBOL)\n",
    "            else:\n",
    "                a.append(i)\n",
    "        return a\n",
    "    return cvrt\n",
    "\n",
    "dd = df_labels.apply(remove_composite)\n",
    "for (k,v) in dict(dd.apply(pd.Series.value_counts).sum(axis=1).sort_values(ascending=False)).items():\n",
    "    if k!=FREQ_CUT_SYMBOL and k!=NaN_symbol and v>MAX_CUT:\n",
    "        dd = replace_type(dd, k, (v-MAX_CUT)/v) \n",
    "df_labels = dd\n",
    "df_labels = dd\n",
    "dd.apply(pd.Series.value_counts).sum(axis=1).sort_values(ascending=False).head(15).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "consecutive-revision",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[''] ['<UNK>']\n",
      "Enc for \"NaN\" [0], Enc for FREQ_CUT_SYMBOL [2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def la(data_batch_i):\n",
    "    r = []\n",
    "    \n",
    "    for i in data_batch_i:\n",
    "        if not (i == NaN_enc[0] or i==FREQ_CUT_ENC[0] or i==Any_enc[0]):\n",
    "            r.append(i)\n",
    "        if i==FREQ_CUT_ENC[0] or i==Any_enc[0]:\n",
    "            r.append(NaN_enc[0])\n",
    "    if len(r) == 0 or sum(r)==0:\n",
    "        return pd.NA\n",
    "    return r\n",
    "\n",
    "df_labels = df_labels.apply(lambda x: x.mask(x.map(x.value_counts())<FREQ_LIMIT, FREQ_CUT_SYMBOL))\n",
    "enc = preprocessing.LabelEncoder()\n",
    "all_types = df_labels.apply(pd.Series).stack().values\n",
    "enc.fit(all_types)\n",
    "FREQ_CUT_ENC = enc.transform([FREQ_CUT_SYMBOL])\n",
    "NaN_enc = enc.transform([NaN_symbol])\n",
    "Any_enc = enc.transform(['Any'])\n",
    "print(enc.inverse_transform(NaN_enc), enc.inverse_transform(FREQ_CUT_ENC))\n",
    "print(f'Enc for \"NaN\" {NaN_enc}, Enc for FREQ_CUT_SYMBOL {FREQ_CUT_ENC}')\n",
    "df3 = df_labels.apply(enc.transform)\n",
    "data['labels'] = df3.values.tolist()\n",
    "\n",
    "data['labels'] = data['labels'].apply(la)\n",
    "data = data.dropna(subset=['labels'], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "def train_test_by_repo(data, split=0.75):\n",
    "    train_l = []\n",
    "    test_l = []\n",
    "    c = 0\n",
    "    train_len = split * len(data)\n",
    "    for name, i in data.groupby(['repo']).count().sample(frac=1).iterrows():\n",
    "        if train_len > c:\n",
    "            train_l.append(name)\n",
    "            c += i['author']\n",
    "        else:\n",
    "            test_l.append(name)\n",
    "    return data.loc[data['repo'].isin(train_l)], data.loc[data['repo'].isin(test_l)]\n",
    "\n",
    "\n",
    "\n",
    "train_ds, test_ds = train_test_by_repo(data, TRAIN_TEST_SPLIT)\n",
    "\n",
    "\n",
    "len(enc.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "decent-monroe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"types.txt\", 'w') as f:\n",
    "    for i in enc.classes_:\n",
    "        f.write(i)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "meaning-density",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: GeForce RTX 2060 SUPER\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sustainable-globe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "backed-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_elem(data_batch_i):\n",
    "    sentence_line =  tokenizer(data_batch_i['body'], return_tensors='pt', padding='max_length', truncation=True)\n",
    "    sentence_line1 = tokenizer(data_batch_i['body'], padding='max_length', truncation=True,  return_offsets_mapping=True, return_length=True)\n",
    "    args = get_names(data_batch_i['body'])\n",
    "    labels = dict(zip([i[0] for i in args], data_batch_i['labels']))\n",
    "    args = offset2ind(args, sentence_line1)\n",
    "    ids = torch.zeros_like(sentence_line['input_ids'])\n",
    "    for i in args:\n",
    "        ids[0][i[1]]=labels.get(i[0], NaN_enc[0])\n",
    "    return sentence_line, ids\n",
    "\n",
    "def offset2ind(args, tokens):\n",
    "    def find(tok, lis):\n",
    "        r = []\n",
    "        for i in lis:\n",
    "            if i[0]>=tok[1][0] and i[1]<=tok[1][1]:\n",
    "                r.append(i)\n",
    "                break\n",
    "        b = [lis.index(i) for i in r]\n",
    "        return b\n",
    "    return [(i[0], find(i,tokens['offset_mapping'])) for i in args]\n",
    "\n",
    "\n",
    "def get_names(src):\n",
    "    ret = []\n",
    "    line_lengths = [len(i) for i in src.split('\\n')]\n",
    "    line_lengths = [0] + line_lengths\n",
    "    for i in range(1,len(line_lengths)):\n",
    "        line_lengths[i] += line_lengths[i-1]+1\n",
    "    \n",
    "    try:\n",
    "        for node in ast.walk(ast.parse(src)):\n",
    "            if isinstance(node, ast.arg):\n",
    "                ret.append((node.arg,(line_lengths[node.lineno-1]+node.col_offset, line_lengths[node.lineno-1]+node.end_col_offset)))\n",
    "        return ret\n",
    "    except:\n",
    "        print(\"Could Not process the code\")\n",
    "        return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "outside-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JITDataDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.data = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        data_batch = self.data.iloc[idx, :]\n",
    "        full_sentence, ids = process_elem(data_batch)\n",
    "        return (full_sentence['input_ids'].squeeze().to(device),\n",
    "                full_sentence['attention_mask'].squeeze().to(device),\n",
    "                (ids > 0).squeeze().to(device),\n",
    "                ids.squeeze().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "drawn-posting",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DataLoader(JITDataDataset(train_ds), batch_size=8,\n",
    "                        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "reverse-chase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class JITModel(torch.nn.Module):\n",
    "    def __init__(self, bert, out_dim):\n",
    "        super().__init__()\n",
    "        self.out_dim = out_dim\n",
    "        self.bert = bert\n",
    "#         \n",
    "        self.dense = nn.Linear(768, out_dim)\n",
    "\n",
    "    def forward(self, a,b,c,d):\n",
    "        \n",
    "        emb = self.bert(a, attention_mask=b)[0]\n",
    "        out = self.dense(emb)\n",
    "        mask = c.unsqueeze(-1).expand(out.size())\n",
    "        masked = torch.masked_select(out, mask).reshape(len(torch.masked_select(d, c)),self.out_dim)\n",
    "        return F.softmax(masked)\n",
    "#          masked\n",
    "\n",
    "\n",
    "model = JITModel(bert, len(enc.classes_))\n",
    "model.to(device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "compressed-psychiatry",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-1bb9bf69454d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "cpu = torch.device(\"cpu\")\n",
    "a = next(iter(test))\n",
    "model.to(cpu)\n",
    "model.bert.to(cpu)\n",
    "model.bert = torch.jit.trace(model.bert, (a[0].to(cpu), a[1].to(cpu)))\n",
    "\n",
    "traced_model = torch.jit.script(model)\n",
    "torch.jit.save(traced_model, \"latest_bert_tune.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "signed-plastic",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=7\n",
    "for name, param in bert.named_parameters():                                            \n",
    "    if f'encoder.layer.{i}' in name:\n",
    "        param.requires_grad = True\n",
    "        i+=1\n",
    "    else:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bottom-magnet",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "intermediate-editing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5a582021b0461897e5a9d61c364cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-77c050f7d939>:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(masked)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['float' 'dict' 'float' 'Path' 'bytes' 'dict' 'int' 'list' 'list' 'float'] ['datetime' 'dict' 'float' 'Path' 'bytes' 'dict' 'str' 'list' 'list' 'int']\n",
      "['Params' 'str' 'bool' 'str' 'Session' 'bool' 'list' 'str' 'dict'] ['Params' 'str' 'bool' 'int' 'object' 'bool' 'set' 'str' 'mapping']\n",
      "['dict' 'str' 'datetime' 'HomeAssistantType' 'list' 'bool' 'dict' 'list'] ['dict' 'bytes' 'datetime' 'HomeAssistantType' 'iterable' 'bool' 'bool'\n",
      " 'list']\n",
      "['HomeAssistant' 'dict' 'Tensor' 'str' 'Contract' 'dict' 'int' 'Params'\n",
      " 'dict' 'ndarray' 'ndarray' 'ndarray' 'float'] ['HomeAssistant' 'list' 'iterable' 'str' 'str' 'dict' 'int' 'Parameters'\n",
      " 'dict' 'Tensor' 'Tensor' 'Tensor' 'float']\n",
      "['float' 'type' 'object' 'HomeAssistant' 'dict' 'bool' 'list' 'list'\n",
      " 'bool' 'HomeAssistant' 'ConfigEntry' 'Session'] ['float' 'type' 'str' 'HomeAssistant' 'dict' 'bool' 'list' 'list' 'list'\n",
      " 'HomeAssistant' 'ConfigEntry' 'Session']\n",
      "['dict' 'dict' 'str' 'list' 'Element' 'Settings' 'int' 'bool' 'list'] ['T' 'dict' 'str' 'DataFrame' 'Element' 'Settings' 'int' 'bool' 'list']\n",
      "['datetime' 'dict' 'HomeAssistant' 'ConfigEntry' 'Event' 'list' 'float'\n",
      " 'float' 'dict' 'dict' 'dict' 'float' 'float' 'float' 'float'] ['datetime' 'dict' 'HomeAssistant' 'ConfigEntry' 'Event' 'list' 'callable'\n",
      " 'float' 'dict' 'dict' 'dict' 'float' 'float' 'float' 'float']\n",
      "['TemplateObjectVariable' 'TemplateObjectVariable' 'languagegenerator'\n",
      " 'UserProfile' 'View' 'Context' 'dict' 'ndarray' 'float' 'object'] ['TemplateObjectVariable' 'TemplateObjectVariable' 'languagegenerator'\n",
      " 'UserProfile' 'View' 'Context' 'ConfigType' 'array' 'float' 'object']\n",
      "['str' 'bytes' 'dict' 'UserProfile' 'DataFrame' 'datetime' 'datetime'\n",
      " 'Session' 'float' 'float' 'float' 'Namespace' 'bool'] ['str' 'bytes' 'dict' 'UserProfile' 'DataFrame' 'datetime' 'datetime'\n",
      " 'State' 'float' 'float' 'float' 'Namespace' 'bool']\n",
      "['ConfigType' 'str' 'int' 'str' 'str' 'bool' 'HttpRequest' 'UserProfile'\n",
      " 'Context' 'dict' 'bool' 'dict' 'str'] ['ConfigType' 'str' 'bytes' 'bytes' 'bytes' 'bool' 'HttpRequest'\n",
      " 'UserProfile' 'Context' 'bytes' 'bool' 'dict' 'callable']\n",
      "['callable' 'HomeAssistantType' 'AiohttpClientMocker' 'Contract' 'Config'\n",
      " 'Path' 'type' 'bytes' 'callable' 'ndarray' 'list'] ['callable' 'HomeAssistantType' 'AiohttpClientMocker' 'Contract'\n",
      " 'ConfigType' 'str' 'type' 'bytes' 'callable' 'ndarray' 'list']\n",
      "['Message' 'View' 'Context' 'bool' 'Path' 'int' 'HttpRequest'\n",
      " 'HomeAssistantType' 'ConfigEntry' 'bool' 'iterable'] ['Message' 'View' 'Context' 'bool' 'Path' 'int' 'Request'\n",
      " 'HomeAssistantType' 'ConfigEntry' 'bool' 'str']\n",
      "['callable' 'Path' 'bool' 'Namespace' 'float' 'Circuit' 'dict'\n",
      " '_SubParsersAction' 'HomeAssistantType'] ['callable' 'Path' 'bool' 'dict' 'list' 'Circuit' 'ndarray'\n",
      " '_SubParsersAction' 'HomeAssistantType']\n"
     ]
    }
   ],
   "source": [
    "opti = torch.optim.Adam(model.parameters(), lr = 1e-6)\n",
    "pbar = tqdm(total=len(train))\n",
    "losses = []\n",
    "accuracy = []\n",
    "for i,a in enumerate(train):\n",
    "    out = model.forward(a[0], a[1], a[2], a[3])\n",
    "    \n",
    "#     mask = a[2].unsqueeze(-1).expand(out.size())\n",
    "#     masked = torch.masked_select(out, mask).reshape(len(torch.masked_select(a[3], a[2])),len(enc.classes_))\n",
    "    \n",
    "    \n",
    "    labels = torch.masked_select(a[3], a[2])\n",
    "    loss = F.nll_loss(torch.log(out), labels)\n",
    "    if i % 500==0:\n",
    "        print(enc.inverse_transform(torch.argmax(out.cpu(), dim=1)), enc.inverse_transform(labels.cpu()))\n",
    "    loss.backward()\n",
    "\n",
    "    if torch.isnan(loss):\n",
    "#         print(a)\n",
    "        pass\n",
    "    else:\n",
    "        accuracy.append(sum(torch.argmax(out.detach(), dim=1) == labels)/len(labels))\n",
    "        losses.append(loss.detach())\n",
    "    opti.step()\n",
    "    if i % 1 ==0:\n",
    "        pbar.set_description(f\"Loss : { sum(losses)/len(losses)}, acc: {sum(accuracy)/len(accuracy)}\")\n",
    "    pbar.update(1)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "double-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_av = lambda x : sum(x)/len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "russian-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = DataLoader(JITDataDataset(test_ds), batch_size=1, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "olive-migration",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e1ed74cb364f4d85fb3e0ab2cda8b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5290 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-77c050f7d939>:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(masked)\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(total=len(test))\n",
    "test_top_5s = []\n",
    "test_accuracy = []\n",
    "test_losses = []\n",
    "test_true = []\n",
    "test_pred = []\n",
    "for i,a in enumerate(test):\n",
    "    out = model.forward(a[0], a[1], a[2], a[3])\n",
    "    labels = torch.masked_select(a[3], a[2])\n",
    "    loss = F.nll_loss(torch.log(out), labels)\n",
    "\n",
    "    if torch.isnan(loss):\n",
    "#         print(a)\n",
    "        pass\n",
    "    else:\n",
    "        test_pred = test_pred + list(enc.inverse_transform(torch.argmax(out.cpu(), dim=1)))\n",
    "        test_true = test_true + list(enc.inverse_transform(labels.cpu()))\n",
    "        test_accuracy.append(sum(torch.argmax(out, dim=1) == labels).detach()/len(labels))\n",
    "        test_losses.append(loss.detach())\n",
    "        top5s = torch.topk(out, 5).indices\n",
    "        correct_top5 = 0\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] in top5s[i]:\n",
    "                correct_top5 += 1\n",
    "        test_top_5s.append(correct_top5/len(labels))\n",
    "    \n",
    "    if i % 20 ==0:\n",
    "        pbar.set_description(f\"Loss : { pr_av(test_losses)}, acc: {pr_av(test_accuracy)}, top5s: {pr_av(test_top_5s)}\")\n",
    "    pbar.update(1)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fewer-seventh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                   AST       0.00      0.00      0.00         6\n",
      "       AUTH_USER_MODEL       1.00      0.36      0.53        22\n",
      "      ActiveConnection       1.00      1.00      1.00        15\n",
      "                   App       0.00      0.00      0.00         0\n",
      "           Application       0.00      0.00      0.00        16\n",
      "        ArgumentParser       0.50      1.00      0.67         2\n",
      "                Buffer       1.00      0.11      0.20        44\n",
      "                Client       0.10      0.50      0.16         4\n",
      "                Config       0.80      0.31      0.44        26\n",
      "           ConfigEntry       0.96      1.00      0.98        24\n",
      "            ConfigType       0.74      0.90      0.81        69\n",
      "         Configuration       0.00      0.00      0.00         2\n",
      "             Container       1.00      0.01      0.02        87\n",
      "               Context       0.89      0.89      0.89        44\n",
      "              Contract       0.00      0.00      0.00         0\n",
      "             DataFrame       0.86      0.92      0.89        59\n",
      "              Database       0.61      0.74      0.67        19\n",
      "  DatabaseSchemaEditor       1.00      1.00      1.00        40\n",
      "               Element       0.42      0.56      0.48         9\n",
      "                 Event       0.36      1.00      0.53         5\n",
      "             Exception       1.00      0.62      0.77         8\n",
      "                 Flask       0.00      0.00      0.00        14\n",
      "                 Graph       0.00      0.00      0.00         1\n",
      "         HomeAssistant       0.78      0.94      0.85       121\n",
      "     HomeAssistantType       0.92      0.77      0.83       128\n",
      "           HttpRequest       0.96      0.99      0.98       700\n",
      "                Logger       1.00      0.75      0.86         4\n",
      "               Message       0.86      0.72      0.78        25\n",
      "                 Model       0.29      0.44      0.35         9\n",
      "                Module       0.00      0.00      0.00         2\n",
      "             Namespace       0.85      0.80      0.83        65\n",
      "                  Node       0.69      0.97      0.81        30\n",
      "                  Nvim       0.00      0.00      0.00        22\n",
      "                Params       0.91      0.91      0.91        22\n",
      "                  Path       0.69      0.85      0.76       181\n",
      "                 Realm       0.99      1.00      1.00       114\n",
      "               Request       0.95      0.72      0.82        96\n",
      "              Response       1.00      0.18      0.31        11\n",
      "        SafeLineLoader       0.95      1.00      0.97        18\n",
      "               Session       0.46      0.90      0.61        67\n",
      "                Sphinx       0.00      0.00      0.00         0\n",
      "                 State       1.00      0.80      0.89         5\n",
      "             StateApps       0.95      1.00      0.98        40\n",
      "                Symbol       0.00      0.00      0.00        54\n",
      "                     T       0.00      0.00      0.00        18\n",
      "TemplateObjectVariable       0.00      0.00      0.00         0\n",
      "                Tensor       0.07      0.15      0.09        26\n",
      "                  Text       0.00      0.00      0.00       446\n",
      "                TextIO       0.00      0.00      0.00         6\n",
      "                  Type       0.17      0.60      0.26         5\n",
      "      Union[str, Path]       0.00      0.00      0.00        10\n",
      "     Union[str, bytes]       0.00      0.00      0.00        46\n",
      "                  User       0.52      0.94      0.67        33\n",
      "                UserID       0.00      0.00      0.00         0\n",
      "           UserProfile       0.97      0.95      0.96       436\n",
      "                  View       1.00      1.00      1.00         3\n",
      "           _MakeClient       0.00      0.00      0.00         0\n",
      "     _SubParsersAction       0.00      0.00      0.00         8\n",
      "                 array       0.00      0.00      0.00        22\n",
      "                  bool       0.94      0.94      0.94       564\n",
      "                 bytes       0.52      0.59      0.55       150\n",
      "              callable       0.87      0.86      0.86       235\n",
      "              datetime       0.82      0.76      0.79       105\n",
      "                  dict       0.70      0.86      0.77       581\n",
      "                 float       0.71      0.78      0.75       399\n",
      "                   int       0.79      0.77      0.78       610\n",
      "                    io       0.00      0.00      0.00        11\n",
      "              iterable       0.43      0.08      0.14       181\n",
      "              iterator       0.00      0.00      0.00        38\n",
      "                  list       0.46      0.84      0.60       421\n",
      "               mapping       1.00      0.19      0.32       119\n",
      "               ndarray       0.49      0.50      0.49       143\n",
      "                object       0.64      0.20      0.31        45\n",
      "              sequence       0.22      0.02      0.04        92\n",
      "                   set       0.00      0.00      0.00        61\n",
      "                   str       0.32      0.71      0.44       414\n",
      "                t.type       0.00      0.00      0.00        58\n",
      "                  type       0.40      0.63      0.49        68\n",
      "           typing.list       0.00      0.00      0.00         8\n",
      "\n",
      "              accuracy                           0.69      7592\n",
      "             macro avg       0.49      0.47      0.44      7592\n",
      "          weighted avg       0.66      0.69      0.65      7592\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deadman445/anaconda3/envs/torchdimplom/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/deadman445/anaconda3/envs/torchdimplom/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/deadman445/anaconda3/envs/torchdimplom/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/deadman445/anaconda3/envs/torchdimplom/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/deadman445/anaconda3/envs/torchdimplom/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/deadman445/anaconda3/envs/torchdimplom/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "\n",
    "print(classification_report(test_true, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-oxygen",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "delayed-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def transform_to_model(method, dev):\n",
    "    data_batch={'body':method, 'labels':[1]*len(get_names(method))}\n",
    "    full_sentence, ids = process_elem(data_batch)\n",
    "    return (full_sentence['input_ids'].to(dev),\n",
    "            full_sentence['attention_mask'].to(dev),\n",
    "            (ids > 0).to(dev),\n",
    "            ids.to(dev))\n",
    "\n",
    "def infer(model, method):\n",
    "    a = transform_to_model(method, device)\n",
    "    out = model.forward(a[0], a[1], a[2], a[3])\n",
    "    ret = enc.inverse_transform(torch.argmax(out.cpu(), dim=1))\n",
    "    top5s = torch.topk(out, 5).indices.cpu()\n",
    "#     for i in top5s:\n",
    "#         print(\"Top5: \",enc.inverse_transform(i))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "occupied-camel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-77c050f7d939>:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(masked)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['float', 'str', 'str'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method='def func(age, street, name = (fun, 1, (2,3))):\\n\\\n",
    "    if (name == \"Vadim\"):\\n\\\n",
    "        print(\"smth is wrong\")\\n\\\n",
    "    else:\\n\\\n",
    "        print(\"Navanyi\")\\n\\\n",
    "    print(age, street)\\n\\\n",
    "    print(name, age, street)\\n'\n",
    "infer(model, method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "standing-ambassador",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-77c050f7d939>:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(masked)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['int', 'str', 'list'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('file','r') as f:\n",
    "    method = \"\\n\".join(f.readlines())\n",
    "infer(model, method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "surprised-hartford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ents                            [[26, 30, str], [19, 24, object]]\n",
       "cats                                                       [None]\n",
       "replacements    [[4, 12, 1429698], [13, 17, 1430619], [38, 42,...\n",
       "docstrings      [        \"\"\"\\n        CompletionItem Initializ...\n",
       "arg_types                                           [str, object]\n",
       "body            def __init__(self, value, desc = '', *args, **...\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "romanov.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "robust-hebrew",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def __new__(cls, value, *args, **kwargs) :\\n        return super().__new__(cls, value)\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "romanov.iloc[1]['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "forward-player",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-77c050f7d939>:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(masked)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['type', 'str', 'list', 'dict'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer(model,romanov.iloc[1]['body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-polyester",
   "metadata": {},
   "source": [
    "'CC' вместо нее G\n",
    "\n",
    "Gdef\n",
    "\n",
    "):\n",
    "\n",
    "G(\n",
    "\n",
    "G==\n",
    "\n",
    "pri vet    priv et\n",
    "\n",
    "\\\\\n",
    "\n",
    "\"\" а уменя нет\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-assembly",
   "metadata": {},
   "source": [
    "# Romanov dataset test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "green-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "romanov = pd.read_json('./annotated_functios/functions_with_annotations.jsonl', lines=True)\n",
    "\n",
    "rm_extra_ents = lambda i:[x[2] for x in i]\n",
    "romanov['arg_types']=romanov['ents'].apply(rm_extra_ents)\n",
    "\n",
    "romanov['body']=romanov['text']\n",
    "del romanov['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "recorded-kansas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ents</th>\n",
       "      <th>cats</th>\n",
       "      <th>replacements</th>\n",
       "      <th>docstrings</th>\n",
       "      <th>arg_types</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[36, 45, Union[int, float]], [25, 34, int]]</td>\n",
       "      <td>[str]</td>\n",
       "      <td>[[4, 24, 1429694], [54, 61, 642357], [84, 93, ...</td>\n",
       "      <td>[    \"\"\"Generate an error message when the the...</td>\n",
       "      <td>[Union[int, float], int]</td>\n",
       "      <td>def generate_range_error(range_min, range_max)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           ents   cats  \\\n",
       "0  [[36, 45, Union[int, float]], [25, 34, int]]  [str]   \n",
       "\n",
       "                                        replacements  \\\n",
       "0  [[4, 24, 1429694], [54, 61, 642357], [84, 93, ...   \n",
       "\n",
       "                                          docstrings  \\\n",
       "0  [    \"\"\"Generate an error message when the the...   \n",
       "\n",
       "                  arg_types                                               body  \n",
       "0  [Union[int, float], int]  def generate_range_error(range_min, range_max)...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "romanov.iloc[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "funded-assumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_arg_types(line):\n",
    "    args = get_names(line['body'])\n",
    "    types = line['arg_types']\n",
    "    args = [arg for arg in args if arg[0] not in ['self', 'args', 'kwargs']]\n",
    "    if len(args)!=len(types):\n",
    "        return pd.NA\n",
    "    return line\n",
    "\n",
    "romanov_consistent = romanov.apply(change_arg_types, axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "hispanic-medicare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     73916.0\n",
       "str                    677.0\n",
       "int                    366.0\n",
       "bool                   263.0\n",
       "Any                    125.0\n",
       "callable                93.0\n",
       "dict                    76.0\n",
       "bytes                   65.0\n",
       "Description             51.0\n",
       "float                   48.0\n",
       "list                    48.0\n",
       "sequence                45.0\n",
       "Union[str, bytes]       31.0\n",
       "T                       29.0\n",
       "ndarray                 29.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = pd.DataFrame(romanov_consistent['arg_types'].values.tolist())\n",
    "df_labels[pd.isnull(df_labels)]  = NaN_symbol\n",
    "\n",
    "dd = df_labels.apply(remove_composite)\n",
    "for (k,v) in dict(dd.apply(pd.Series.value_counts).sum(axis=1).sort_values(ascending=False)).items():\n",
    "    if k!=FREQ_CUT_SYMBOL and k!=NaN_symbol and v>MAX_CUT:\n",
    "        dd = replace_type(dd, k, (v-MAX_CUT)/v) \n",
    "df_labels = dd\n",
    "df_labels = dd\n",
    "dd.apply(pd.Series.value_counts).sum(axis=1).sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "intermediate-hawaiian",
   "metadata": {},
   "outputs": [],
   "source": [
    "le_dict = dict(zip(enc.classes_, enc.transform(enc.classes_)))\n",
    "label_encode = lambda i:[le_dict.get(x, NaN_enc[0]) for x in i]\n",
    "\n",
    "\n",
    "\n",
    "romanov_consistent['labels']=dd.apply(label_encode).values.tolist()\n",
    "\n",
    "romanov_consistent['labels'] = romanov_consistent['labels'].apply(la)\n",
    "romanov_consistent = romanov_consistent.dropna(subset=['labels'], axis=0)\n",
    "\n",
    "romanov_loader = DataLoader(JITDataDataset(romanov_consistent), batch_size=1, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "romance-construction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3340, 6)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "romanov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "sunrise-watts",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2330, 7)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "romanov_consistent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "suspected-feeding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d7f2e03954426ba240ff5d60bb9ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/949 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-77c050f7d939>:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(masked)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['float'] ['int']\n",
      "['str'] ['str']\n",
      "['bool' 'str' 'bool' 'bool'] ['bool' 'str' 'bool' 'bool']\n",
      "['bool' 'str'] ['str' 'str']\n",
      "['dict'] ['str']\n",
      "['str' 'list'] ['iterable' 'str']\n",
      "['Tensor' 'int'] ['int' 'int']\n",
      "['Tensor' 'int' 'int' 'int'] ['int' 'int' 'bool' 'str']\n",
      "['dict'] ['int']\n",
      "['Path' 'str' 'str'] ['str' 'str' 'str']\n",
      "['callable'] ['sequence']\n",
      "['str' 'list' 'int' 'int'] ['int' 'int' 'int' 'bool']\n",
      "['Path'] ['callable']\n",
      "['callable' 'callable'] ['str' 'bool']\n",
      "['str' 'callable' 'int' 'callable' 'callable' 'callable' 'int'] ['callable' 'float' 'dict' 'float' 'float' 'int' 'list']\n",
      "['Path' 'int' 'int'] ['int' 'int' 'str']\n",
      "['Client' 'str'] ['str' 'str']\n",
      "['type' 'int'] ['str' 'int']\n",
      "['str'] ['str']\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(total=len(romanov_loader))\n",
    "r_top_5s = []\n",
    "r_accuracy = []\n",
    "r_losses = []\n",
    "\n",
    "r_true = []\n",
    "r_pred = []\n",
    "\n",
    "\n",
    "\n",
    "for i,a in enumerate(romanov_loader):\n",
    "    out = model.forward(a[0], a[1], a[2], a[3])\n",
    "    labels = torch.masked_select(a[3], a[2])\n",
    "    loss = F.nll_loss(torch.log(out), labels)\n",
    "\n",
    "    if torch.isnan(loss):\n",
    "        # print(a)\\n\",\n",
    "        pass\n",
    "    else:\n",
    "        r_pred = r_pred + list(enc.inverse_transform(torch.argmax(out.cpu(), dim=1)))\n",
    "        r_true = r_true + list(enc.inverse_transform(labels.cpu()))\n",
    "        if i%50==0:\n",
    "            print(enc.inverse_transform(torch.argmax(out.cpu(), dim=1)), enc.inverse_transform(labels.cpu()))\n",
    "        r_accuracy.append(sum(torch.argmax(out, dim=1) == labels).detach()/len(labels))\n",
    "        r_losses.append(loss.detach())\n",
    "        top5s = torch.topk(out, 5).indices\n",
    "        correct_top5 = 0\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] in top5s[i]:\n",
    "                correct_top5 += 1\n",
    "        r_top_5s.append(correct_top5/len(labels))\n",
    "    \n",
    "    if i % 20 ==0:\n",
    "        pbar.set_description(f\"Loss : { pr_av(r_losses)}, acc: {pr_av(r_accuracy)}, top5s: {pr_av(r_top_5s)}\")\n",
    "    pbar.update(1)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "compatible-karen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Client       0.00      0.00      0.00         0\n",
      "     Context       0.00      0.00      0.00         0\n",
      "   DataFrame       0.16      0.75      0.26         8\n",
      "     Element       0.00      0.00      0.00         0\n",
      "     Message       0.00      0.00      0.00         0\n",
      "   Namespace       0.02      0.33      0.04         3\n",
      "        Node       0.00      0.00      0.00         0\n",
      "        Path       0.00      0.00      0.00         0\n",
      "     Request       0.00      0.00      0.00         0\n",
      "      Tensor       0.00      0.00      0.00         0\n",
      "        Text       0.00      0.00      0.00         0\n",
      "        User       0.00      0.00      0.00         0\n",
      "        bool       0.41      0.20      0.27       264\n",
      "       bytes       0.48      0.43      0.46        65\n",
      "    callable       0.31      0.29      0.30        93\n",
      "    datetime       0.00      0.00      0.00         1\n",
      "        dict       0.18      0.26      0.21        76\n",
      "       float       0.33      0.21      0.26        48\n",
      "         int       0.43      0.33      0.37       366\n",
      "    iterable       0.00      0.00      0.00        13\n",
      "        list       0.15      0.23      0.18        48\n",
      "     mapping       0.50      0.14      0.22        14\n",
      "     ndarray       0.15      0.41      0.22        29\n",
      "    sequence       0.20      0.07      0.10        45\n",
      "         set       0.00      0.00      0.00         0\n",
      "         str       0.63      0.40      0.49       679\n",
      "        type       0.05      0.45      0.09        20\n",
      "\n",
      "    accuracy                           0.32      1772\n",
      "   macro avg       0.15      0.17      0.13      1772\n",
      "weighted avg       0.46      0.32      0.37      1772\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(r_true, r_pred,zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "liked-mustang",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def generate_range_error(range_min, range_max) :\n",
      "\n",
      "    err_str = \"expected \"\n",
      "\n",
      "    if range_max == constants.INFINITY:\n",
      "        err_str += \"at least {} argument\".format(range_min)\n",
      "\n",
      "        if range_min != 1:\n",
      "            err_str += \"s\"\n",
      "    else:\n",
      "        if range_min == range_max:\n",
      "            err_str += \"{} argument\".format(range_min)\n",
      "        else:\n",
      "            err_str += \"{} to {} argument\".format(range_min, range_max)\n",
      "\n",
      "        if range_max != 1:\n",
      "            err_str += \"s\"\n",
      "\n",
      "    return err_str\n",
      "\n",
      "__________________________________________________-\n",
      "def __new__(cls, value, *args, **kwargs) :\n",
      "        return super().__new__(cls, value)\n",
      "\n",
      "__________________________________________________-\n",
      "def __init__(self, value, desc = '', *args, **kwargs) :\n",
      "\n",
      "        super().__init__(*args, **kwargs)\n",
      "        self.description = desc\n",
      "\n",
      "__________________________________________________-\n",
      "def __init__(self, is_method, is_completer, to_call):\n",
      "\n",
      "        self.is_method = is_method\n",
      "        self.is_completer = is_completer\n",
      "        self.to_call = to_call\n",
      "\n",
      "__________________________________________________-\n",
      "def _set_choices_callable(action, choices_callable) :\n",
      "\n",
      "    # Verify consistent use of parameters\n",
      "    if action.choices is not None:\n",
      "        err_msg = (\"None of the following parameters can be used alongside a choices parameter:\\n\"\n",
      "                   \"choices_function, choices_method, completer_function, completer_method\")\n",
      "        raise (TypeError(err_msg))\n",
      "    elif action.nargs == 0:\n",
      "        err_msg = (\"None of the following parameters can be used on an action that takes no arguments:\\n\"\n",
      "                   \"choices_function, choices_method, completer_function, completer_method\")\n",
      "        raise (TypeError(err_msg))\n",
      "\n",
      "    setattr(action, ATTR_CHOICES_CALLABLE, choices_callable)\n",
      "\n",
      "__________________________________________________-\n",
      "def set_choices_function(action, choices_function) :\n",
      "\n",
      "    _set_choices_callable(action, ChoicesCallable(is_method=False, is_completer=False, to_call=choices_function))\n",
      "\n",
      "__________________________________________________-\n",
      "def set_choices_method(action, choices_method) :\n",
      "\n",
      "    _set_choices_callable(action, ChoicesCallable(is_method=True, is_completer=False, to_call=choices_method))\n",
      "\n",
      "__________________________________________________-\n",
      "def set_completer_function(action, completer_function) :\n",
      "\n",
      "    _set_choices_callable(action, ChoicesCallable(is_method=False, is_completer=True, to_call=completer_function))\n",
      "\n",
      "__________________________________________________-\n",
      "def set_completer_method(action, completer_method) :\n",
      "\n",
      "    _set_choices_callable(action, ChoicesCallable(is_method=True, is_completer=True, to_call=completer_method))\n",
      "\n",
      "__________________________________________________-\n",
      "def _add_argument_wrapper(self, *args,\n",
      "                          nargs = None,\n",
      "                          choices_function = None,\n",
      "                          choices_method = None,\n",
      "                          completer_function = None,\n",
      "                          completer_method = None,\n",
      "                          suppress_tab_hint = False,\n",
      "                          descriptive_header = None,\n",
      "                          **kwargs) :\n",
      "\n",
      "    # Verify consistent use of arguments\n",
      "    choices_callables = [choices_function, choices_method, completer_function, completer_method]\n",
      "    num_params_set = len(choices_callables) - choices_callables.count(None)\n",
      "\n",
      "    if num_params_set > 1:\n",
      "        err_msg = (\"Only one of the following parameters may be used at a time:\\n\"\n",
      "                   \"choices_function, choices_method, completer_function, completer_method\")\n",
      "        raise (ValueError(err_msg))\n",
      "\n",
      "    # Pre-process special ranged nargs\n",
      "    nargs_range = None\n",
      "\n",
      "    if nargs is not None:\n",
      "        # Check if nargs was given as a range\n",
      "        if isinstance(nargs, tuple):\n",
      "\n",
      "            # Handle 1-item tuple by setting max to INFINITY\n",
      "            if len(nargs) == 1:\n",
      "                nargs = (nargs[0], constants.INFINITY)\n",
      "\n",
      "            # Validate nargs tuple\n",
      "            if len(nargs) != 2 or not isinstance(nargs[0], int) or \\\n",
      "                    not (isinstance(nargs[1], int) or nargs[1] == constants.INFINITY):\n",
      "                raise ValueError('Ranged values for nargs must be a tuple of 1 or 2 integers')\n",
      "            if nargs[0] >= nargs[1]:\n",
      "                raise ValueError('Invalid nargs range. The first value must be less than the second')\n",
      "            if nargs[0] < 0:\n",
      "                raise ValueError('Negative numbers are invalid for nargs range')\n",
      "\n",
      "            # Save the nargs tuple as our range setting\n",
      "            nargs_range = nargs\n",
      "            range_min = nargs_range[0]\n",
      "            range_max = nargs_range[1]\n",
      "\n",
      "            # Convert nargs into a format argparse recognizes\n",
      "            if range_min == 0:\n",
      "                if range_max == 1:\n",
      "                    nargs_adjusted = argparse.OPTIONAL\n",
      "\n",
      "                    # No range needed since (0, 1) is just argparse.OPTIONAL\n",
      "                    nargs_range = None\n",
      "                else:\n",
      "                    nargs_adjusted = argparse.ZERO_OR_MORE\n",
      "                    if range_max == constants.INFINITY:\n",
      "                        # No range needed since (0, INFINITY) is just argparse.ZERO_OR_MORE\n",
      "                        nargs_range = None\n",
      "            elif range_min == 1 and range_max == constants.INFINITY:\n",
      "                nargs_adjusted = argparse.ONE_OR_MORE\n",
      "\n",
      "                # No range needed since (1, INFINITY) is just argparse.ONE_OR_MORE\n",
      "                nargs_range = None\n",
      "            else:\n",
      "                nargs_adjusted = argparse.ONE_OR_MORE\n",
      "        else:\n",
      "            nargs_adjusted = nargs\n",
      "\n",
      "        # Add the argparse-recognized version of nargs to kwargs\n",
      "        kwargs['nargs'] = nargs_adjusted\n",
      "\n",
      "    # Create the argument using the original add_argument function\n",
      "    new_arg = orig_actions_container_add_argument(self, *args, **kwargs)\n",
      "\n",
      "    # Set the custom attributes\n",
      "    setattr(new_arg, ATTR_NARGS_RANGE, nargs_range)\n",
      "\n",
      "    if choices_function:\n",
      "        set_choices_function(new_arg, choices_function)\n",
      "    elif choices_method:\n",
      "        set_choices_method(new_arg, choices_method)\n",
      "    elif completer_function:\n",
      "        set_completer_function(new_arg, completer_function)\n",
      "    elif completer_method:\n",
      "        set_completer_method(new_arg, completer_method)\n",
      "\n",
      "    setattr(new_arg, ATTR_SUPPRESS_TAB_HINT, suppress_tab_hint)\n",
      "    setattr(new_arg, ATTR_DESCRIPTIVE_COMPLETION_HEADER, descriptive_header)\n",
      "\n",
      "    return new_arg\n",
      "\n",
      "__________________________________________________-\n",
      "def _get_nargs_pattern_wrapper(self, action) :\n",
      "    # Wrapper around ArgumentParser._get_nargs_pattern behavior to support nargs ranges\n",
      "    nargs_range = getattr(action, ATTR_NARGS_RANGE, None)\n",
      "    if nargs_range is not None:\n",
      "        if nargs_range[1] == constants.INFINITY:\n",
      "            range_max = ''\n",
      "        else:\n",
      "            range_max = nargs_range[1]\n",
      "\n",
      "        nargs_pattern = '(-*A{{{},{}}}-*)'.format(nargs_range[0], range_max)\n",
      "\n",
      "        # if this is an optional action, -- is not allowed\n",
      "        if action.option_strings:\n",
      "            nargs_pattern = nargs_pattern.replace('-*', '')\n",
      "            nargs_pattern = nargs_pattern.replace('-', '')\n",
      "        return nargs_pattern\n",
      "\n",
      "    return orig_argument_parser_get_nargs_pattern(self, action)\n",
      "\n",
      "__________________________________________________-\n",
      "def _match_argument_wrapper(self, action, arg_strings_pattern) :\n",
      "    # Wrapper around ArgumentParser._match_argument behavior to support nargs ranges\n",
      "    nargs_pattern = self._get_nargs_pattern(action)\n",
      "    match = re.match(nargs_pattern, arg_strings_pattern)\n",
      "\n",
      "    # raise an exception if we weren't able to find a match\n",
      "    if match is None:\n",
      "        nargs_range = getattr(action, ATTR_NARGS_RANGE, None)\n",
      "        if nargs_range is not None:\n",
      "            raise ArgumentError(action, generate_range_error(nargs_range[0], nargs_range[1]))\n",
      "\n",
      "    return orig_argument_parser_match_argument(self, action, arg_strings_pattern)\n",
      "\n",
      "__________________________________________________-\n",
      "def _format_usage(self, usage, actions, groups, prefix) :\n",
      "        if prefix is None:\n",
      "            prefix = _('Usage: ')\n",
      "\n",
      "        # if usage is specified, use that\n",
      "        if usage is not None:\n",
      "            usage %= dict(prog=self._prog)\n",
      "\n",
      "        # if no optionals or positionals are available, usage is just prog\n",
      "        elif usage is None and not actions:\n",
      "            usage = '%(prog)s' % dict(prog=self._prog)\n",
      "\n",
      "        # if optionals and positionals are available, calculate usage\n",
      "        elif usage is None:\n",
      "            prog = '%(prog)s' % dict(prog=self._prog)\n",
      "\n",
      "            # split optionals from positionals\n",
      "            optionals = []\n",
      "            positionals = []\n",
      "            # Begin cmd2 customization (separates required and optional, applies to all changes in this function)\n",
      "            required_options = []\n",
      "            for action in actions:\n",
      "                if action.option_strings:\n",
      "                    if action.required:\n",
      "                        required_options.append(action)\n",
      "                    else:\n",
      "                        optionals.append(action)\n",
      "                else:\n",
      "                    positionals.append(action)\n",
      "            # End cmd2 customization\n",
      "\n",
      "            # build full usage string\n",
      "            format = self._format_actions_usage\n",
      "            action_usage = format(required_options + optionals + positionals, groups)\n",
      "            usage = ' '.join([s for s in [prog, action_usage] if s])\n",
      "\n",
      "            # wrap the usage parts if it's too long\n",
      "            text_width = self._width - self._current_indent\n",
      "            if len(prefix) + len(usage) > text_width:\n",
      "\n",
      "                # Begin cmd2 customization\n",
      "\n",
      "                # break usage into wrappable parts\n",
      "                part_regexp = r'\\(.*?\\)+|\\[.*?\\]+|\\S+'\n",
      "                req_usage = format(required_options, groups)\n",
      "                opt_usage = format(optionals, groups)\n",
      "                pos_usage = format(positionals, groups)\n",
      "                req_parts = re.findall(part_regexp, req_usage)\n",
      "                opt_parts = re.findall(part_regexp, opt_usage)\n",
      "                pos_parts = re.findall(part_regexp, pos_usage)\n",
      "                assert ' '.join(req_parts) == req_usage\n",
      "                assert ' '.join(opt_parts) == opt_usage\n",
      "                assert ' '.join(pos_parts) == pos_usage\n",
      "\n",
      "                # End cmd2 customization\n",
      "\n",
      "                # helper for wrapping lines\n",
      "                # noinspection PyMissingOrEmptyDocstring,PyShadowingNames\n",
      "                def get_lines(parts, indent, prefix=None):\n",
      "                    lines = []\n",
      "                    line = []\n",
      "                    if prefix is not None:\n",
      "                        line_len = len(prefix) - 1\n",
      "                    else:\n",
      "                        line_len = len(indent) - 1\n",
      "                    for part in parts:\n",
      "                        if line_len + 1 + len(part) > text_width and line:\n",
      "                            lines.append(indent + ' '.join(line))\n",
      "                            line = []\n",
      "                            line_len = len(indent) - 1\n",
      "                        line.append(part)\n",
      "                        line_len += len(part) + 1\n",
      "                    if line:\n",
      "                        lines.append(indent + ' '.join(line))\n",
      "                    if prefix is not None:\n",
      "                        lines[0] = lines[0][len(indent):]\n",
      "                    return lines\n",
      "\n",
      "                # if prog is short, follow it with optionals or positionals\n",
      "                if len(prefix) + len(prog) <= 0.75 * text_width:\n",
      "                    indent = ' ' * (len(prefix) + len(prog) + 1)\n",
      "                    # Begin cmd2 customization\n",
      "                    if req_parts:\n",
      "                        lines = get_lines([prog] + req_parts, indent, prefix)\n",
      "                        lines.extend(get_lines(opt_parts, indent))\n",
      "                        lines.extend(get_lines(pos_parts, indent))\n",
      "                    elif opt_parts:\n",
      "                        lines = get_lines([prog] + opt_parts, indent, prefix)\n",
      "                        lines.extend(get_lines(pos_parts, indent))\n",
      "                    elif pos_parts:\n",
      "                        lines = get_lines([prog] + pos_parts, indent, prefix)\n",
      "                    else:\n",
      "                        lines = [prog]\n",
      "                    # End cmd2 customization\n",
      "\n",
      "                # if prog is long, put it on its own line\n",
      "                else:\n",
      "                    indent = ' ' * len(prefix)\n",
      "                    # Begin cmd2 customization\n",
      "                    parts = req_parts + opt_parts + pos_parts\n",
      "                    lines = get_lines(parts, indent)\n",
      "                    if len(lines) > 1:\n",
      "                        lines = []\n",
      "                        lines.extend(get_lines(req_parts, indent))\n",
      "                        lines.extend(get_lines(opt_parts, indent))\n",
      "                        lines.extend(get_lines(pos_parts, indent))\n",
      "                    # End cmd2 customization\n",
      "                    lines = [prog] + lines\n",
      "\n",
      "                # join lines into usage\n",
      "                usage = '\\n'.join(lines)\n",
      "\n",
      "        # prefix with 'Usage:'\n",
      "        return '%s%s\\n\\n' % (prefix, usage)\n",
      "\n",
      "__________________________________________________-\n",
      "def _format_action_invocation(self, action) :\n",
      "        if not action.option_strings:\n",
      "            default = self._get_default_metavar_for_positional(action)\n",
      "            metavar, = self._metavar_formatter(action, default)(1)\n",
      "            return metavar\n",
      "\n",
      "        else:\n",
      "            parts = []\n",
      "\n",
      "            # if the Optional doesn't take a value, format is:\n",
      "            #    -s, --long\n",
      "            if action.nargs == 0:\n",
      "                parts.extend(action.option_strings)\n",
      "                return ', '.join(parts)\n",
      "\n",
      "            # Begin cmd2 customization (less verbose)\n",
      "            # if the Optional takes a value, format is:\n",
      "            #    -s, --long ARGS\n",
      "            else:\n",
      "                default = self._get_default_metavar_for_optional(action)\n",
      "                args_string = self._format_args(action, default)\n",
      "\n",
      "                return ', '.join(action.option_strings) + ' ' + args_string\n",
      "            # End cmd2 customization\n",
      "__________________________________________________-\n",
      "def _metavar_formatter(self, action, default_metavar) :\n",
      "        if action.metavar is not None:\n",
      "            result = action.metavar\n",
      "        elif action.choices is not None:\n",
      "            choice_strs = [str(choice) for choice in action.choices]\n",
      "            # Begin cmd2 customization (added space after comma)\n",
      "            result = '{%s}' % ', '.join(choice_strs)\n",
      "            # End cmd2 customization\n",
      "        else:\n",
      "            result = default_metavar\n",
      "\n",
      "        # noinspection PyMissingOrEmptyDocstring\n",
      "        def format(tuple_size):\n",
      "            if isinstance(result, tuple):\n",
      "                return result\n",
      "            else:\n",
      "                return (result, ) * tuple_size\n",
      "        return format\n",
      "\n",
      "__________________________________________________-\n",
      "def _format_args(self, action, default_metavar) :\n",
      "        get_metavar = self._metavar_formatter(action, default_metavar)\n",
      "        # Begin cmd2 customization (less verbose)\n",
      "        nargs_range = getattr(action, ATTR_NARGS_RANGE, None)\n",
      "\n",
      "        if nargs_range is not None:\n",
      "            if nargs_range[1] == constants.INFINITY:\n",
      "                range_str = '{}+'.format(nargs_range[0])\n",
      "            else:\n",
      "                range_str = '{}..{}'.format(nargs_range[0], nargs_range[1])\n",
      "\n",
      "            result = '{}{{{}}}'.format('%s' % get_metavar(1), range_str)\n",
      "        elif action.nargs == ZERO_OR_MORE:\n",
      "            result = '[%s [...]]' % get_metavar(1)\n",
      "        elif action.nargs == ONE_OR_MORE:\n",
      "            result = '%s [...]' % get_metavar(1)\n",
      "        elif isinstance(action.nargs, int) and action.nargs > 1:\n",
      "            result = '{}{{{}}}'.format('%s' % get_metavar(1), action.nargs)\n",
      "        # End cmd2 customization\n",
      "        else:\n",
      "            result = super()._format_args(action, default_metavar)\n",
      "        return result\n",
      "\n",
      "__________________________________________________-\n",
      "def __init__(self, *args, **kwargs) :\n",
      "        if 'formatter_class' not in kwargs:\n",
      "            kwargs['formatter_class'] = Cmd2HelpFormatter\n",
      "\n",
      "        super().__init__(*args, **kwargs)\n",
      "\n",
      "__________________________________________________-\n",
      "def error(self, message) :\n",
      "\n",
      "        lines = message.split('\\n')\n",
      "        linum = 0\n",
      "        formatted_message = ''\n",
      "        for line in lines:\n",
      "            if linum == 0:\n",
      "                formatted_message = 'Error: ' + line\n",
      "            else:\n",
      "                formatted_message += '\\n       ' + line\n",
      "            linum += 1\n",
      "\n",
      "        self.print_usage(sys.stderr)\n",
      "        formatted_message = ansi.style_error(formatted_message)\n",
      "        self.exit(2, '{}\\n\\n'.format(formatted_message))\n",
      "\n",
      "__________________________________________________-\n",
      "def format_help(self) :\n",
      "\n",
      "        formatter = self._get_formatter()\n",
      "\n",
      "        # usage\n",
      "        formatter.add_usage(self.usage, self._actions,\n",
      "                            self._mutually_exclusive_groups)\n",
      "\n",
      "        # description\n",
      "        formatter.add_text(self.description)\n",
      "\n",
      "        # Begin cmd2 customization (separate required and optional arguments)\n",
      "\n",
      "        # positionals, optionals and user-defined groups\n",
      "        for action_group in self._action_groups:\n",
      "            if action_group.title == 'optional arguments':\n",
      "                # check if the arguments are required, group accordingly\n",
      "                req_args = []\n",
      "                opt_args = []\n",
      "                for action in action_group._group_actions:\n",
      "                    if action.required:\n",
      "                        req_args.append(action)\n",
      "                    else:\n",
      "                        opt_args.append(action)\n",
      "\n",
      "                # separately display required arguments\n",
      "                formatter.start_section('required arguments')\n",
      "                formatter.add_text(action_group.description)\n",
      "                formatter.add_arguments(req_args)\n",
      "                formatter.end_section()\n",
      "\n",
      "                # now display truly optional arguments\n",
      "                formatter.start_section(action_group.title)\n",
      "                formatter.add_text(action_group.description)\n",
      "                formatter.add_arguments(opt_args)\n",
      "                formatter.end_section()\n",
      "            else:\n",
      "                formatter.start_section(action_group.title)\n",
      "                formatter.add_text(action_group.description)\n",
      "                formatter.add_arguments(action_group._group_actions)\n",
      "                formatter.end_section()\n",
      "\n",
      "        # End cmd2 customization\n",
      "\n",
      "        # epilog\n",
      "        formatter.add_text(self.epilog)\n",
      "\n",
      "        # determine help from format above\n",
      "        return formatter.format_help() + '\\n'\n",
      "\n",
      "__________________________________________________-\n",
      "def set_default_argument_parser(parser) :\n",
      "\n",
      "    global DEFAULT_ARGUMENT_PARSER\n",
      "    DEFAULT_ARGUMENT_PARSER = parser\n",
      "\n",
      "__________________________________________________-\n",
      "def __init__(self, header, *, width = None,\n",
      "                 header_horiz_align = HorizontalAlignment.LEFT,\n",
      "                 header_vert_align = VerticalAlignment.BOTTOM,\n",
      "                 data_horiz_align = HorizontalAlignment.LEFT,\n",
      "                 data_vert_align = VerticalAlignment.TOP,\n",
      "                 max_data_lines = constants.INFINITY) :\n",
      "\n",
      "        self.header = header\n",
      "\n",
      "        if width is None:\n",
      "            # Use the width of the widest line in the header or 1 if the header has no width\n",
      "            line_widths = [ansi.style_aware_wcswidth(line) for line in self.header.splitlines()]\n",
      "            line_widths.append(1)\n",
      "            self.width = max(line_widths)\n",
      "        elif width < 1:\n",
      "            raise ValueError(\"Column width cannot be less than 1\")\n",
      "        else:\n",
      "            self.width = width\n",
      "\n",
      "        self.header_horiz_align = header_horiz_align\n",
      "        self.header_vert_align = header_vert_align\n",
      "        self.data_horiz_align = data_horiz_align\n",
      "        self.data_vert_align = data_vert_align\n",
      "\n",
      "        if max_data_lines < 1:\n",
      "            raise ValueError(\"Max data lines cannot be less than 1\")\n",
      "\n",
      "        self.max_data_lines = max_data_lines\n",
      "\n",
      "__________________________________________________-\n",
      "def __init__(self, cols, *, tab_width = 4) :\n",
      "\n",
      "        self.cols = copy.copy(cols)\n",
      "        self.tab_width = tab_width\n",
      "\n",
      "__________________________________________________-\n",
      "def _wrap_long_word(word, max_width, max_lines, is_last_word) :\n",
      "\n",
      "        styles = utils.get_styles_in_text(word)\n",
      "        wrapped_buf = io.StringIO()\n",
      "\n",
      "        # How many lines we've used\n",
      "        total_lines = 1\n",
      "\n",
      "        # Display width of the current line we are building\n",
      "        cur_line_width = 0\n",
      "\n",
      "        char_index = 0\n",
      "        while char_index < len(word):\n",
      "            # We've reached the last line. Let truncate_line do the rest.\n",
      "            if total_lines == max_lines:\n",
      "                # If this isn't the last word, but it's gonna fill the final line, then force truncate_line\n",
      "                # to place an ellipsis at the end of it by making the word too wide.\n",
      "                remaining_word = word[char_index:]\n",
      "                if not is_last_word and ansi.style_aware_wcswidth(remaining_word) == max_width:\n",
      "                    remaining_word += \"EXTRA\"\n",
      "\n",
      "                truncated_line = utils.truncate_line(remaining_word, max_width)\n",
      "                cur_line_width = ansi.style_aware_wcswidth(truncated_line)\n",
      "                wrapped_buf.write(truncated_line)\n",
      "                break\n",
      "\n",
      "            # Check if we're at a style sequence. These don't count toward display width.\n",
      "            if char_index in styles:\n",
      "                wrapped_buf.write(styles[char_index])\n",
      "                char_index += len(styles[char_index])\n",
      "                continue\n",
      "\n",
      "            cur_char = word[char_index]\n",
      "            cur_char_width = wcwidth(cur_char)\n",
      "\n",
      "            if cur_char_width > max_width:\n",
      "                # We have a case where the character is wider than max_width. This can happen if max_width\n",
      "                # is 1 and the text contains wide characters (e.g. East Asian). Replace it with an ellipsis.\n",
      "                cur_char = constants.HORIZONTAL_ELLIPSIS\n",
      "                cur_char_width = wcwidth(cur_char)\n",
      "\n",
      "            if cur_line_width + cur_char_width > max_width:\n",
      "                # Adding this char will exceed the max_width. Start a new line.\n",
      "                wrapped_buf.write('\\n')\n",
      "                total_lines += 1\n",
      "                cur_line_width = 0\n",
      "                continue\n",
      "\n",
      "            # Add this character and move to the next one\n",
      "            cur_line_width += cur_char_width\n",
      "            wrapped_buf.write(cur_char)\n",
      "            char_index += 1\n",
      "\n",
      "        return wrapped_buf.getvalue(), total_lines, cur_line_width\n",
      "\n",
      "__________________________________________________-\n",
      "def _wrap_text(text, max_width, max_lines) :\n",
      "\n",
      "        def add_word(word_to_add, is_last_word):\n",
      "\n",
      "            nonlocal cur_line_width\n",
      "            nonlocal total_lines\n",
      "\n",
      "            # No more space to add word\n",
      "            if total_lines == max_lines and cur_line_width == max_width:\n",
      "                return\n",
      "\n",
      "            word_width = ansi.style_aware_wcswidth(word_to_add)\n",
      "\n",
      "            # If the word is wider than max width of a line, attempt to start it on its own line and wrap it\n",
      "            if word_width > max_width:\n",
      "                room_to_add = True\n",
      "\n",
      "                if cur_line_width > 0:\n",
      "                    # The current line already has text, check if there is room to create a new line\n",
      "                    if total_lines < max_lines:\n",
      "                        wrapped_buf.write('\\n')\n",
      "                        total_lines += 1\n",
      "                    else:\n",
      "                        # We will truncate this word on the remaining line\n",
      "                        room_to_add = False\n",
      "\n",
      "                if room_to_add:\n",
      "                    wrapped_word, lines_used, cur_line_width = TableCreator._wrap_long_word(word_to_add,\n",
      "                                                                                            max_width,\n",
      "                                                                                            max_lines - total_lines + 1,\n",
      "                                                                                            is_last_word)\n",
      "                    # Write the word to the buffer\n",
      "                    wrapped_buf.write(wrapped_word)\n",
      "                    total_lines += lines_used - 1\n",
      "                    return\n",
      "\n",
      "            # We aren't going to wrap the word across multiple lines\n",
      "            remaining_width = max_width - cur_line_width\n",
      "\n",
      "            # Check if we need to start a new line\n",
      "            if word_width > remaining_width and total_lines < max_lines:\n",
      "                # Save the last character in wrapped_buf, which can't be empty at this point.\n",
      "                seek_pos = wrapped_buf.tell() - 1\n",
      "                wrapped_buf.seek(seek_pos)\n",
      "                last_char = wrapped_buf.read()\n",
      "\n",
      "                wrapped_buf.write('\\n')\n",
      "                total_lines += 1\n",
      "                cur_line_width = 0\n",
      "                remaining_width = max_width\n",
      "\n",
      "                # Only when a space is following a space do we want to start the next line with it.\n",
      "                if word_to_add == SPACE and last_char != SPACE:\n",
      "                    return\n",
      "\n",
      "            # Check if we've hit the last line we're allowed to create\n",
      "            if total_lines == max_lines:\n",
      "                # If this word won't fit, truncate it\n",
      "                if word_width > remaining_width:\n",
      "                    word_to_add = utils.truncate_line(word_to_add, remaining_width)\n",
      "                    word_width = remaining_width\n",
      "\n",
      "                # If this isn't the last word, but it's gonna fill the final line, then force truncate_line\n",
      "                # to place an ellipsis at the end of it by making the word too wide.\n",
      "                elif not is_last_word and word_width == remaining_width:\n",
      "                    word_to_add = utils.truncate_line(word_to_add + \"EXTRA\", remaining_width)\n",
      "\n",
      "            cur_line_width += word_width\n",
      "            wrapped_buf.write(word_to_add)\n",
      "\n",
      "        ############################################################################################################\n",
      "        # _wrap_text() main code\n",
      "        ############################################################################################################\n",
      "        # Buffer of the wrapped text\n",
      "        wrapped_buf = io.StringIO()\n",
      "\n",
      "        # How many lines we've used\n",
      "        total_lines = 0\n",
      "\n",
      "        # Respect the existing line breaks\n",
      "        data_str_lines = text.splitlines()\n",
      "        for data_line_index, data_line in enumerate(data_str_lines):\n",
      "            total_lines += 1\n",
      "\n",
      "            if data_line_index > 0:\n",
      "                wrapped_buf.write('\\n')\n",
      "\n",
      "            # Locate the styles in this line\n",
      "            styles = utils.get_styles_in_text(data_line)\n",
      "\n",
      "            # Display width of the current line we are building\n",
      "            cur_line_width = 0\n",
      "\n",
      "            # Current word being built\n",
      "            cur_word_buf = io.StringIO()\n",
      "\n",
      "            char_index = 0\n",
      "            while char_index < len(data_line):\n",
      "                if total_lines == max_lines and cur_line_width == max_width:\n",
      "                    break\n",
      "\n",
      "                # Check if we're at a style sequence. These don't count toward display width.\n",
      "                if char_index in styles:\n",
      "                    cur_word_buf.write(styles[char_index])\n",
      "                    char_index += len(styles[char_index])\n",
      "                    continue\n",
      "\n",
      "                cur_char = data_line[char_index]\n",
      "                if cur_char == SPACE:\n",
      "                    # If we've reached the end of a word, then add the word to the wrapped text\n",
      "                    if cur_word_buf.tell() > 0:\n",
      "                        # is_last_word is False since there is a space after the word\n",
      "                        add_word(cur_word_buf.getvalue(), is_last_word=False)\n",
      "                        cur_word_buf = io.StringIO()\n",
      "\n",
      "                    # Add the space to the wrapped text\n",
      "                    last_word = data_line_index == len(data_str_lines) - 1 and char_index == len(data_line) - 1\n",
      "                    add_word(cur_char, last_word)\n",
      "                else:\n",
      "                    # Add this character to the word buffer\n",
      "                    cur_word_buf.write(cur_char)\n",
      "\n",
      "                char_index += 1\n",
      "\n",
      "            # Add the final word of this line if it's been started\n",
      "            if cur_word_buf.tell() > 0:\n",
      "                last_word = data_line_index == len(data_str_lines) - 1 and char_index == len(data_line)\n",
      "                add_word(cur_word_buf.getvalue(), last_word)\n",
      "\n",
      "            # Stop line loop if we've written to max_lines\n",
      "            if total_lines == max_lines:\n",
      "                # If this isn't the last data line and there is space left on the final wrapped line, then add an ellipsis\n",
      "                if data_line_index < len(data_str_lines) - 1 and cur_line_width < max_width:\n",
      "                    wrapped_buf.write(constants.HORIZONTAL_ELLIPSIS)\n",
      "                break\n",
      "\n",
      "        return wrapped_buf.getvalue()\n",
      "\n",
      "__________________________________________________-\n",
      "def add_word(word_to_add, is_last_word):\n",
      "\n",
      "            nonlocal cur_line_width\n",
      "            nonlocal total_lines\n",
      "\n",
      "            # No more space to add word\n",
      "            if total_lines == max_lines and cur_line_width == max_width:\n",
      "                return\n",
      "\n",
      "            word_width = ansi.style_aware_wcswidth(word_to_add)\n",
      "\n",
      "            # If the word is wider than max width of a line, attempt to start it on its own line and wrap it\n",
      "            if word_width > max_width:\n",
      "                room_to_add = True\n",
      "\n",
      "                if cur_line_width > 0:\n",
      "                    # The current line already has text, check if there is room to create a new line\n",
      "                    if total_lines < max_lines:\n",
      "                        wrapped_buf.write('\\n')\n",
      "                        total_lines += 1\n",
      "                    else:\n",
      "                        # We will truncate this word on the remaining line\n",
      "                        room_to_add = False\n",
      "\n",
      "                if room_to_add:\n",
      "                    wrapped_word, lines_used, cur_line_width = TableCreator._wrap_long_word(word_to_add,\n",
      "                                                                                            max_width,\n",
      "                                                                                            max_lines - total_lines + 1,\n",
      "                                                                                            is_last_word)\n",
      "                    # Write the word to the buffer\n",
      "                    wrapped_buf.write(wrapped_word)\n",
      "                    total_lines += lines_used - 1\n",
      "                    return\n",
      "\n",
      "            # We aren't going to wrap the word across multiple lines\n",
      "            remaining_width = max_width - cur_line_width\n",
      "\n",
      "            # Check if we need to start a new line\n",
      "            if word_width > remaining_width and total_lines < max_lines:\n",
      "                # Save the last character in wrapped_buf, which can't be empty at this point.\n",
      "                seek_pos = wrapped_buf.tell() - 1\n",
      "                wrapped_buf.seek(seek_pos)\n",
      "                last_char = wrapped_buf.read()\n",
      "\n",
      "                wrapped_buf.write('\\n')\n",
      "                total_lines += 1\n",
      "                cur_line_width = 0\n",
      "                remaining_width = max_width\n",
      "\n",
      "                # Only when a space is following a space do we want to start the next line with it.\n",
      "                if word_to_add == SPACE and last_char != SPACE:\n",
      "                    return\n",
      "\n",
      "            # Check if we've hit the last line we're allowed to create\n",
      "            if total_lines == max_lines:\n",
      "                # If this word won't fit, truncate it\n",
      "                if word_width > remaining_width:\n",
      "                    word_to_add = utils.truncate_line(word_to_add, remaining_width)\n",
      "                    word_width = remaining_width\n",
      "\n",
      "                # If this isn't the last word, but it's gonna fill the final line, then force truncate_line\n",
      "                # to place an ellipsis at the end of it by making the word too wide.\n",
      "                elif not is_last_word and word_width == remaining_width:\n",
      "                    word_to_add = utils.truncate_line(word_to_add + \"EXTRA\", remaining_width)\n",
      "\n",
      "            cur_line_width += word_width\n",
      "            wrapped_buf.write(word_to_add)\n",
      "\n",
      "__________________________________________________-\n",
      "def _generate_cell_lines(self, cell_data, is_header, col, fill_char) :\n",
      "\n",
      "        # Convert data to string and replace tabs with spaces\n",
      "        data_str = str(cell_data).replace('\\t', SPACE * self.tab_width)\n",
      "\n",
      "        # Wrap text in this cell\n",
      "        max_lines = constants.INFINITY if is_header else col.max_data_lines\n",
      "        wrapped_text = self._wrap_text(data_str, col.width, max_lines)\n",
      "\n",
      "        # Align the text horizontally\n",
      "        horiz_alignment = col.header_horiz_align if is_header else col.data_horiz_align\n",
      "        if horiz_alignment == HorizontalAlignment.LEFT:\n",
      "            text_alignment = utils.TextAlignment.LEFT\n",
      "        elif horiz_alignment == HorizontalAlignment.CENTER:\n",
      "            text_alignment = utils.TextAlignment.CENTER\n",
      "        else:\n",
      "            text_alignment = utils.TextAlignment.RIGHT\n",
      "\n",
      "        aligned_text = utils.align_text(wrapped_text, fill_char=fill_char, width=col.width, alignment=text_alignment)\n",
      "\n",
      "        lines = deque(aligned_text.splitlines())\n",
      "        cell_width = max([ansi.style_aware_wcswidth(line) for line in lines])\n",
      "        return lines, cell_width\n",
      "\n",
      "__________________________________________________-\n",
      "def generate_row(self, *, row_data = None, fill_char = SPACE,\n",
      "                     pre_line = EMPTY, inter_cell = (2 * SPACE), post_line = EMPTY) :\n",
      "\n",
      "        class Cell:\n",
      "\n",
      "            def __init__(self) :\n",
      "                # Data in this cell split into individual lines\n",
      "                self.lines = []\n",
      "\n",
      "                # Display width of this cell\n",
      "                self.width = 0\n",
      "\n",
      "        if row_data is None:\n",
      "            row_data = [col.header for col in self.cols]\n",
      "            is_header = True\n",
      "        else:\n",
      "            if len(row_data) != len(self.cols):\n",
      "                raise ValueError(\"Length of row_data must match length of cols\")\n",
      "            is_header = False\n",
      "\n",
      "        # Replace tabs (tabs in data strings will be handled in _generate_cell_lines())\n",
      "        fill_char = fill_char.replace('\\t', SPACE)\n",
      "        pre_line = pre_line.replace('\\t', SPACE * self.tab_width)\n",
      "        inter_cell = inter_cell.replace('\\t', SPACE * self.tab_width)\n",
      "        post_line = post_line.replace('\\t', SPACE * self.tab_width)\n",
      "\n",
      "        # Validate fill_char character count\n",
      "        if len(ansi.strip_style(fill_char)) != 1:\n",
      "            raise TypeError(\"Fill character must be exactly one character long\")\n",
      "\n",
      "        # Look for unprintable characters\n",
      "        validation_dict = {'fill_char': fill_char, 'pre_line': pre_line,\n",
      "                           'inter_cell': inter_cell, 'post_line': post_line}\n",
      "        for key, val in validation_dict.items():\n",
      "            if ansi.style_aware_wcswidth(val) == -1:\n",
      "                raise (ValueError(\"{} contains an unprintable character\".format(key)))\n",
      "\n",
      "        # Number of lines this row uses\n",
      "        total_lines = 0\n",
      "\n",
      "        # Generate the cells for this row\n",
      "        cells = list()\n",
      "\n",
      "        for col_index, col in enumerate(self.cols):\n",
      "            cell = Cell()\n",
      "            cell.lines, cell.width = self._generate_cell_lines(row_data[col_index], is_header, col, fill_char)\n",
      "            cells.append(cell)\n",
      "            total_lines = max(len(cell.lines), total_lines)\n",
      "\n",
      "        row_buf = io.StringIO()\n",
      "\n",
      "        # Vertically align each cell\n",
      "        for cell_index, cell in enumerate(cells):\n",
      "            col = self.cols[cell_index]\n",
      "            vert_align = col.header_vert_align if is_header else col.data_vert_align\n",
      "\n",
      "            # Check if this cell need vertical filler\n",
      "            line_diff = total_lines - len(cell.lines)\n",
      "            if line_diff == 0:\n",
      "                continue\n",
      "\n",
      "            # Add vertical filler lines\n",
      "            padding_line = utils.align_left(EMPTY, fill_char=fill_char, width=cell.width)\n",
      "            if vert_align == VerticalAlignment.TOP:\n",
      "                to_top = 0\n",
      "                to_bottom = line_diff\n",
      "            elif vert_align == VerticalAlignment.MIDDLE:\n",
      "                to_top = line_diff // 2\n",
      "                to_bottom = line_diff - to_top\n",
      "            else:\n",
      "                to_top = line_diff\n",
      "                to_bottom = 0\n",
      "\n",
      "            for i in range(to_top):\n",
      "                cell.lines.appendleft(padding_line)\n",
      "            for i in range(to_bottom):\n",
      "                cell.lines.append(padding_line)\n",
      "\n",
      "        # Build this row one line at a time\n",
      "        for line_index in range(total_lines):\n",
      "            for cell_index, cell in enumerate(cells):\n",
      "                if cell_index == 0:\n",
      "                    row_buf.write(pre_line)\n",
      "\n",
      "                row_buf.write(cell.lines[line_index])\n",
      "\n",
      "                if cell_index < len(self.cols) - 1:\n",
      "                    row_buf.write(inter_cell)\n",
      "                if cell_index == len(self.cols) - 1:\n",
      "                    row_buf.write(post_line)\n",
      "\n",
      "            # Add a newline if this is not the last line\n",
      "            if line_index < total_lines - 1:\n",
      "                row_buf.write('\\n')\n",
      "\n",
      "        return row_buf.getvalue()\n",
      "\n",
      "__________________________________________________-\n",
      "def __init__(self) :\n",
      "                # Data in this cell split into individual lines\n",
      "                self.lines = []\n",
      "\n",
      "                # Display width of this cell\n",
      "                self.width = 0\n",
      "\n",
      "__________________________________________________-\n",
      "def __init__(self, cols, *, tab_width = 4, divider_char = '-') :\n",
      "\n",
      "        if divider_char is not None:\n",
      "            if len(ansi.strip_style(divider_char)) != 1:\n",
      "                raise TypeError(\"Divider character must be exactly one character long\")\n",
      "\n",
      "            divider_char_width = ansi.style_aware_wcswidth(divider_char)\n",
      "            if divider_char_width == -1:\n",
      "                raise (ValueError(\"Divider character is an unprintable character\"))\n",
      "\n",
      "        super().__init__(cols, tab_width=tab_width)\n",
      "        self.divider_char = divider_char\n",
      "\n",
      "__________________________________________________-\n",
      "def base_width(cls, num_cols) :\n",
      "\n",
      "        if num_cols < 1:\n",
      "            raise ValueError(\"Column count cannot be less than 1\")\n",
      "\n",
      "        data_str = SPACE\n",
      "        data_width = ansi.style_aware_wcswidth(data_str) * num_cols\n",
      "\n",
      "        tbl = cls([Column(data_str)] * num_cols)\n",
      "        data_row = tbl.generate_data_row([data_str] * num_cols)\n",
      "\n",
      "        return ansi.style_aware_wcswidth(data_row) - data_width\n",
      "\n",
      "__________________________________________________-\n",
      "def generate_data_row(self, row_data) :\n",
      "\n",
      "        return self.generate_row(row_data=row_data, inter_cell=self.INTER_CELL)\n",
      "\n",
      "__________________________________________________-\n",
      "def total_width(self) :\n",
      "\n",
      "        base_width = self.base_width(len(self.cols))\n",
      "        data_width = sum(col.width for col in self.cols)\n",
      "        return base_width + data_width\n",
      "\n",
      "__________________________________________________-\n",
      "def generate_header(self) :\n",
      "\n",
      "        header_buf = io.StringIO()\n",
      "\n",
      "        # Create the header labels\n",
      "        header = self.generate_row(inter_cell=self.INTER_CELL)\n",
      "        header_buf.write(header)\n",
      "\n",
      "        # Create the divider if necessary\n",
      "        if self.divider_char is not None:\n",
      "            total_width = self.total_width()\n",
      "            divider_char_width = ansi.style_aware_wcswidth(self.divider_char)\n",
      "\n",
      "            # Make divider as wide as table and use padding if width of\n",
      "            # divider_char does not divide evenly into table width.\n",
      "            divider = self.divider_char * (total_width // divider_char_width)\n",
      "            divider += SPACE * (total_width % divider_char_width)\n",
      "\n",
      "            header_buf.write('\\n')\n",
      "            header_buf.write(divider)\n",
      "        return header_buf.getvalue()\n",
      "\n",
      "__________________________________________________-\n",
      "def generate_table(self, table_data, *,\n",
      "                       include_header = True, row_spacing = 1) :\n",
      "\n",
      "        if row_spacing < 0:\n",
      "            raise ValueError(\"Row spacing cannot be less than 0\")\n",
      "\n",
      "        table_buf = io.StringIO()\n",
      "\n",
      "        if include_header:\n",
      "            header = self.generate_header()\n",
      "            table_buf.write(header)\n",
      "            if len(table_data) > 0:\n",
      "                table_buf.write('\\n')\n",
      "\n",
      "        for index, row_data in enumerate(table_data):\n",
      "            if index > 0 and row_spacing > 0:\n",
      "                table_buf.write(row_spacing * '\\n')\n",
      "\n",
      "            row = self.generate_data_row(row_data)\n",
      "            table_buf.write(row)\n",
      "            if index < len(table_data) - 1:\n",
      "                table_buf.write('\\n')\n",
      "\n",
      "        return table_buf.getvalue()\n",
      "\n",
      "__________________________________________________-\n",
      "def __init__(self, cols, *, tab_width = 4,\n",
      "                 column_borders = True, padding = 1) :\n",
      "\n",
      "        super().__init__(cols, tab_width=tab_width)\n",
      "        self.empty_data = [EMPTY for _ in self.cols]\n",
      "        self.column_borders = column_borders\n",
      "\n",
      "        if padding < 0:\n",
      "            raise ValueError(\"Padding cannot be less than 0\")\n",
      "        self.padding = padding\n",
      "\n",
      "__________________________________________________-\n",
      "def base_width(cls, num_cols, *, column_borders = True, padding = 1) :\n",
      "\n",
      "        if num_cols < 1:\n",
      "            raise ValueError(\"Column count cannot be less than 1\")\n",
      "\n",
      "        data_str = SPACE\n",
      "        data_width = ansi.style_aware_wcswidth(data_str) * num_cols\n",
      "\n",
      "        tbl = cls([Column(data_str)] * num_cols, column_borders=column_borders, padding=padding)\n",
      "        data_row = tbl.generate_data_row([data_str] * num_cols)\n",
      "\n",
      "        return ansi.style_aware_wcswidth(data_row) - data_width\n",
      "\n",
      "__________________________________________________-\n",
      "def generate_data_row(self, row_data) :\n",
      "\n",
      "        pre_line = '║' + self.padding * SPACE\n",
      "\n",
      "        inter_cell = self.padding * SPACE\n",
      "        if self.column_borders:\n",
      "            inter_cell += '│'\n",
      "        inter_cell += self.padding * SPACE\n",
      "\n",
      "        post_line = self.padding * SPACE + '║'\n",
      "\n",
      "        return self.generate_row(row_data=row_data, pre_line=pre_line, inter_cell=inter_cell, post_line=post_line)\n",
      "\n",
      "__________________________________________________-\n",
      "def total_width(self) :\n",
      "\n",
      "        base_width = self.base_width(len(self.cols), column_borders=self.column_borders, padding=self.padding)\n",
      "        data_width = sum(col.width for col in self.cols)\n",
      "        return base_width + data_width\n",
      "\n",
      "__________________________________________________-\n",
      "def generate_header(self) :\n",
      "\n",
      "        pre_line = '║' + self.padding * SPACE\n",
      "\n",
      "        inter_cell = self.padding * SPACE\n",
      "        if self.column_borders:\n",
      "            inter_cell += '│'\n",
      "        inter_cell += self.padding * SPACE\n",
      "\n",
      "        post_line = self.padding * SPACE + '║'\n",
      "\n",
      "        # Create the bordered header\n",
      "        header_buf = io.StringIO()\n",
      "        header_buf.write(self.generate_table_top_border())\n",
      "        header_buf.write('\\n')\n",
      "        header_buf.write(self.generate_row(pre_line=pre_line, inter_cell=inter_cell, post_line=post_line))\n",
      "        header_buf.write('\\n')\n",
      "        header_buf.write(self.generate_header_bottom_border())\n",
      "\n",
      "        return header_buf.getvalue()\n",
      "\n",
      "__________________________________________________-\n",
      "def generate_table(self, table_data, *, include_header = True) :\n",
      "\n",
      "        table_buf = io.StringIO()\n",
      "\n",
      "        if include_header:\n",
      "            header = self.generate_header()\n",
      "            table_buf.write(header)\n",
      "        else:\n",
      "            top_border = self.generate_table_top_border()\n",
      "            table_buf.write(top_border)\n",
      "\n",
      "        table_buf.write('\\n')\n",
      "\n",
      "        for index, row_data in enumerate(table_data):\n",
      "            if index > 0:\n",
      "                row_bottom_border = self.generate_row_bottom_border()\n",
      "                table_buf.write(row_bottom_border)\n",
      "                table_buf.write('\\n')\n",
      "\n",
      "            row = self.generate_data_row(row_data)\n",
      "            table_buf.write(row)\n",
      "            table_buf.write('\\n')\n",
      "\n",
      "        table_buf.write(self.generate_table_bottom_border())\n",
      "        return table_buf.getvalue()\n",
      "\n",
      "__________________________________________________-\n",
      "def __init__(self, cols, *, tab_width = 4, column_borders = True, padding = 1,\n",
      "                 bg_odd = None, bg_even = ansi.bg.bright_black) :\n",
      "\n",
      "        super().__init__(cols, tab_width=tab_width, column_borders=column_borders, padding=padding)\n",
      "        self.row_num = 1\n",
      "        self.bg_odd = None if bg_odd is None else functools.partial(ansi.style, bg=bg_odd)\n",
      "        self.bg_even = None if bg_even is None else functools.partial(ansi.style, bg=bg_even)\n",
      "\n",
      "__________________________________________________-\n",
      "def _apply_bg_color(self, data) :\n",
      "\n",
      "        if self.row_num % 2 == 0 and self.bg_even is not None:\n",
      "            return self.bg_even(data)\n",
      "        elif self.row_num % 2 != 0 and self.bg_odd is not None:\n",
      "            return self.bg_odd(data)\n",
      "        else:\n",
      "            return str(data)\n",
      "\n",
      "__________________________________________________-\n",
      "def generate_data_row(self, row_data) :\n",
      "\n",
      "        pre_line = '║' + self.padding * SPACE\n",
      "\n",
      "        inter_cell = self.padding * SPACE\n",
      "        if self.column_borders:\n",
      "            inter_cell += '│'\n",
      "        inter_cell += self.padding * SPACE\n",
      "\n",
      "        post_line = self.padding * SPACE + '║'\n",
      "\n",
      "        fill_char = self._apply_bg_color(SPACE)\n",
      "        pre_line = self._apply_bg_color(pre_line)\n",
      "        inter_cell = self._apply_bg_color(inter_cell)\n",
      "        post_line = self._apply_bg_color(post_line)\n",
      "\n",
      "        # Apply appropriate background color to data, but don't change the original\n",
      "        to_display = [self._apply_bg_color(col) for col in row_data]\n",
      "\n",
      "        row = self.generate_row(row_data=to_display, fill_char=fill_char, pre_line=pre_line,\n",
      "                                inter_cell=inter_cell, post_line=post_line)\n",
      "        self.row_num += 1\n",
      "        return row\n",
      "\n",
      "__________________________________________________-\n",
      "def generate_table(self, table_data, *, include_header = True) :\n",
      "\n",
      "        table_buf = io.StringIO()\n",
      "\n",
      "        if include_header:\n",
      "            header = self.generate_header()\n",
      "            table_buf.write(header)\n",
      "        else:\n",
      "            top_border = self.generate_table_top_border()\n",
      "            table_buf.write(top_border)\n",
      "\n",
      "        table_buf.write('\\n')\n",
      "\n",
      "        for row_data in table_data:\n",
      "            row = self.generate_data_row(row_data)\n",
      "            table_buf.write(row)\n",
      "            table_buf.write('\\n')\n",
      "\n",
      "        table_buf.write(self.generate_table_bottom_border())\n",
      "        return table_buf.getvalue()\n",
      "\n",
      "__________________________________________________-\n",
      "def style_aware_write(fileobj, msg) :\n",
      "\n",
      "    if allow_style.lower() == STYLE_NEVER.lower() or \\\n",
      "            (allow_style.lower() == STYLE_TERMINAL.lower() and not fileobj.isatty()):\n",
      "        msg = strip_style(msg)\n",
      "    fileobj.write(msg)\n",
      "\n",
      "__________________________________________________-\n",
      "def style_aware_wcswidth(text) :\n",
      "\n",
      "    # Strip ANSI style sequences since they cause wcswidth to return -1\n",
      "    return wcswidth(strip_style(text))\n",
      "\n",
      "__________________________________________________-\n",
      "def strip_style(text) :\n",
      "\n",
      "    return ANSI_STYLE_RE.sub('', text)\n",
      "\n",
      "__________________________________________________-\n",
      "def style(text, *, fg = '', bg = '', bold = False,\n",
      "          dim = False, underline = False) :\n",
      "\n",
      "    # List of strings that add style\n",
      "    additions = []\n",
      "\n",
      "    # List of strings that remove style\n",
      "    removals = []\n",
      "\n",
      "    # Convert the text object into a string if it isn't already one\n",
      "    text = \"{}\".format(text)\n",
      "\n",
      "    # Process the style settings\n",
      "    if fg:\n",
      "        additions.append(fg_lookup(fg))\n",
      "        removals.append(FG_RESET)\n",
      "\n",
      "    if bg:\n",
      "        additions.append(bg_lookup(bg))\n",
      "        removals.append(BG_RESET)\n",
      "\n",
      "    if bold:\n",
      "        additions.append(INTENSITY_BRIGHT)\n",
      "        removals.append(INTENSITY_NORMAL)\n",
      "\n",
      "    if dim:\n",
      "        additions.append(INTENSITY_DIM)\n",
      "        removals.append(INTENSITY_NORMAL)\n",
      "\n",
      "    if underline:\n",
      "        additions.append(UNDERLINE_ENABLE)\n",
      "        removals.append(UNDERLINE_DISABLE)\n",
      "\n",
      "    # Combine the ANSI style sequences with the text\n",
      "    return \"\".join(additions) + text + \"\".join(removals)\n",
      "\n",
      "__________________________________________________-\n",
      "def __str__(self) :\n",
      "\n",
      "        return str(self.value)\n",
      "\n",
      "__________________________________________________-\n",
      "def __add__(self, other) :\n",
      "\n",
      "        return str(self) + other\n",
      "\n",
      "__________________________________________________-\n"
     ]
    }
   ],
   "source": [
    "for v,i in romanov.iloc[:50].iterrows():\n",
    "    print(i['body'])\n",
    "    print(infer(model, i['body']), i['arg_types'])\n",
    "    print('__________________________________________________-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "selected-indiana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_enc = preprocessing.LabelEncoder()\n",
    "\n",
    "df_labels = pd.DataFrame(romanov_consistent['arg_types'].values.tolist())\n",
    "df_labels[pd.isnull(df_labels)]  = NaN_symbol\n",
    "all_types = df_labels.apply(pd.Series).stack().values\n",
    "r_enc.fit(all_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "blank-costs",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " 'Any',\n",
       " 'DataFrame',\n",
       " 'Type',\n",
       " 'bool',\n",
       " 'bytes',\n",
       " 'dict',\n",
       " 'float',\n",
       " 'int',\n",
       " 'list',\n",
       " 'object',\n",
       " 'str',\n",
       " 'type'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(r_enc.classes_).intersection(set(enc.classes_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
